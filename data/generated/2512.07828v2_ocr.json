{
  "schema_version": "1.0",
  "source_file": "2512.07828v2.pdf",
  "source_type": "pdf",
  "processor": "mistral_ocr",
  "pages": [
    {
      "page_number": 1,
      "width": 1700,
      "height": 2200,
      "text": "The Adoption and Usage of AI Agents: Early Evidence from Perplexity Jeremy Yang^{1} Noah Yonack^{2} Kate Zyskowski^{2} Denis Yarats^{2} Johnny Ho^{2} Jerry Ma^{2} ^{1}Harvard University ^{2}Perplexity Abstract This paper presents the first large-scale field study of the adoption, usage intensity, and use cases of general-purpose AI agents operating in open-world web environments. Our analysis centers on Comet, an AI-powered browser developed by Perplexity, and its integrated agent, Comet Assistant. Drawing on hundreds of millions of anonymized user interactions, we address three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for? Our findings reveal substantial heterogeneity in adoption and usage across user segments. Earlier adopters, users in countries with higher GDP per capita and educational attainment, and individuals working in digital or knowledge-intensive sectors—such as digital technology, academia, finance, marketing, and entrepreneurship—are more likely to adopt or actively use the agent. To systematically characterize the substance of agent usage, we introduce a hierarchical agentic taxonomy that organizes use cases across three levels: topic, subtopic, and task. The two largest topics—Productivity & Workflow and Learning & Research—account for 57% of all agentic queries, while the two largest subtopics—Courses and Shopping for Goods—make up 22%. The top 10 out of 90 tasks represent 55% of queries. Personal use constitutes 55% of queries, while professional and educational contexts comprise 30% and 16%, respectively. In the short term, use cases exhibit strong stickiness, but over time, users tend to shift toward more cognitively oriented topics. The diffusion of increasingly capable AI agents carries important implications for researchers, businesses, policymakers, and educators, inviting new lines of inquiry into this rapidly emerging class of AI capabilities.",
      "markdown": "# The Adoption and Usage of AI Agents: Early Evidence from Perplexity\n\nJeremy Yang^{1} Noah Yonack^{2}\nKate Zyskowski^{2} Denis Yarats^{2} Johnny Ho^{2} Jerry Ma^{2}\n^{1}Harvard University\n^{2}Perplexity\n\n###### Abstract\n\nThis paper presents the first large-scale field study of the adoption, usage intensity, and use cases of general-purpose AI agents operating in open-world web environments. Our analysis centers on Comet, an AI-powered browser developed by Perplexity, and its integrated agent, Comet Assistant. Drawing on hundreds of millions of anonymized user interactions, we address three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for? Our findings reveal substantial heterogeneity in adoption and usage across user segments. Earlier adopters, users in countries with higher GDP per capita and educational attainment, and individuals working in digital or knowledge-intensive sectors—such as digital technology, academia, finance, marketing, and entrepreneurship—are more likely to adopt or actively use the agent. To systematically characterize the substance of agent usage, we introduce a hierarchical agentic taxonomy that organizes use cases across three levels: topic, subtopic, and task. The two largest topics—Productivity & Workflow and Learning & Research—account for 57% of all agentic queries, while the two largest subtopics—Courses and Shopping for Goods—make up 22%. The top 10 out of 90 tasks represent 55% of queries. Personal use constitutes 55% of queries, while professional and educational contexts comprise 30% and 16%, respectively. In the short term, use cases exhibit strong stickiness, but over time, users tend to shift toward more cognitively oriented topics. The diffusion of increasingly capable AI agents carries important implications for researchers, businesses, policymakers, and educators, inviting new lines of inquiry into this rapidly emerging class of AI capabilities.\n\n##",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": [
        "https://arxiv.org/abs/2512.07828v2",
        "mailto:jeryang%40hbs.edu",
        "mailto:jerry%40perplexity.ai"
      ]
    },
    {
      "page_number": 2,
      "width": 1700,
      "height": 2200,
      "text": "1 Introduction 2025 is frequently heralded as the year of agentic AI, as the frontier shifts from conversational Large Language Model (LLM) chatbots to action-oriented AI agents. This narrative has emerged as AI agents have progressed from a largely theoretical construct to widely productized assistants, demonstrating strong potential to transform work and daily life by planning and executing complex tasks in response to high-level human instructions with little supervision [Wooldridge and Jennings, 1995]. AI agents could profoundly reshape individual workflows, as well as organizational and market structures, by increasing productivity and efficiency and lowering transaction costs as autonomous participants in both consumption and production processes [Hadfield and Koh, 2025, Rothschild et al., 2025, Shahidi et al., 2025]. In aggregate, Precedence Research estimates that the global agentic AI market size will grow from $8 billion in 2025 to $199 billion by 2034. PwC forecasts that the overall associated economic contribution could reach between $2.6 trillion and $4.4 trillion annually by 2030. Despite this enthusiasm and its far-reaching economic implications, systematic behavioral evidence on how people actually adopt and use AI agents in the field remains limited, often relying on non-representative firm surveys [Pan et al., 2025] or focusing on specialized agents such as coding assistants [Sarkar, 2025]. Launched in July 2025, Comet by Perplexity is among the first widely adopted AI browsers and offers the embedded Comet Assistant as a general-purpose AI agent capable of performing user-specified tasks across open-world web environments. By studying hundreds of millions of anonymized user interactions with Comet and Comet Assistant, we narrow the gap by providing early insights into three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for? AI Agents We define agentic AI systems as AI assistants capable of autonomously pursuing user-defined goals by planning and taking multi-step actions on a user's behalf to interact with and effect outcomes across real-world environments. In general, agentic AI is a concept that resists precise definition. Despite variations, the definitions share several common themes: goal orientation, action taking, and autonomy. For instance, Shavit et al. [2023] defines agentic AI systems as those capable of taking actions that consistently contribute toward achieving goals over extended periods without their behavior being explicitly specified in advance, and Schluntz and Zhang [2024] describes agents as systems that dynamically direct their own processes and tool use, maintaining control over how they",
      "markdown": "# 1 Introduction\n\n2025 is frequently heralded as the year of agentic AI, as the frontier shifts from conversational Large Language Model (LLM) chatbots to action-oriented AI agents. This narrative has emerged as AI agents have progressed from a largely theoretical construct to widely productized assistants, demonstrating strong potential to transform work and daily life by planning and executing complex tasks in response to high-level human instructions with little supervision [Wooldridge and Jennings, 1995]. AI agents could profoundly reshape individual workflows, as well as organizational and market structures, by increasing productivity and efficiency and lowering transaction costs as autonomous participants in both consumption and production processes [Hadfield and Koh, 2025, Rothschild et al., 2025, Shahidi et al., 2025]. In aggregate, Precedence Research estimates that the global agentic AI market size will grow from $8 billion in 2025 to $199 billion by 2034. PwC forecasts that the overall associated economic contribution could reach between $2.6 trillion and $4.4 trillion annually by 2030.\n\nDespite this enthusiasm and its far-reaching economic implications, systematic behavioral evidence on how people actually adopt and use AI agents in the field remains limited, often relying on non-representative firm surveys [Pan et al., 2025] or focusing on specialized agents such as coding assistants [Sarkar, 2025]. Launched in July 2025, Comet by Perplexity is among the first widely adopted AI browsers and offers the embedded Comet Assistant as a general-purpose AI agent capable of performing user-specified tasks across open-world web environments. By studying hundreds of millions of anonymized user interactions with Comet and Comet Assistant, we narrow the gap by providing early insights into three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for?\n\n# AI Agents\n\nWe define agentic AI systems as AI assistants capable of autonomously pursuing user-defined goals by planning and taking multi-step actions on a user's behalf to interact with and effect outcomes across real-world environments.\n\nIn general, agentic AI is a concept that resists precise definition. Despite variations, the definitions share several common themes: goal orientation, action taking, and autonomy. For instance, Shavit et al. [2023] defines agentic AI systems as those capable of taking actions that consistently contribute toward achieving goals over extended periods without their behavior being explicitly specified in advance, and Schluntz and Zhang [2024] describes agents as systems that dynamically direct their own processes and tool use, maintaining control over how they",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": [
        "https://finance.yahoo.com/news/nvidia-jensen-huang-says-ai-044815659.html",
        "https://x.com/gdb/status/1879327050819104778",
        "https://www.aboutamazon.com/news/company-news/amazon-ceo-andy-jassy-on-generative-ai",
        "https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality",
        "https://www.precedenceresearch.com/agentic-ai-market",
        "https://www.pwc.com/m1/en/publications/agentic-ai-the-new-frontier-in-genai.html",
        "https://knowledge.wharton.upenn.edu/special-report/2025-ai-adoption-report/"
      ]
    },
    {
      "page_number": 3,
      "width": 1700,
      "height": 2200,
      "text": "complete tasks. Perplexity Team [2025] refines these definitions by replacing the term \"agent\" with \"assistant,\" arguing that each AI agent is best understood as a personal, powerful generalist serving the interests of a single user or customer, in contrast to a human agent who typically manages multiple clients within narrow professional roles or licensing constraints and often faces conflicting incentives. In addition, we place particular emphasis on the agent's ability not only to exchange information with its environment but also to actively modify it. Under the ReAct framework, an agentic workflow typically cycles automatically between three iterative phases to achieve the end goal: thinking, acting, and observing [Yao et al., 2022]. In the thinking phase, the agent interprets the goal from the query and devises a step-by-step plan to achieve it. In the acting phase, the agent executes actions by controlling external tools to interact with its environment. In the observing phase, the agent processes feedback from its environment and returns to the thinking phase to confirm or revise its plan as needed. It is also useful to contrast LLM chatbots and AI agents. Both chatbots and agents build on LLMs, but agents extend chatbots' capabilities beyond conversations to include autonomous actions. LLMs serve as the \"brain\" of an agent, functioning as the central reasoning engine that processes information, evaluates options, and makes decisions. Tools are the \"hands\" that connect the agent's reasoning to the external world, enabling it to act upon its environment. More advanced agent capabilities also include multi-agent orchestration—the ability to interface with and manage workflows across multiple collaborating agents—and self-evolution—the ability to identify gaps in pre-specified resources and dynamically expand them. Research Setting: Perplexity and Comet Perplexity is an AI-powered platform that helps users discover, analyze, and act on information. Instead of requiring users to navigate through pages of results (\"blue links\"), as traditional search engines do, Perplexity interacts with the web on users' behalf to deliver direct, verifiable, and conversational answers. Each answer includes inline citations and links to original sources, enabling users to verify information and explore topics in more detail.[9] Comet is a browser from Perplexity that embeds an AI assistant directly into the browsing experience, helping users discover, analyze, and act on information more effectively. Its core feature, Comet Assistant, operates as an autonomous agent that takes actions and completes open-world web-based tasks on behalf of users. To fulfill user requests, Comet Assistant can execute a variety of tasks, including scheduling meetings, editing documents, sending emails, booking flights, making purchases, and more.[10] Comet was launched on July 9, 2025, on desktop for subscribers to Perplexity's Max tier $^{11}$ , along with selected users from a pre-launch waitlist. $^{12}$ Access expanded to Pro subscribers on",
      "markdown": "complete tasks. Perplexity Team [2025] refines these definitions by replacing the term \"agent\" with \"assistant,\" arguing that each AI agent is best understood as a personal, powerful generalist serving the interests of a single user or customer, in contrast to a human agent who typically manages multiple clients within narrow professional roles or licensing constraints and often faces conflicting incentives. In addition, we place particular emphasis on the agent's ability not only to exchange information with its environment but also to actively modify it.\n\nUnder the ReAct framework, an agentic workflow typically cycles automatically between three iterative phases to achieve the end goal: thinking, acting, and observing [Yao et al., 2022]. In the thinking phase, the agent interprets the goal from the query and devises a step-by-step plan to achieve it. In the acting phase, the agent executes actions by controlling external tools to interact with its environment. In the observing phase, the agent processes feedback from its environment and returns to the thinking phase to confirm or revise its plan as needed.\n\nIt is also useful to contrast LLM chatbots and AI agents. Both chatbots and agents build on LLMs, but agents extend chatbots' capabilities beyond conversations to include autonomous actions. LLMs serve as the \"brain\" of an agent, functioning as the central reasoning engine that processes information, evaluates options, and makes decisions. Tools are the \"hands\" that connect the agent's reasoning to the external world, enabling it to act upon its environment. More advanced agent capabilities also include multi-agent orchestration—the ability to interface with and manage workflows across multiple collaborating agents—and self-evolution—the ability to identify gaps in pre-specified resources and dynamically expand them.\n\n# Research Setting: Perplexity and Comet\n\nPerplexity is an AI-powered platform that helps users discover, analyze, and act on information. Instead of requiring users to navigate through pages of results (\"blue links\"), as traditional search engines do, Perplexity interacts with the web on users' behalf to deliver direct, verifiable, and conversational answers. Each answer includes inline citations and links to original sources, enabling users to verify information and explore topics in more detail.[9]\n\nComet is a browser from Perplexity that embeds an AI assistant directly into the browsing experience, helping users discover, analyze, and act on information more effectively. Its core feature, Comet Assistant, operates as an autonomous agent that takes actions and completes open-world web-based tasks on behalf of users. To fulfill user requests, Comet Assistant can execute a variety of tasks, including scheduling meetings, editing documents, sending emails, booking flights, making purchases, and more.[10]\n\nComet was launched on July 9, 2025, on desktop for subscribers to Perplexity's Max tier $^{11}$ , along with selected users from a pre-launch waitlist. $^{12}$  Access expanded to Pro subscribers on",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": [
        "https://huggingface.co/learn/agents-course/en/unit1/agent-steps-and-structure",
        "https://www.kaggle.com/whitepaper-introduction-to-agents",
        "https://www.perplexity.ai/help-center/en/articles/10352155-what-is-perplexity",
        "https://www.perplexity.ai/hub/blog/introducing-comet"
      ]
    },
    {
      "page_number": 4,
      "width": 1700,
      "height": 2200,
      "text": "August 13, 2025, beginning with users in the United States.¹³ On October 2, 2025, Comet became available to all users worldwide.¹⁴ In addition to these general cohorts, Comet was opened to university students globally on September 3, 2025. Data Our analysis relies on three samples collected from Comet desktop users between July 9 and October 22, 2025.¹⁵ First, we use anonymized data from the entire population of Comet users and their queries to provide high-level, aggregated statistics on agent adoption and usage intensity; this sample includes millions of users and hundreds of millions of queries. Second, we analyze a random sample of 100,000 Comet users and classify their O*NET occupation clusters and subclusters based on the National Career Clusters Framework to examine variation across occupations.¹⁶ Third, we analyze a separate random sample of 100,000 agent users and classify all of their agentic queries using a novel hierarchical agentic taxonomy to better understand common use cases at the topic, subtopic, and task levels. Summary of Findings We report two sets of results on the adoption and use of AI agents: the extensive and intensive margins and a comprehensive taxonomy of use cases. Adoption and usage intensity Overall, agent adoption and usage intensity demonstrate sustained growth with acceleration following the general availability (GA) of Comet. The post-GA period accounts for 60% of agent adopters and 50% of agentic queries throughout our sampling period. Earlier Comet adopters (those with pre-GA access) represent a disproportionately large share of agent adopters and agentic queries relative to their user share. The disparity is more pronounced in usage intensity than in adoption—an average user in the first cohort (July 9) is twice as likely to adopt the agent and makes nine times as many agentic queries as an average user in the GA cohort (October 2). At the country level, adoption and usage intensity show strong positive correlations with GDP per capita and average years of education. At the occupational level, adopters and queries tend to come more from digital or knowledge-intensive domains. Digital technology¹⁷ represents the largest occupational cluster, comprising 28% of adopters and 30% of queries, followed by academia, finance, marketing, and entrepreneurship. These occupational clusters collectively ¹³ https://www.perplexity.ai/hub/blog/the-intelligent-business-introducing-comet-for-enterprise-pro ¹⁴ https://www.perplexity.ai/hub/blog/comet-is-now-available-to-everyone-worldwide ¹⁵ We define Comet users as those who made at least one query on Comet during our study period. We use October 22, 2025, as the cutoff date because a major agent update began rolling out to selected users on October 23, which could affect adoption and usage patterns thereafter. The new agent was launched to all users on November 6. The updated agent performs 23% better than the previous version and offers greater multitasking capacity across multiple tabs. The agent we analyze in our data operates in a single web environment. For more details, see: https://www.perplexity.ai/hub/blog/the-new-comet-assistant. ¹⁶ https://www.ometonline.org/find/career?c=0 https://careertech.org/career-clusters/ ¹⁷ The Digital Technology Career Cluster focuses on developing digital systems for communication and data storage using critical technologies such as artificial intelligence (AI), data analytics, and cybersecurity. https://careertech.org/career-clusters/digital-technology/",
      "markdown": "August 13, 2025, beginning with users in the United States.¹³ On October 2, 2025, Comet became available to all users worldwide.¹⁴ In addition to these general cohorts, Comet was opened to university students globally on September 3, 2025.\n\n## Data\n\nOur analysis relies on three samples collected from Comet desktop users between July 9 and October 22, 2025.¹⁵ First, we use anonymized data from the entire population of Comet users and their queries to provide high-level, aggregated statistics on agent adoption and usage intensity; this sample includes millions of users and hundreds of millions of queries. Second, we analyze a random sample of 100,000 Comet users and classify their O*NET occupation clusters and subclusters based on the National Career Clusters Framework to examine variation across occupations.¹⁶ Third, we analyze a separate random sample of 100,000 agent users and classify all of their agentic queries using a novel hierarchical agentic taxonomy to better understand common use cases at the topic, subtopic, and task levels.\n\n## Summary of Findings\n\nWe report two sets of results on the adoption and use of AI agents: the extensive and intensive margins and a comprehensive taxonomy of use cases.\n\n## Adoption and usage intensity\n\nOverall, agent adoption and usage intensity demonstrate sustained growth with acceleration following the general availability (GA) of Comet. The post-GA period accounts for 60% of agent adopters and 50% of agentic queries throughout our sampling period. Earlier Comet adopters (those with pre-GA access) represent a disproportionately large share of agent adopters and agentic queries relative to their user share. The disparity is more pronounced in usage intensity than in adoption—an average user in the first cohort (July 9) is twice as likely to adopt the agent and makes nine times as many agentic queries as an average user in the GA cohort (October 2). At the country level, adoption and usage intensity show strong positive correlations with GDP per capita and average years of education. At the occupational level, adopters and queries tend to come more from digital or knowledge-intensive domains. Digital technology¹⁷ represents the largest occupational cluster, comprising 28% of adopters and 30% of queries, followed by academia, finance, marketing, and entrepreneurship. These occupational clusters collectively\n\n¹³ https://www.perplexity.ai/hub/blog/the-intelligent-business-introducing-comet-for-enterprise-pro\n¹⁴ https://www.perplexity.ai/hub/blog/comet-is-now-available-to-everyone-worldwide\n¹⁵ We define Comet users as those who made at least one query on Comet during our study period. We use October 22, 2025, as the cutoff date because a major agent update began rolling out to selected users on October 23, which could affect adoption and usage patterns thereafter. The new agent was launched to all users on November 6. The updated agent performs 23% better than the previous version and offers greater multitasking capacity across multiple tabs. The agent we analyze in our data operates in a single web environment. For more details, see: https://www.perplexity.ai/hub/blog/the-new-comet-assistant.\n¹⁶ https://www.ometonline.org/find/career?c=0 https://careertech.org/career-clusters/\n¹⁷ The Digital Technology Career Cluster focuses on developing digital systems for communication and data storage using critical technologies such as artificial intelligence (AI), data analytics, and cybersecurity. https://careertech.org/career-clusters/digital-technology/",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": [
        "https://www.perplexity.ai/hub/blog/the-intelligent-business-introducing-comet-for-enterprise-pro",
        "https://www.perplexity.ai/hub/blog/comet-is-now-available-to-everyone-worldwide",
        "https://www.perplexity.ai/hub/blog/the-new-comet-assistant",
        "https://www.onetonline.org/find/career?c=0",
        "https://careertech.org/career-clusters/",
        "https://careertech.org/career-clusters/digital-technology/"
      ]
    },
    {
      "page_number": 5,
      "width": 1700,
      "height": 2200,
      "text": "account for over 70% of total adopters and queries. They also tend to have higher agent adopter or agentic query shares than their user shares. Use cases We illustrate the hierarchical structure of our agentic taxonomy in Figure 1 and report our complete taxonomy in Table 1. Productivity is the dominant topic with a 36% share. It is followed by learning (21%), media (16%), and shopping (10%). The most prevalent subtopics with over 5% query share include courses (13%), goods shopping (9%), research (8%), document editing (8%), account management (7%), and social media (7%). The most frequently observed tasks are exercise assistance (9%), research information summarization and analysis (7%), document creation and editing (7%), product search and filtering (6%), and research information search and filtering (6%). We also study the use of agents across environments, which are the websites on which these tasks are performed. The concentration of environments varies substantially across subtopics: the top 5 environments account for 97% of queries in music, 97% in videos, and 96% in professional networking, compared to only 28% in account management, 35% in shopping for services, and 37% in project management. Across all use cases, 55% of agentic queries originate from personal use settings, 30% from professional use settings, and 16% from educational use settings. In the short term, users show strong within-topic persistence, demonstrating stickiness in use cases; when topic transitions occur, they are more likely to migrate toward productivity, learning, or media topics. Over time, query shares shift from travel and media topics to productivity, learning, and career topics.",
      "markdown": "account for over 70% of total adopters and queries. They also tend to have higher agent adopter or agentic query shares than their user shares.\n\n### Use cases\n\nWe illustrate the hierarchical structure of our agentic taxonomy in Figure 1 and report our complete taxonomy in Table 1. Productivity is the dominant topic with a 36% share. It is followed by learning (21%), media (16%), and shopping (10%). The most prevalent subtopics with over 5% query share include courses (13%), goods shopping (9%), research (8%), document editing (8%), account management (7%), and social media (7%). The most frequently observed tasks are exercise assistance (9%), research information summarization and analysis (7%), document creation and editing (7%), product search and filtering (6%), and research information search and filtering (6%). We also study the use of agents across environments, which are the websites on which these tasks are performed. The concentration of environments varies substantially across subtopics: the top 5 environments account for 97% of queries in music, 97% in videos, and 96% in professional networking, compared to only 28% in account management, 35% in shopping for services, and 37% in project management. Across all use cases, 55% of agentic queries originate from personal use settings, 30% from professional use settings, and 16% from educational use settings. In the short term, users show strong within-topic persistence, demonstrating stickiness in use cases; when topic transitions occur, they are more likely to migrate toward productivity, learning, or media topics. Over time, query shares shift from travel and media topics to productivity, learning, and career topics.",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 6,
      "width": 1700,
      "height": 2200,
      "text": "Figure 1: Hierarchical Structure of the Agentic Taxonomy !img-0.jpeg Note: A topic contains multiple subtopics; a subtopic contains multiple tasks; a task can be connected to multiple environments; and an environment can be connected to one or multiple tasks within or across different topics and subtopics. The colors indicate different topics, solid lines indicate connections between topics, subtopics, and tasks, and dashed lines indicate which tasks are performed in which environments. Note that task 1.1.1 can be performed in environments A and B, whereas task 1.1.2 can only be performed in environment B. Tasks 2.1.1 and 2.1.2 indicate similar patterns. Environment B spans subtopics 1.1 and 2.1, whereas environments A and C are specific to a single subtopic. We substantiate the structure with some examples. The query \"unsubscribe me from all promotional emails that I receive more than twice per month\" would be labeled as {Topic: Productivity &amp; Workflow, Subtopic: Email Management, Task: Search or filter emails, Delete or unsubscribe emails}. In this case, searching or filtering emails, and deleting or unsubscribing from them, can both be performed in environments such as Gmail or Outlook. Now imagine another query that gets classified into {Topic: Shopping &amp; Commerce, Subtopic: Shopping for Goods, Task: Search discounts, Make product purchase}; both tasks can be performed on Instacart, whereas only search discounts can be performed on SimplyCodes, as it only shows discount codes and does not sell products directly. Facebook is one example of a cross-topic environment—it could be the environment for Media &amp; Entertainment queries, but also for Shopping &amp; Commerce queries when they are about products listed on Facebook Marketplace.",
      "markdown": "Figure 1: Hierarchical Structure of the Agentic Taxonomy\n![img-0.jpeg](img-0.jpeg)\nNote: A topic contains multiple subtopics; a subtopic contains multiple tasks; a task can be connected to multiple environments; and an environment can be connected to one or multiple tasks within or across different topics and subtopics. The colors indicate different topics, solid lines indicate connections between topics, subtopics, and tasks, and dashed lines indicate which tasks are performed in which environments. Note that task 1.1.1 can be performed in environments A and B, whereas task 1.1.2 can only be performed in environment B. Tasks 2.1.1 and 2.1.2 indicate similar patterns. Environment B spans subtopics 1.1 and 2.1, whereas environments A and C are specific to a single subtopic. We substantiate the structure with some examples. The query \"unsubscribe me from all promotional emails that I receive more than twice per month\" would be labeled as {Topic: Productivity &amp; Workflow, Subtopic: Email Management, Task: Search or filter emails, Delete or unsubscribe emails}. In this case, searching or filtering emails, and deleting or unsubscribing from them, can both be performed in environments such as Gmail or Outlook. Now imagine another query that gets classified into {Topic: Shopping &amp; Commerce, Subtopic: Shopping for Goods, Task: Search discounts, Make product purchase}; both tasks can be performed on Instacart, whereas only search discounts can be performed on SimplyCodes, as it only shows discount codes and does not sell products directly. Facebook is one example of a cross-topic environment—it could be the environment for Media &amp; Entertainment queries, but also for Shopping &amp; Commerce queries when they are about products listed on Facebook Marketplace.",
      "blocks": [],
      "tables": [],
      "images": [
        {
          "id": "img-0.jpeg",
          "top_left_x": 341,
          "top_left_y": 666,
          "bottom_right_x": 1329,
          "bottom_right_y": 1174,
          "image_base64": null,
          "image_annotation": null
        }
      ],
      "hyperlinks": []
    },
    {
      "page_number": 7,
      "width": 1700,
      "height": 2200,
      "text": "tbl-0.md Note: The table contains all topics, subtopics, and tasks in the agentic taxonomy, except \"Other\". Topics and subtopics are general goals, and tasks are specific tasks the agent is expected to complete to achieve those goals. A query is classified into one topic, one subtopic underneath that topic, and one or more tasks underneath that subtopic. Queries that cannot be classified into the taxonomy at a given level are labeled as \"Other\" at that level and all subsequent levels. For example, a query that does not belong to any of the topics would be labeled as \"Other\" at topic, subtopic, and task levels; a query that belongs to productivity but does not belong to any of the subtopics under productivity will be labeled as \"Other\" at subtopic and task levels; a query that belongs to productivity and email management but does not belong to any of the tasks under email management will be labeled as \"Other\" at the task level. Table 1: Agentic Taxonomy—Topics, Subtopics, and Tasks",
      "markdown": "[tbl-0.md](tbl-0.md)\n\nNote: The table contains all topics, subtopics, and tasks in the agentic taxonomy, except \"Other\". Topics and subtopics are general goals, and tasks are specific tasks the agent is expected to complete to achieve those goals. A query is classified into one topic, one subtopic underneath that topic, and one or more tasks underneath that subtopic. Queries that cannot be classified into the taxonomy at a given level are labeled as \"Other\" at that level and all subsequent levels. For example, a query that does not belong to any of the topics would be labeled as \"Other\" at topic, subtopic, and task levels; a query that belongs to productivity but does not belong to any of the subtopics under productivity will be labeled as \"Other\" at subtopic and task levels; a query that belongs to productivity and email management but does not belong to any of the tasks under email management will be labeled as \"Other\" at the task level.\n\nTable 1: Agentic Taxonomy—Topics, Subtopics, and Tasks",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-0.md",
          "format": "markdown",
          "content": "|  Topics | Subtopics | Tasks  |\n| --- | --- | --- |\n|  Productivity & Workflow | Account Management | Register/log in to accounts, Manage settings/profiles, Manage files, Summarize/analyze account information  |\n|   |  Document & Form Editing | Create/edit documents, Search/filter documents, Summarize/analyze documents  |\n|   |  Multimedia Editing | Create/edit multimedia, Search/filter multimedia, Summarize/analyze multimedia  |\n|   |  Email Management | Search/filter emails, Create/edit emails, Send emails, Delete/unsubscribe emails, Summarize/analyze emails  |\n|   |  Spreadsheet & Data Editing | Create/edit spreadsheets, Search/filter spreadsheets, Summarize/analyze spreadsheets  |\n|   |  Computer Programming | Create/edit code, Execute code, Summarize/analyze code  |\n|   |  Investments & Banking | Search/filter stocks, Buy/sell stocks, Summarize/analyze investment information, Summarize/analyze banking information  |\n|   |  Project Management | Create/edit projects, Summarize/analyze project information  |\n|   |  Calendar Management | Create/edit events, Check availability, Search/filter events, Summarize/analyze events  |\n|  Learning & Research | Courses | Navigate courses, Summarize/analyze course materials, Assist exercises  |\n|   |  Research | Search/filter research information, Summarize/analyze research information  |\n|  Media & Entertainment | Social Media & Messaging | Search/filter social media posts, Summarize/analyze social media posts, Create social media posts, Engage with social media posts, Send social media/text messages  |\n|   |  Online Games | Search/filter online games, Summarize/analyze online game information, Play online games  |\n|   |  Movies, TV, & Videos | Search/filter videos, Summarize/analyze videos, Play videos, Navigate within videos, Manage playlists  |\n|   |  Music & Podcasts | Search/filter music/podcasts, Summarize/analyze music/podcasts, Play music/podcasts, Manage playlists  |\n|   |  News | Search/filter news, Summarize/analyze news  |\n|   |  Sports | Search/filter match/player information, Summarize/analyze match/player statistics  |\n|  Shopping & Commerce | Goods | Search/filter products, Search discounts, Summarize/analyze product information, Add products to cart, Make product purchase, Manage orders  |\n|   |  Services | Search/filter products, Search discounts, Summarize/analyze product information, Add products to cart, Make product purchase, Manage orders  |\n|  Travel & Leisure | Flights & Transportation | Search/filter flights & transportation, Summarize/analyze flights & transportation, Add flights & transportation to cart, Book flights & transportation  |\n|   |  Trip Itineraries | Search/filter destinations, Plan trips, Summarize/analyze trips  |\n|   |  Lodging | Search/filter lodging, Summarize/analyze lodging information, Add lodging to cart, Book lodging  |\n|   |  Restaurants | Search/filter restaurants, Summarize/analyze restaurant information, Book restaurants  |\n|  Job & Career | Job Search & Application | Search/filter jobs, Summarize/analyze job descriptions, Complete applications  |\n|   |  Professional Networking | Search/filter professional profiles, Summarize/analyze professional profiles, Send professional connection requests/messages, Engage with professional profiles/posts  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 8,
      "width": 1700,
      "height": 2200,
      "text": "The remainder of this paper is structured as follows. Section 2 reviews related literature and highlights our contributions. Section 3 describes our sampling methodology and data privacy safeguards. Section 4 explains the development of our hierarchical agentic taxonomy. Section 5 presents our main findings on AI agent adoption patterns, usage intensity, and use cases. Finally, Section 6 discusses the implications of our findings for researchers, businesses, and policymakers, while acknowledging limitations and identifying promising avenues for future research that we aim to pursue. Key figures and tables are included in the main text. Additional figures, tables, and other supplementary materials are provided in the Appendices. 2 Related Work Our paper is directly related to the literature on how people use LLMs and AI agents in real-world settings. $^{18}$ Our paper extends recent work on the adoption and usage of LLM chatbots. Several prominent studies have examined this topic, including Handa et al. [2025c], which documents user interactions with Claude, and Zhao et al. [2024] and Chatterji et al. [2025], which analyze how people use ChatGPT. Anthropic has also released detailed analyses focusing on specific user groups, such as university students [Handa et al., 2025a], educators [Bent et al., 2025], and different geographies and enterprises [Appel et al., 2025]. In addition, Aubakirova et al. [2025] uses OpenRouter data to study LLM chatbot usage across both open- and closed-source models. These papers developed taxonomies to categorize standard Q&amp;A queries. We also create a taxonomy using internal data from an AI product; however, our key contribution is the focus on agentic queries. The main difference is that Q&amp;A queries focus on information exchange between the user and model in a conversation. In contrast, agentic queries focus on the agent executing tasks on the user's behalf in an external environment. Evidence on how people use AI agents in the field is limited and typically focuses on specific use cases, such as coding. For example, Anthropic [2025b] studies the usage of Claude Code, a coding agent, in software development, and Sarkar [2025] investigates the adoption, usage, and productivity impact of coding agents in Cursor. Our contribution differs in that we analyze a general-purpose agent operating across all common use cases.[19] 3 Data Sampling Our analysis leverages three samples collected between July 9 and October 22, 2025—that is, from the launch date to 20 days after general availability. Each sample is tailored to a particular",
      "markdown": "The remainder of this paper is structured as follows. Section 2 reviews related literature and highlights our contributions. Section 3 describes our sampling methodology and data privacy safeguards. Section 4 explains the development of our hierarchical agentic taxonomy. Section 5 presents our main findings on AI agent adoption patterns, usage intensity, and use cases. Finally, Section 6 discusses the implications of our findings for researchers, businesses, and policymakers, while acknowledging limitations and identifying promising avenues for future research that we aim to pursue. Key figures and tables are included in the main text. Additional figures, tables, and other supplementary materials are provided in the Appendices.\n\n# 2 Related Work\n\nOur paper is directly related to the literature on how people use LLMs and AI agents in real-world settings. $^{18}$  Our paper extends recent work on the adoption and usage of LLM chatbots. Several prominent studies have examined this topic, including Handa et al. [2025c], which documents user interactions with Claude, and Zhao et al. [2024] and Chatterji et al. [2025], which analyze how people use ChatGPT. Anthropic has also released detailed analyses focusing on specific user groups, such as university students [Handa et al., 2025a], educators [Bent et al., 2025], and different geographies and enterprises [Appel et al., 2025]. In addition, Aubakirova et al. [2025] uses OpenRouter data to study LLM chatbot usage across both open- and closed-source models. These papers developed taxonomies to categorize standard Q&amp;A queries. We also create a taxonomy using internal data from an AI product; however, our key contribution is the focus on agentic queries. The main difference is that Q&amp;A queries focus on information exchange between the user and model in a conversation. In contrast, agentic queries focus on the agent executing tasks on the user's behalf in an external environment.\n\nEvidence on how people use AI agents in the field is limited and typically focuses on specific use cases, such as coding. For example, Anthropic [2025b] studies the usage of Claude Code, a coding agent, in software development, and Sarkar [2025] investigates the adoption, usage, and productivity impact of coding agents in Cursor. Our contribution differs in that we analyze a general-purpose agent operating across all common use cases.[19]\n\n# 3 Data\n\n# Sampling\n\nOur analysis leverages three samples collected between July 9 and October 22, 2025—that is, from the launch date to 20 days after general availability. Each sample is tailored to a particular",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 9,
      "width": 1700,
      "height": 2200,
      "text": "set of research questions. We define a Comet user as a user who has made at least one query on Comet during the study period. At the user level, we exclude all enterprise users, users under the Perplexity for Government program, users who deleted their accounts during the sampling period, users who opted out of data retention for model training during that period, and logged-out users. At the query level, we define an agentic query as one that involves the agent taking control of the browser or taking actions on external applications—such as email or calendar clients—through connectors built on the Model Context Protocol (MCP) or via API calls. Under this stricter definition, we do not consider all queries with tool use (such as web search or code interpreter) as agentic, since these tools merely exchange information with external environments but do not manipulate them. When users onboard onto Comet, sample agentic queries are shown for demonstration purposes; we remove these queries to focus only on user-initiated ones. In rare cases, a single agentic query might trigger multiple browser-control, MCP, or API calls; we exclude such cases to focus on queries that trigger a single call, ensuring a clean inference of user intent. Lastly, we exclude queries made in Comet’s incognito mode. We describe the three samples we analyze below. Sample A: The population of Comet users and queries We use the entire population of millions of users and hundreds of millions of queries on Comet—both agentic and non-agentic—during the sampling period to understand overall patterns in adoption and usage intensity. Sample B: A random sample of Comet users and queries We draw random samples of 100,000 Comet users and their recent queries—both agentic and non-agentic—during the study period to infer their O*NET occupation clusters and subclusters, enabling us to examine variation in adoption and usage intensity across occupations. The sampling includes two stages. First, a random set of users is selected, then for each user, a random set of queries from recent dates is selected. The sampled queries are then concatenated into a single string and labeled using a classifier against the occupation taxonomy. We include university students as a separate cluster as they are not included in the occupation taxonomy. Sample C: A random sample of Comet agent users and all their agentic queries We draw another random sample of 100,000 agent users and classify all their agentic queries using a novel agentic taxonomy to identify common use cases. The sampling is performed only at the user level: once a user is selected, all their agentic queries are included in the analysis. This procedure allows us to track within-user agent usage trajectories and uncover longitudinal patterns. In large user samples, the queries are also representative of query-level estimands,",
      "markdown": "set of research questions.\n\nWe define a Comet user as a user who has made at least one query on Comet during the study period. At the user level, we exclude all enterprise users, users under the Perplexity for Government program, users who deleted their accounts during the sampling period, users who opted out of data retention for model training during that period, and logged-out users. At the query level, we define an agentic query as one that involves the agent taking control of the browser or taking actions on external applications—such as email or calendar clients—through connectors built on the Model Context Protocol (MCP) or via API calls. Under this stricter definition, we do not consider all queries with tool use (such as web search or code interpreter) as agentic, since these tools merely exchange information with external environments but do not manipulate them. When users onboard onto Comet, sample agentic queries are shown for demonstration purposes; we remove these queries to focus only on user-initiated ones. In rare cases, a single agentic query might trigger multiple browser-control, MCP, or API calls; we exclude such cases to focus on queries that trigger a single call, ensuring a clean inference of user intent. Lastly, we exclude queries made in Comet’s incognito mode. We describe the three samples we analyze below.\n\n### Sample A: The population of Comet users and queries\n\nWe use the entire population of millions of users and hundreds of millions of queries on Comet—both agentic and non-agentic—during the sampling period to understand overall patterns in adoption and usage intensity.\n\n### Sample B: A random sample of Comet users and queries\n\nWe draw random samples of 100,000 Comet users and their recent queries—both agentic and non-agentic—during the study period to infer their O*NET occupation clusters and subclusters, enabling us to examine variation in adoption and usage intensity across occupations. The sampling includes two stages. First, a random set of users is selected, then for each user, a random set of queries from recent dates is selected. The sampled queries are then concatenated into a single string and labeled using a classifier against the occupation taxonomy. We include university students as a separate cluster as they are not included in the occupation taxonomy.\n\n### Sample C: A random sample of Comet agent users and all their agentic queries\n\nWe draw another random sample of 100,000 agent users and classify all their agentic queries using a novel agentic taxonomy to identify common use cases. The sampling is performed only at the user level: once a user is selected, all their agentic queries are included in the analysis. This procedure allows us to track within-user agent usage trajectories and uncover longitudinal patterns. In large user samples, the queries are also representative of query-level estimands,",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": [
        "https://www.anthropic.com/news/model-context-protocol",
        "https://www.onetonline.org/find/career?c=0"
      ]
    },
    {
      "page_number": 10,
      "width": 1700,
      "height": 2200,
      "text": "including common use cases. For the same sample of users, we further infer their O*NET occupation clusters and subclusters. Data Privacy We follow industry standards and implement multiple safeguards to ensure that no human uses any personally identifiable information (PII) at any point in the analysis. First, as noted above, enterprise users, users under the Perplexity for Government program, users who deleted their accounts during the sampling period, users who opted out of data retention for model training during that period, logged-out users, and queries made in incognito mode are excluded from the analysis. Second, our analysis does not use any demographic information, names, email addresses, or other real-world identifiers; all user-level matching is performed through internal numerical user IDs. Third, we employ automated classifiers to label occupations and use cases. The classifier input is not the raw query text but a reformulated description of the underlying intent, enriched with context such as prior queries in the same conversation and the website on which the query was made. Lastly, all results reported in the paper are presented only in a highly aggregated form. 4 Agentic Taxonomy We develop a hierarchical agentic taxonomy guided by two principles. First, it should comprehensively capture common agentic intents so that it can generalize to other agentic products beyond Comet. Second, it should have a hierarchical structure that reveals higher-level goals while distinguishing specific lower-level tasks and actions. To achieve these goals, we adopt a bottom-up approach consisting of three phases: exploration, refinement, and classification. In the exploration phase, we draw a random sample of agentic queries, extract their embeddings, and apply K-means clustering to group them based on semantic similarity. Queries are then sampled from each cluster and concatenated into a single string representing that cluster. We then summarize each concatenated string to interpret the meaning of each cluster. In the refinement phase, we manually examine the cluster labels identified in the previous step to merge, split, trim, or expand them, following the guiding principles. When a significant share of queries is labeled as “Other”, suggesting that the provided taxonomy does not sufficiently capture them, we re-classify the queries in that cluster using the bottom-up approach in the first step to identify clusters missing from the taxonomy and update it. Finally, we classify agentic queries within the finalized taxonomy using a query classification model. Our final taxonomy consists of three hierarchical levels—*topic*, *subtopic*, and *task*—as illustrated in a stylized diagram in Figure 1, along with their connections to the environments the tasks are performed in. The full taxonomy is summarized in Table 1.",
      "markdown": "including common use cases. For the same sample of users, we further infer their O*NET occupation clusters and subclusters.\n\n### Data Privacy\n\nWe follow industry standards and implement multiple safeguards to ensure that no human uses any personally identifiable information (PII) at any point in the analysis.\n\nFirst, as noted above, enterprise users, users under the Perplexity for Government program, users who deleted their accounts during the sampling period, users who opted out of data retention for model training during that period, logged-out users, and queries made in incognito mode are excluded from the analysis. Second, our analysis does not use any demographic information, names, email addresses, or other real-world identifiers; all user-level matching is performed through internal numerical user IDs. Third, we employ automated classifiers to label occupations and use cases. The classifier input is not the raw query text but a reformulated description of the underlying intent, enriched with context such as prior queries in the same conversation and the website on which the query was made. Lastly, all results reported in the paper are presented only in a highly aggregated form.\n\n## 4 Agentic Taxonomy\n\nWe develop a hierarchical agentic taxonomy guided by two principles. First, it should comprehensively capture common agentic intents so that it can generalize to other agentic products beyond Comet. Second, it should have a hierarchical structure that reveals higher-level goals while distinguishing specific lower-level tasks and actions.\n\nTo achieve these goals, we adopt a bottom-up approach consisting of three phases: exploration, refinement, and classification. In the exploration phase, we draw a random sample of agentic queries, extract their embeddings, and apply K-means clustering to group them based on semantic similarity. Queries are then sampled from each cluster and concatenated into a single string representing that cluster. We then summarize each concatenated string to interpret the meaning of each cluster. In the refinement phase, we manually examine the cluster labels identified in the previous step to merge, split, trim, or expand them, following the guiding principles. When a significant share of queries is labeled as “Other”, suggesting that the provided taxonomy does not sufficiently capture them, we re-classify the queries in that cluster using the bottom-up approach in the first step to identify clusters missing from the taxonomy and update it. Finally, we classify agentic queries within the finalized taxonomy using a query classification model.\n\nOur final taxonomy consists of three hierarchical levels—*topic*, *subtopic*, and *task*—as illustrated in a stylized diagram in Figure 1, along with their connections to the environments the tasks are performed in. The full taxonomy is summarized in Table 1.",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": [
        "https://www.perplexity.ai/hub/legal/privacy-policy"
      ]
    },
    {
      "page_number": 11,
      "width": 1700,
      "height": 2200,
      "text": "Topics and subtopics are top- and mid-level use cases of the agent, indicating the overall goal, while tasks are the specific tasks the agent is expected to complete to achieve that goal. Each query is classified into one topic, one subtopic, and one or more tasks. For instance, the query “unsubscribe me from all promotional emails that I receive more than twice per month” would be labeled as {Topic: Productivity & Workflow, Subtopic: Email Management, Task: Search or filter emails, Delete or unsubscribe emails}. The environments the agent operates in are observed in the data and can be connected to our taxonomy. Tasks in a particular subtopic are performed in a specific set of environments, and each environment might involve one or more of these tasks. For instance, under the subtopic Email Management, tasks such as Search or filter emails and Delete or unsubscribe emails can both be performed in environments such as Gmail or Outlook; under Shopping for Goods, Search discounts and Make product purchase can both be performed on Instacart, whereas only Search discounts can be performed on SimplyCodes as it only shows discount codes and does not sell products directly. Furthermore, an environment might cut across multiple topics and subtopics. For instance, Facebook could be the environment for Media & Entertainment queries, but also Shopping & Commerce queries when they are about products listed on Facebook Marketplace. We further categorize the usage context into personal, professional, and educational domains. We validate the classification accuracy against a golden dataset of 1,000 anonymized and desensitized queries. The classifier-assigned labels agree with the topics, subtopics, tasks, and usage context in the golden dataset 89%, 83%, 81%, and 83% of the time, respectively. More details about the validation are provided in Appendix D. 5 Main Results We first discuss the results on the adoption (extensive margin) and usage intensity (intensive margin), and then the use cases (agentic taxonomy). 5.1 Adoption and Usage Intensity We define agent adopters as users who had at least one agentic query in the sampling period. The results below are all based on Sample A, except for occupation, which is based on Sample B. Figure 6 in Appendix A shows that agent adoption and overall usage as measured by agentic query volumes are growing steadily over the period studied, with an increased pace after Comet became generally available. About 60% of agent users were acquired, and 50% of agentic queries occurred post-GA. The query volumes grow at a slightly higher rate than adopters. We analyze the adoption and usage patterns of user segments defined by cohort, country, and occupation. To capture the magnitude of adoption and usage within a user segment relative to its user share, we define the Perplexity Agent Adoption Ratio (AAR) and the Agent Usage Ratio (AUR) as the ratio of a segment’s agent adopter share or agentic query share to its user share.",
      "markdown": "Topics and subtopics are top- and mid-level use cases of the agent, indicating the overall goal, while tasks are the specific tasks the agent is expected to complete to achieve that goal. Each query is classified into one topic, one subtopic, and one or more tasks. For instance, the query “unsubscribe me from all promotional emails that I receive more than twice per month” would be labeled as {Topic: Productivity & Workflow, Subtopic: Email Management, Task: Search or filter emails, Delete or unsubscribe emails}.\n\nThe environments the agent operates in are observed in the data and can be connected to our taxonomy. Tasks in a particular subtopic are performed in a specific set of environments, and each environment might involve one or more of these tasks. For instance, under the subtopic Email Management, tasks such as Search or filter emails and Delete or unsubscribe emails can both be performed in environments such as Gmail or Outlook; under Shopping for Goods, Search discounts and Make product purchase can both be performed on Instacart, whereas only Search discounts can be performed on SimplyCodes as it only shows discount codes and does not sell products directly. Furthermore, an environment might cut across multiple topics and subtopics. For instance, Facebook could be the environment for Media & Entertainment queries, but also Shopping & Commerce queries when they are about products listed on Facebook Marketplace. We further categorize the usage context into personal, professional, and educational domains.\n\nWe validate the classification accuracy against a golden dataset of 1,000 anonymized and desensitized queries. The classifier-assigned labels agree with the topics, subtopics, tasks, and usage context in the golden dataset 89%, 83%, 81%, and 83% of the time, respectively. More details about the validation are provided in Appendix D.\n\n## 5 Main Results\n\nWe first discuss the results on the adoption (extensive margin) and usage intensity (intensive margin), and then the use cases (agentic taxonomy).\n\n### 5.1 Adoption and Usage Intensity\n\nWe define agent adopters as users who had at least one agentic query in the sampling period. The results below are all based on Sample A, except for occupation, which is based on Sample B.\n\nFigure 6 in Appendix A shows that agent adoption and overall usage as measured by agentic query volumes are growing steadily over the period studied, with an increased pace after Comet became generally available. About 60% of agent users were acquired, and 50% of agentic queries occurred post-GA. The query volumes grow at a slightly higher rate than adopters.\n\nWe analyze the adoption and usage patterns of user segments defined by cohort, country, and occupation. To capture the magnitude of adoption and usage within a user segment relative to its user share, we define the Perplexity Agent Adoption Ratio (AAR) and the Agent Usage Ratio (AUR) as the ratio of a segment’s agent adopter share or agentic query share to its user share.",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 12,
      "width": 1700,
      "height": 2200,
      "text": "An AAR or AUR greater than one indicates that a segment is over-represented in the adopters or queries relative to their population base, and vice versa. By cohort Table 2 shows that among the three cohorts by access dates, earlier adopters (those with access before GA) account for about $30\\%$ of total users, but about $50\\%$ of agent adopters and $70\\%$ of agentic queries. The disparity is more pronounced in usage intensity than in adoption—an average user in the first cohort (July 9) is twice as likely to adopt the agent but makes nine times as many agentic queries as an average user in the GA cohort (October 2). AAR and AUR both decrease in the order of access cohorts. In general, the composition of early adopters is endogenous to the rollout plan; in our case, it is based on the subscription tiers. Nonetheless, these results are consistent with general patterns in the adoption and usage of new technologies [Moore, 1991]: early adopters disproportionately drive initial adoption and usage, and subsequent diffusion may require additional educational efforts. With improved agent-to-agent collaboration capabilities and standardized protocols, one might expect stronger network effects that could accelerate adoption and usage in the future.[26] tbl-1.md Note: The table shows the agent adoption and agentic query by cohort. User share is the number of users in each cohort divided by the total users. Agent adopter and query share are the numbers of adopters and agentic queries in each cohort, divided by the total number of adopters and agentic queries. AAR (Agent Adoption Ratio) is the ratio between agent adopter share and user share. AUR (Agent Usage Ratio) is the ratio between agentic query share and user share. AAR and AUR greater (less) than 1 indicate that a cohort is over-represented (under-represented) in agent adopters and queries relative to their user base. Table 2: Agent Adoption and Agentic Query by Cohort By country Figure 2 and 3 show that there are strong positive correlations between log agent adopters per million population and log GDP per capita ( $r = 0.85$ , $p &lt; 0.001$ , $R^2 = 0.73$ ) and years of education ( $r = 0.75$ , $p &lt; 0.001$ , $R^2 = 0.56$ ), where $r$ is the correlation coefficient, $p$ is the p-value of the correlation coefficient, and $R^2$ is the R-squared of the regression lines. The correlations between log agentic queries per million population and log GDP per capita ( $r = 0.86$ , $p &lt; 0.001$ , $R^2 = 0.74$ ) and years of education ( $r = 0.75$ , $p &lt; 0.001$ , $R^2 = 0.57$ ) follow a similar pattern. Together, they suggest that relatively more economically developed and educated countries tend to adopt and use the agent more.[27]",
      "markdown": "An AAR or AUR greater than one indicates that a segment is over-represented in the adopters or queries relative to their population base, and vice versa.\n\n# By cohort\n\nTable 2 shows that among the three cohorts by access dates, earlier adopters (those with access before GA) account for about  $30\\%$  of total users, but about  $50\\%$  of agent adopters and  $70\\%$  of agentic queries. The disparity is more pronounced in usage intensity than in adoption—an average user in the first cohort (July 9) is twice as likely to adopt the agent but makes nine times as many agentic queries as an average user in the GA cohort (October 2). AAR and AUR both decrease in the order of access cohorts.\n\nIn general, the composition of early adopters is endogenous to the rollout plan; in our case, it is based on the subscription tiers. Nonetheless, these results are consistent with general patterns in the adoption and usage of new technologies [Moore, 1991]: early adopters disproportionately drive initial adoption and usage, and subsequent diffusion may require additional educational efforts. With improved agent-to-agent collaboration capabilities and standardized protocols, one might expect stronger network effects that could accelerate adoption and usage in the future.[26]\n\n[tbl-1.md](tbl-1.md)\n\nNote: The table shows the agent adoption and agentic query by cohort. User share is the number of users in each cohort divided by the total users. Agent adopter and query share are the numbers of adopters and agentic queries in each cohort, divided by the total number of adopters and agentic queries. AAR (Agent Adoption Ratio) is the ratio between agent adopter share and user share. AUR (Agent Usage Ratio) is the ratio between agentic query share and user share. AAR and AUR greater (less) than 1 indicate that a cohort is over-represented (under-represented) in agent adopters and queries relative to their user base.\n\nTable 2: Agent Adoption and Agentic Query by Cohort\n\n# By country\n\nFigure 2 and 3 show that there are strong positive correlations between log agent adopters per million population and log GDP per capita ( $r = 0.85$ ,  $p &lt; 0.001$ ,  $R^2 = 0.73$ ) and years of education ( $r = 0.75$ ,  $p &lt; 0.001$ ,  $R^2 = 0.56$ ), where  $r$  is the correlation coefficient,  $p$  is the p-value of the correlation coefficient, and  $R^2$  is the R-squared of the regression lines. The correlations between log agentic queries per million population and log GDP per capita ( $r = 0.86$ ,  $p &lt; 0.001$ ,  $R^2 = 0.74$ ) and years of education ( $r = 0.75$ ,  $p &lt; 0.001$ ,  $R^2 = 0.57$ ) follow a similar pattern. Together, they suggest that relatively more economically developed and educated countries tend to adopt and use the agent more.[27]",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-1.md",
          "format": "markdown",
          "content": "|  Cohort | User Share (%) | Agent Adopter Share (%) | Agentic Query Share (%) | AAR | AUR  |\n| --- | --- | --- | --- | --- | --- |\n|  July 9 | 4.3 | 7.7 | 18.9 | 1.79 | 4.40  |\n|  August 13 | 28.3 | 38.1 | 48.5 | 1.35 | 1.71  |\n|  October 2 | 67.4 | 54.2 | 32.7 | 0.80 | 0.49  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": [
        "https://a2a-protocol.org/latest/"
      ]
    },
    {
      "page_number": 13,
      "width": 1700,
      "height": 2200,
      "text": "!img-1.jpeg (a) Log GDP Per Capita vs. Log Agent Adopters Per Million Population !img-2.jpeg (b) Average Years of Education vs. Log Agent Adopters Per Million Population Figure 2: Log GDP Per Capita and Average Years of Education vs. Log Agent Adopters Per Million Population by Country Note: The plots show the scatterplots and best-fitting lines of log GDP per capita and average years of education vs. the log of agent adopter per million population for the top 100 countries by agent adopter count. The plots are on a log scale, but the labels are in absolute values for better readability. Jitter is applied to the country labels to provide better visual separation. $r$ is the correlation coefficient, $p$ is the p-value of the regression coefficient, and $R^2$ is the R-squared of the regression lines. The GDP and population data are from World Bank World Development Indicators (2024) $^a$ and the average years of education data are from UNDP Human Development Report (2024) $^b$ .",
      "markdown": "![img-1.jpeg](img-1.jpeg)\n(a) Log GDP Per Capita vs. Log Agent Adopters Per Million Population\n\n![img-2.jpeg](img-2.jpeg)\n(b) Average Years of Education vs. Log Agent Adopters Per Million Population\nFigure 2: Log GDP Per Capita and Average Years of Education vs. Log Agent Adopters Per Million Population by Country\n\nNote: The plots show the scatterplots and best-fitting lines of log GDP per capita and average years of education vs. the log of agent adopter per million population for the top 100 countries by agent adopter count. The plots are on a log scale, but the labels are in absolute values for better readability. Jitter is applied to the country labels to provide better visual separation.  $r$  is the correlation coefficient,  $p$  is the p-value of the regression coefficient, and  $R^2$  is the R-squared of the regression lines. The GDP and population data are from World Bank World Development Indicators (2024) $^a$  and the average years of education data are from UNDP Human Development Report (2024) $^b$ .",
      "blocks": [],
      "tables": [],
      "images": [
        {
          "id": "img-1.jpeg",
          "top_left_x": 387,
          "top_left_y": 301,
          "bottom_right_x": 1283,
          "bottom_right_y": 871,
          "image_base64": null,
          "image_annotation": null
        },
        {
          "id": "img-2.jpeg",
          "top_left_x": 387,
          "top_left_y": 968,
          "bottom_right_x": 1283,
          "bottom_right_y": 1537,
          "image_base64": null,
          "image_annotation": null
        }
      ],
      "hyperlinks": [
        "https://data.worldbank.org/",
        "https://hdr.undp.org/content/human-development-report-2023-24"
      ]
    },
    {
      "page_number": 14,
      "width": 1700,
      "height": 2200,
      "text": "!img-3.jpeg (a) Log GDP Per Capita vs. Log Agentic Queries Per Million Population !img-4.jpeg (b) Average Years of Education vs. Log Agentic Queries Per Million Population Figure 3: Log GDP Per Capita and Average Years of Education vs. Log Agentic Queries Per Million Population by Country Note: The plots show the scatterplots and best-fitting lines of log GDP per capita and average years of education vs. the log of agentic query per million population for the top 100 countries by agentic query count. The plots are on a log scale, but the labels are in absolute values for better readability. Jitter is applied to the country labels to provide better visual separation. $r$ is the correlation coefficient, $p$ is the $p$ -value of the regression coefficient, and $R^2$ is the R-squared of the regression lines. The GDP and population data are from World Bank World Development Indicators (2024) $^a$ , and the average years of education data are from UNDP Human Development Report (2024) $^b$",
      "markdown": "![img-3.jpeg](img-3.jpeg)\n(a) Log GDP Per Capita vs. Log Agentic Queries Per Million Population\n\n![img-4.jpeg](img-4.jpeg)\n(b) Average Years of Education vs. Log Agentic Queries Per Million Population\nFigure 3: Log GDP Per Capita and Average Years of Education vs. Log Agentic Queries Per Million Population by Country\n\nNote: The plots show the scatterplots and best-fitting lines of log GDP per capita and average years of education vs. the log of agentic query per million population for the top 100 countries by agentic query count. The plots are on a log scale, but the labels are in absolute values for better readability. Jitter is applied to the country labels to provide better visual separation.  $r$  is the correlation coefficient,  $p$  is the  $p$ -value of the regression coefficient, and  $R^2$  is the R-squared of the regression lines. The GDP and population data are from World Bank World Development Indicators (2024) $^a$ , and the average years of education data are from UNDP Human Development Report (2024) $^b$",
      "blocks": [],
      "tables": [],
      "images": [
        {
          "id": "img-3.jpeg",
          "top_left_x": 387,
          "top_left_y": 301,
          "bottom_right_x": 1283,
          "bottom_right_y": 871,
          "image_base64": null,
          "image_annotation": null
        },
        {
          "id": "img-4.jpeg",
          "top_left_x": 387,
          "top_left_y": 968,
          "bottom_right_x": 1283,
          "bottom_right_y": 1535,
          "image_base64": null,
          "image_annotation": null
        }
      ],
      "hyperlinks": [
        "https://data.worldbank.org/",
        "https://hdr.undp.org/content/human-development-report-2023-24"
      ]
    },
    {
      "page_number": 15,
      "width": 1700,
      "height": 2200,
      "text": "By occupation Table 3 ranks occupation clusters (including the student cluster) by user share, adopter share, and AAR. Digital technology is by far the largest cluster, accounting for 28% of adopters, slightly higher than its user share. Academics (including the student and education clusters) and financial workers have an adopter share of more than 10%. Workers in marketing, design, and entrepreneurship have an adopter share of more than 5%. Clusters with lower adopter shares are typically those that require interacting with the physical environment. The hospitality cluster has the highest AAR at 1.36, although the sample size is significantly smaller; it is followed by marketing and entrepreneurship at 1.24 and 1.17, respectively. Table 4 ranks occupation clusters by user share, query share, and AUR. The patterns track adoption closely—top clusters remain the same with slight changes in the rank. Comparing the AUR and AAR for the same cluster reveals patterns in the degree of usage intensity relative to the degree of adoption: students and workers in entrepreneurship, marketing, and digital technology all have AUR / AAR greater than one, suggesting that their tendency to use the agent conditional on adoption is even stronger than their tendency to adopt. Tables 8 and 9 in Appendix A show the top 10 occupation subclusters and their user shares by agent adopter shares and AAR, and agentic query share and AUR, respectively. Patterns at the subcluster level are largely consistent with those at the cluster level, with software engineers being the largest subcluster, accounting for 14% of adopters and 15% of queries, and having AAR and AUR around 1.1 and 1.2, respectively. All other subclusters are below 6% in both adopter and query shares. Subclusters in marketing—such as business development and sales, digital marketing, and market research—and in entrepreneurship—such as information management, operations, and strategy—tend to have the highest AAR and AUR. These results may reflect differences in the task composition of each occupation and how closely those tasks align with common agent use cases, which the next section examines.",
      "markdown": "By occupation\n\nTable 3 ranks occupation clusters (including the student cluster) by user share, adopter share, and AAR. Digital technology is by far the largest cluster, accounting for 28% of adopters, slightly higher than its user share. Academics (including the student and education clusters) and financial workers have an adopter share of more than 10%. Workers in marketing, design, and entrepreneurship have an adopter share of more than 5%. Clusters with lower adopter shares are typically those that require interacting with the physical environment. The hospitality cluster has the highest AAR at 1.36, although the sample size is significantly smaller; it is followed by marketing and entrepreneurship at 1.24 and 1.17, respectively.\n\nTable 4 ranks occupation clusters by user share, query share, and AUR. The patterns track adoption closely—top clusters remain the same with slight changes in the rank. Comparing the AUR and AAR for the same cluster reveals patterns in the degree of usage intensity relative to the degree of adoption: students and workers in entrepreneurship, marketing, and digital technology all have AUR / AAR greater than one, suggesting that their tendency to use the agent conditional on adoption is even stronger than their tendency to adopt.\n\nTables 8 and 9 in Appendix A show the top 10 occupation subclusters and their user shares by agent adopter shares and AAR, and agentic query share and AUR, respectively. Patterns at the subcluster level are largely consistent with those at the cluster level, with software engineers being the largest subcluster, accounting for 14% of adopters and 15% of queries, and having AAR and AUR around 1.1 and 1.2, respectively. All other subclusters are below 6% in both adopter and query shares. Subclusters in marketing—such as business development and sales, digital marketing, and market research—and in entrepreneurship—such as information management, operations, and strategy—tend to have the highest AAR and AUR.\n\nThese results may reflect differences in the task composition of each occupation and how closely those tasks align with common agent use cases, which the next section examines.",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 16,
      "width": 1700,
      "height": 2200,
      "text": "tbl-2.md Note: The table shows agent adoption by O*NET occupation cluster. The \"Other\" category is removed. We put students in a separate cluster and educators in the Education cluster. User share is the number of users in each cluster divided by the total users. Agent adopter share is the number of adopters in each cluster divided by the total adopters. AAR (Agent Adoption Ratio) is the ratio between agent adopter share and user share. AAR greater (less) than 1 indicates that a cluster is over-represented (under-represented) in agent adoption relative to their user base. Table 3: Agent Adoption by Occupation Cluster tbl-3.md Note: The table shows usage intensity by O*NET occupation cluster. The \"Other\" category is removed. We put students in a separate cluster and educators in the Education cluster. User share is the number of users in each cluster divided by the total users. Agent query share is the number of agentic queries in each cluster divided by the total agentic queries. AUR (Agent Usage Ratio) is the ratio between agentic query share and user share. AUR greater (less) than 1 indicates that a cluster is over-represented (under-represented) in agent usage relative to their user base. Table 4: Agentic Query by Occupation Cluster",
      "markdown": "[tbl-2.md](tbl-2.md)\n\nNote: The table shows agent adoption by O*NET occupation cluster. The \"Other\" category is removed. We put students in a separate cluster and educators in the Education cluster. User share is the number of users in each cluster divided by the total users. Agent adopter share is the number of adopters in each cluster divided by the total adopters. AAR (Agent Adoption Ratio) is the ratio between agent adopter share and user share. AAR greater (less) than 1 indicates that a cluster is over-represented (under-represented) in agent adoption relative to their user base.\n\nTable 3: Agent Adoption by Occupation Cluster\n\n[tbl-3.md](tbl-3.md)\n\nNote: The table shows usage intensity by O*NET occupation cluster. The \"Other\" category is removed. We put students in a separate cluster and educators in the Education cluster. User share is the number of users in each cluster divided by the total users. Agent query share is the number of agentic queries in each cluster divided by the total agentic queries. AUR (Agent Usage Ratio) is the ratio between agentic query share and user share. AUR greater (less) than 1 indicates that a cluster is over-represented (under-represented) in agent usage relative to their user base.\n\nTable 4: Agentic Query by Occupation Cluster",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-2.md",
          "format": "markdown",
          "content": "|  Agent Adoption by Occupation Cluster: By AAR  |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Cluster | User Share (%) | User Share Rank | Agent Adopter Share (%) | Agent Adopter Share Rank | AAR  |\n|  Hospitality, Events, & Tourism | 2.5 | 11 | 3.4 | 9 | 1.36  |\n|  Marketing & Sales | 7.2 | 6 | 8.9 | 4 | 1.24  |\n|  Management & Entrepreneurship | 6.5 | 7 | 7.6 | 6 | 1.17  |\n|  Digital Technology | 26.4 | 1 | 27.7 | 1 | 1.05  |\n|  Supply Chain & Transportation | 2.2 | 13 | 2.3 | 12 | 1.05  |\n|  Financial Services | 10.0 | 3 | 10.1 | 3 | 1.01  |\n|  Student | 12.4 | 2 | 12.4 | 2 | 1.00  |\n|  Construction | 2.3 | 12 | 2.2 | 13 | 0.96  |\n|  Energy & Natural Resources | 0.9 | 14 | 0.8 | 14 | 0.89  |\n|  Arts, Entertainment, & Design | 9.1 | 4 | 8.0 | 5 | 0.88  |\n|  Education | 7.7 | 5 | 6.4 | 7 | 0.83  |\n|  Healthcare & Human Services | 4.9 | 8 | 4.0 | 8 | 0.82  |\n|  Advanced Manufacturing | 3.5 | 9 | 2.8 | 10 | 0.80  |\n|  Public Service & Safety | 3.4 | 10 | 2.7 | 11 | 0.79  |\n|  Agriculture | 0.9 | 15 | 0.7 | 15 | 0.78  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        },
        {
          "table_id": "tbl-3.md",
          "format": "markdown",
          "content": "|  Agentic Query by Occupation Cluster: By AUR  |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Cluster | User Share (%) | User Share Rank | Agentic Query Share (%) | Agentic Query Share Rank | AUR  |\n|  Marketing & Sales | 7.2 | 6 | 10.5 | 3 | 1.46  |\n|  Management & Entrepreneurship | 6.5 | 7 | 9.0 | 4 | 1.38  |\n|  Student | 12.4 | 2 | 15.6 | 2 | 1.26  |\n|  Digital Technology | 26.4 | 1 | 29.6 | 1 | 1.12  |\n|  Hospitality, Events, & Tourism | 2.5 | 11 | 2.6 | 9 | 1.04  |\n|  Supply Chain & Transportation | 2.2 | 13 | 2.0 | 10 | 0.91  |\n|  Financial Services | 10.0 | 3 | 8.6 | 5 | 0.86  |\n|  Arts, Entertainment, & Design | 9.1 | 4 | 6.9 | 6 | 0.76  |\n|  Education | 7.7 | 5 | 5.6 | 7 | 0.73  |\n|  Construction | 2.3 | 12 | 1.6 | 13 | 0.70  |\n|  Healthcare & Human Services | 4.9 | 8 | 3.3 | 8 | 0.67  |\n|  Agriculture | 0.9 | 15 | 0.5 | 15 | 0.56  |\n|  Energy & Natural Resources | 0.9 | 14 | 0.5 | 14 | 0.56  |\n|  Advanced Manufacturing | 3.5 | 9 | 1.9 | 11 | 0.54  |\n|  Public Service & Safety | 3.4 | 10 | 1.8 | 12 | 0.53  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 17,
      "width": 1700,
      "height": 2200,
      "text": "5.2 Use Cases We document the use cases by topic, subtopic, task, environment (the websites on which the tasks are performed), and usage context. All results are based on Sample C. Topics and subtopics Topics and subtopics capture the high-level goals of an agentic query. Figure 4 presents the topic share and subtopic share breakdown by topic. Productivity is the largest category, accounting for $36\\%$ of all agentic queries. Learning, media, and shopping are the other topics with over $10\\%$ query share. The two largest topics—productivity and learning—together account for $57\\%$ of all queries. Some topics, such as learning, shopping, and career, have a dominant subtopic that accounts for more than half of the queries in that topic. Table 10 in Appendix A also shows the overall query share of each subtopic. Courses account for $13\\%$ of all queries, followed by goods shopping, document editing, account management, social media, and email. Figure 4: Topic Breakdown by Subtopic Percentage !img-5.jpeg Note: The plot shows the percentage shares of subtopics within each topic. Bar width is proportional to topic percentage, and box height within each bar is proportional to subtopic percentage. \"Other\" category $(3.4\\%)$ is not shown among the topics. The labels for subtopics that account for less than $5\\%$ within a topic are suppressed. Topic shares are shown in the labels on the x-axis. The subtopics within each topic are sorted by percentage in decreasing order from top to bottom. The darker shades within a topic represent subtopics with higher percentages.",
      "markdown": "# 5.2 Use Cases\n\nWe document the use cases by topic, subtopic, task, environment (the websites on which the tasks are performed), and usage context. All results are based on Sample C.\n\n# Topics and subtopics\n\nTopics and subtopics capture the high-level goals of an agentic query. Figure 4 presents the topic share and subtopic share breakdown by topic. Productivity is the largest category, accounting for  $36\\%$  of all agentic queries. Learning, media, and shopping are the other topics with over  $10\\%$  query share. The two largest topics—productivity and learning—together account for  $57\\%$  of all queries. Some topics, such as learning, shopping, and career, have a dominant subtopic that accounts for more than half of the queries in that topic. Table 10 in Appendix A also shows the overall query share of each subtopic. Courses account for  $13\\%$  of all queries, followed by goods shopping, document editing, account management, social media, and email.\n\nFigure 4: Topic Breakdown by Subtopic Percentage\n![img-5.jpeg](img-5.jpeg)\nNote: The plot shows the percentage shares of subtopics within each topic. Bar width is proportional to topic percentage, and box height within each bar is proportional to subtopic percentage. \"Other\" category  $(3.4\\%)$  is not shown among the topics. The labels for subtopics that account for less than  $5\\%$  within a topic are suppressed. Topic shares are shown in the labels on the x-axis. The subtopics within each topic are sorted by percentage in decreasing order from top to bottom. The darker shades within a topic represent subtopics with higher percentages.",
      "blocks": [],
      "tables": [],
      "images": [
        {
          "id": "img-5.jpeg",
          "top_left_x": 200,
          "top_left_y": 919,
          "bottom_right_x": 1475,
          "bottom_right_y": 1586,
          "image_base64": null,
          "image_annotation": null
        }
      ],
      "hyperlinks": []
    },
    {
      "page_number": 18,
      "width": 1700,
      "height": 2200,
      "text": "Table 5 shows the topic distribution by occupation cluster. Topic-wise, productivity remains the largest topic for most occupations, whereas learning and research is the largest for students and educators, and travel is the largest for the hospitality cluster. Occupation-wise, workers in finance have the largest query share in productivity, students have the largest share in learning, designers have the largest share in media, workers in advanced manufacturing have the largest share in shopping, workers in entrepreneurship have the largest share in career, and workers in hospitality have the largest share in travel. tbl-4.md Note: The table shows the distribution of topics by occupation cluster. Topic percentage $(P(\\text{Topic Occupation}))$ is the topic share among all agentic queries from a given occupation cluster. Percentages may not sum to $100\\%$ due to rounding. Table 5: Topic Distribution by Occupation Cluster We also examine transition patterns between consecutive queries. Figure 7 in Appendix A shows the transition probability matrix from the previous query to the next query for all query pairs, aggregated at the user level. The results show that in most cases, topics transition into themselves, suggesting the stickiness of agent use cases. Productivity, learning, and career topics are the most sticky, whereas travel is the least sticky; media and shopping topics fall in between. When cross-topic transitions occur, they most likely transition into productivity, learning, or media topics. Then we compare users' first queries—their entry points into the agent—and all queries. Figure 8 in Appendix A contrasts the topic distribution among the first agentic query for each user with the overall distribution. Over time, the share of queries on productivity, learning, and career topics has increased, suggesting a shift toward more cognitively oriented use cases. Tasks Tasks under topics and subtopics capture the low-level tasks the agent is expected to complete to achieve the end goals. We show the top 10 tasks in Table 6. Half of the top 10 are in learning, including various learning and research assistance. The other five are split across productivity (edit documents and manage account settings), shopping (search or summarize product information), and media (search social media).",
      "markdown": "Table 5 shows the topic distribution by occupation cluster. Topic-wise, productivity remains the largest topic for most occupations, whereas learning and research is the largest for students and educators, and travel is the largest for the hospitality cluster. Occupation-wise, workers in finance have the largest query share in productivity, students have the largest share in learning, designers have the largest share in media, workers in advanced manufacturing have the largest share in shopping, workers in entrepreneurship have the largest share in career, and workers in hospitality have the largest share in travel.\n\n[tbl-4.md](tbl-4.md)\n\nNote: The table shows the distribution of topics by occupation cluster. Topic percentage  $(P(\\text{Topic | Occupation}))$  is the topic share among all agentic queries from a given occupation cluster. Percentages may not sum to  $100\\%$  due to rounding.\n\nTable 5: Topic Distribution by Occupation Cluster\n\nWe also examine transition patterns between consecutive queries. Figure 7 in Appendix A shows the transition probability matrix from the previous query to the next query for all query pairs, aggregated at the user level. The results show that in most cases, topics transition into themselves, suggesting the stickiness of agent use cases. Productivity, learning, and career topics are the most sticky, whereas travel is the least sticky; media and shopping topics fall in between. When cross-topic transitions occur, they most likely transition into productivity, learning, or media topics. Then we compare users' first queries—their entry points into the agent—and all queries. Figure 8 in Appendix A contrasts the topic distribution among the first agentic query for each user with the overall distribution. Over time, the share of queries on productivity, learning, and career topics has increased, suggesting a shift toward more cognitively oriented use cases.\n\n# Tasks\n\nTasks under topics and subtopics capture the low-level tasks the agent is expected to complete to achieve the end goals. We show the top 10 tasks in Table 6. Half of the top 10 are in learning, including various learning and research assistance. The other five are split across productivity (edit documents and manage account settings), shopping (search or summarize product information), and media (search social media).",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-4.md",
          "format": "markdown",
          "content": "|  Cluster / Topic | Productivity & Workflow (%) | Learning & Research (%) | Media & Entertainment (%) | Shopping & Commerce (%) | Job & Career (%) | Travel & Leisure (%)  |\n| --- | --- | --- | --- | --- | --- | --- |\n|  Digital Technology | 41.0 | 19.9 | 14.7 | 9.3 | 9.1 | 6.0  |\n|  Student | 29.1 | 43.3 | 10.6 | 5.3 | 8.1 | 3.7  |\n|  Management & Entrepreneurship | 45.8 | 13.7 | 12.3 | 9.8 | 12.2 | 6.2  |\n|  Marketing & Sales | 37.5 | 12.1 | 23.8 | 14.0 | 8.2 | 4.5  |\n|  Financial Services | 46.7 | 15.2 | 14.0 | 9.8 | 5.7 | 8.6  |\n|  Education | 34.1 | 37.0 | 13.8 | 6.6 | 2.6 | 5.8  |\n|  Arts, Entertainment, & Design | 39.4 | 12.1 | 25.0 | 11.3 | 6.0 | 6.2  |\n|  Healthcare & Human Services | 38.6 | 23.3 | 14.3 | 10.2 | 5.9 | 7.7  |\n|  Advanced Manufacturing | 30.4 | 19.8 | 11.8 | 25.4 | 5.4 | 7.1  |\n|  Public Service & Safety | 39.7 | 26.2 | 17.7 | 7.2 | 3.2 | 6.0  |\n|  Hospitality, Events, & Tourism | 29.9 | 6.6 | 13.4 | 12.2 | 2.7 | 35.2  |\n|  Supply Chain & Transportation | 40.3 | 13.4 | 12.5 | 18.6 | 5.3 | 10.0  |\n|  Construction | 39.1 | 14.9 | 14.1 | 16.3 | 7.7 | 7.9  |\n|  Energy & Natural Resources | 42.9 | 18.8 | 13.1 | 10.4 | 4.9 | 9.8  |\n|  Agriculture | 41.5 | 20.5 | 13.9 | 12.4 | 5.4 | 6.3  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 19,
      "width": 1700,
      "height": 2200,
      "text": "tbl-5.md Note: The table shows the top 10 tasks among all agentic queries. $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\text{Topic}) \\times P(\\text{Task} \\text{Topic}, \\text{Subtopic})$ . Table 6: The Top 10 Tasks Tables 11, 12, 13, 14, 15, and 16 in Appendix A show the main tasks under each topic and subtopic with over $5\\%$ query shares within a subtopic. Note that because query share measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic can add up to over 100. A few subtopics contain a dominant task that appears in over $80\\%$ of all queries in that subtopic. For instance, searching for flights and lodging both appear in $93\\%$ of queries in the flight and lodging subtopics; editing documents and summarizing research information both appear in $85\\%$ of queries in the document editing and research subtopics, respectively. In contrast, some subtopics show more dispersed task distributions: for instance, searching videos—the top task in the video subtopic—appears in only $48\\%$ of all queries in that category; searching email—the top task in the email subtopic—appears in only $49\\%$ of all queries in that category. Table 17 in Appendix A shows the top 5 tasks in each occupation cluster. In general, research, document editing, and shopping-related tasks appear consistently across clusters. Some occupation clusters feature a prominent task. For instance, search products appear in $21\\%$ of queries from the advanced manufacturing cluster. Other clusters, in contrast, have a more diffuse task composition. The top tasks in the entrepreneurship and design clusters—summarizing research information and searching products—appear in fewer than $8\\%$ of their queries. The top tasks by occupation also shed light on why certain occupations tend to adopt and use the agent more. Knowledge-intensive sectors such as digital technology, entrepreneurship, finance, and academia tend to use the agent for research and learning-related tasks. In contrast, highly digitized sectors such as marketing and design tend to use the agent for media-related tasks. Environments Environment refers to the external world with which the agent interacts while performing a task to achieve its goals. In our context, the environment is the specific website on which the agent operates for a given query. We show the top environments by overall query shares in Table 7. The top 16 environments together account for $64\\%$ of queries, with the top 5 alone representing $43\\%$ . These environments are typically the dominant websites within their respective domains. We break down the top 5 environments under each subtopic and their query shares in Tables 18, 19, 20, 21, 22, and 23 in Appendix A. A single environment dominates some subtopics.",
      "markdown": "[tbl-5.md](tbl-5.md)\n\nNote: The table shows the top 10 tasks among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} | \\text{Topic}) \\times P(\\text{Task} | \\text{Topic}, \\text{Subtopic})$ .\n\nTable 6: The Top 10 Tasks\n\nTables 11, 12, 13, 14, 15, and 16 in Appendix A show the main tasks under each topic and subtopic with over  $5\\%$  query shares within a subtopic. Note that because query share measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic can add up to over 100. A few subtopics contain a dominant task that appears in over  $80\\%$  of all queries in that subtopic. For instance, searching for flights and lodging both appear in  $93\\%$  of queries in the flight and lodging subtopics; editing documents and summarizing research information both appear in  $85\\%$  of queries in the document editing and research subtopics, respectively. In contrast, some subtopics show more dispersed task distributions: for instance, searching videos—the top task in the video subtopic—appears in only  $48\\%$  of all queries in that category; searching email—the top task in the email subtopic—appears in only  $49\\%$  of all queries in that category.\n\nTable 17 in Appendix A shows the top 5 tasks in each occupation cluster. In general, research, document editing, and shopping-related tasks appear consistently across clusters. Some occupation clusters feature a prominent task. For instance, search products appear in  $21\\%$  of queries from the advanced manufacturing cluster. Other clusters, in contrast, have a more diffuse task composition. The top tasks in the entrepreneurship and design clusters—summarizing research information and searching products—appear in fewer than  $8\\%$  of their queries. The top tasks by occupation also shed light on why certain occupations tend to adopt and use the agent more. Knowledge-intensive sectors such as digital technology, entrepreneurship, finance, and academia tend to use the agent for research and learning-related tasks. In contrast, highly digitized sectors such as marketing and design tend to use the agent for media-related tasks.\n\n# Environments\n\nEnvironment refers to the external world with which the agent interacts while performing a task to achieve its goals. In our context, the environment is the specific website on which the agent operates for a given query. We show the top environments by overall query shares in Table 7. The top 16 environments together account for  $64\\%$  of queries, with the top 5 alone representing  $43\\%$ . These environments are typically the dominant websites within their respective domains.\n\nWe break down the top 5 environments under each subtopic and their query shares in Tables 18, 19, 20, 21, 22, and 23 in Appendix A. A single environment dominates some subtopics.",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-5.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Task | Overall (%)  |\n| --- | --- | --- | --- |\n|  Learning & Research | Courses | Assist exercises | 9.41  |\n|  Learning & Research | Research | Summarize/analyze research information | 6.71  |\n|  Productivity & Workflow | Document & Form Editing | Create/edit documents/forms | 6.58  |\n|  Shopping & Commerce | Goods | Search/filter products | 6.43  |\n|  Learning & Research | Research | Search/filter research information | 5.95  |\n|  Shopping & Commerce | Goods | Summarize/analyze product information | 5.18  |\n|  Productivity & Workflow | Account Management | Manage settings/profiles | 4.33  |\n|  Learning & Research | Courses | Summarize/analyze course materials | 3.69  |\n|  Learning & Research | Courses | Navigate courses | 3.31  |\n|  Media & Entertainment | Social Media & Messaging | Search/filter social media posts/messages | 3.29  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 20,
      "width": 1700,
      "height": 2200,
      "text": "For instance, linkedin.com alone accounts for $93\\%$ of queries in professional networking, and the query shares of youtube.com and docs.google.com[28]—the top environments in video and spreadsheet editing subtopics—are more than twenty times larger than the share of the second environments in those subtopics. On the other hand, there is only a $2\\%$ difference between coursera.org and netacad.com under courses, and a $3\\%$ difference between instagram.com and x.com under social media. Table 24 in Appendix A shows the combined shares of the top 5 environments in each subtopic. A higher share indicates the agent usage is more concentrated in a few environments. The level of concentration varies significantly: the top 5 environments account for $97\\%$ of queries in music, $97\\%$ in videos, and $96\\%$ in professional networking, compared to only $28\\%$ in account management, $35\\%$ in services shopping, and $37\\%$ in project management, respectively. Lastly, Table 25 in Appendix A shows the top 5 environments for each occupation cluster, which are closely related to the main use cases for each occupation. tbl-6.md Note: The table shows all environments with a query share above $1\\%$ among all agentic queries. docs.google.com includes Google Docs, Sheets, Slides, and Forms. All email domains are grouped into \"email services combined\" and all online messengers are grouped into \"messenger services combined\". Table 7: Top Agent Environments",
      "markdown": "For instance, linkedin.com alone accounts for  $93\\%$  of queries in professional networking, and the query shares of youtube.com and docs.google.com[28]—the top environments in video and spreadsheet editing subtopics—are more than twenty times larger than the share of the second environments in those subtopics. On the other hand, there is only a  $2\\%$  difference between coursera.org and netacad.com under courses, and a  $3\\%$  difference between instagram.com and x.com under social media. Table 24 in Appendix A shows the combined shares of the top 5 environments in each subtopic. A higher share indicates the agent usage is more concentrated in a few environments. The level of concentration varies significantly: the top 5 environments account for  $97\\%$  of queries in music,  $97\\%$  in videos, and  $96\\%$  in professional networking, compared to only  $28\\%$  in account management,  $35\\%$  in services shopping, and  $37\\%$  in project management, respectively. Lastly, Table 25 in Appendix A shows the top 5 environments for each occupation cluster, which are closely related to the main use cases for each occupation.\n\n[tbl-6.md](tbl-6.md)\n\nNote: The table shows all environments with a query share above  $1\\%$  among all agentic queries. docs.google.com includes Google Docs, Sheets, Slides, and Forms. All email domains are grouped into \"email services combined\" and all online messengers are grouped into \"messenger services combined\".\n\nTable 7: Top Agent Environments",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-6.md",
          "format": "markdown",
          "content": "|  Environment | Overall (%)  |\n| --- | --- |\n|  docs.google.com | 11.97  |\n|  email services combined | 11.23  |\n|  linkedin.com | 9.42  |\n|  youtube.com | 7.03  |\n|  amazon.com | 3.46  |\n|  instagram.com | 2.56  |\n|  messenger services combined | 2.47  |\n|  maps.google.com | 2.20  |\n|  coursera.org | 2.04  |\n|  x.com | 2.00  |\n|  github.com | 1.85  |\n|  facebook.com | 1.77  |\n|  netacad.com | 1.75  |\n|  canva.com | 1.49  |\n|  canvas.com | 1.44  |\n|  notion.so | 1.13  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 21,
      "width": 1700,
      "height": 2200,
      "text": "Usage context Lastly, we investigate agent usage across personal, professional, and educational contexts.[29] Personal use comprises about $55\\%$ of total agentic queries, with professional and educational contexts representing $30\\%$ and $16\\%$ , respectively. There is a slight increase in the share of educational use and a slight decrease in the share of personal use over time, while the share of professional use remains stable. This could be driven by the public launch time of Comet overlapping with the start of the fall semester and by on-campus promotional efforts, such as early access for university students, rather than by a systematic shift in the underlying composition of user groups and use cases. We show the distribution of topics by usage context in Figure 5. For personal use, productivity and media together account for $62\\%$ of all agentic queries. For professional use, $80\\%$ of agentic queries are productivity- and career-related. Educational usage is dominated by learning, comprising $89\\%$ of agentic queries. We also show the distribution of subtopic, task, and environment by usage context in Tables 26, 27, and 28 in Appendix A. The top subtopics for personal, professional, and educational use are goods shopping, document editing, and courses, respectively. The top environments for personal, professional, and educational use are emails, linkedin.com, and docs.google.com, respectively. Figure 5: Topic Distribution by Usage Context !img-6.jpeg Note: The plot shows the percentage shares of topics within each usage context. The \"Other\" category is removed from contexts. Bar width is proportional to context percentage, and box height within each bar is proportional to topic percentage. The labels for topics that account for less than $5\\%$ within a context are suppressed. Context shares are shown in the x-axis labels. The same topic is shown in the same color across contexts. The topic percentage overall is shown as a baseline for comparison. The topics within each context are sorted in the same order as the overall for easier comparison across contexts. The topics in the overall category are sorted by topic percentage, from highest to lowest.",
      "markdown": "# Usage context\n\nLastly, we investigate agent usage across personal, professional, and educational contexts.[29] Personal use comprises about  $55\\%$  of total agentic queries, with professional and educational contexts representing  $30\\%$  and  $16\\%$ , respectively. There is a slight increase in the share of educational use and a slight decrease in the share of personal use over time, while the share of professional use remains stable. This could be driven by the public launch time of Comet overlapping with the start of the fall semester and by on-campus promotional efforts, such as early access for university students, rather than by a systematic shift in the underlying composition of user groups and use cases.\n\nWe show the distribution of topics by usage context in Figure 5. For personal use, productivity and media together account for  $62\\%$  of all agentic queries. For professional use,  $80\\%$  of agentic queries are productivity- and career-related. Educational usage is dominated by learning, comprising  $89\\%$  of agentic queries. We also show the distribution of subtopic, task, and environment by usage context in Tables 26, 27, and 28 in Appendix A. The top subtopics for personal, professional, and educational use are goods shopping, document editing, and courses, respectively. The top environments for personal, professional, and educational use are emails, linkedin.com, and docs.google.com, respectively.\n\nFigure 5: Topic Distribution by Usage Context\n![img-6.jpeg](img-6.jpeg)\nNote: The plot shows the percentage shares of topics within each usage context. The \"Other\" category is removed from contexts. Bar width is proportional to context percentage, and box height within each bar is proportional to topic percentage. The labels for topics that account for less than  $5\\%$  within a context are suppressed. Context shares are shown in the x-axis labels. The same topic is shown in the same color across contexts. The topic percentage overall is shown as a baseline for comparison. The topics within each context are sorted in the same order as the overall for easier comparison across contexts. The topics in the overall category are sorted by topic percentage, from highest to lowest.",
      "blocks": [],
      "tables": [],
      "images": [
        {
          "id": "img-6.jpeg",
          "top_left_x": 200,
          "top_left_y": 1045,
          "bottom_right_x": 1475,
          "bottom_right_y": 1687,
          "image_base64": null,
          "image_annotation": null
        }
      ],
      "hyperlinks": []
    },
    {
      "page_number": 22,
      "width": 1700,
      "height": 2200,
      "text": "6 Discussion Our paper provides the first systematic evidence on the adoption, usage intensity, and use cases of general-purpose AI agents, based on large-scale behavioral data from Comet by Perplexity. Our findings reveal substantial differences in the propensity to adopt and use the agent across user segments. Earlier adopters, users in countries with higher GDP per capita and higher average years of education, and individuals working in more digital or knowledge-intensive fields—such as digital technology, academia, finance, marketing, and entrepreneurship—tend to adopt and use the agent more actively. Agent use cases span a broad range of categories. The two largest topics—productivity and learning—together comprise 57% of all agentic queries. The two largest subtopics—courses and goods shopping—together account for 22% of all agentic queries. The top 10 out of 90 tasks represent 55% of all agentic queries. We also document heterogeneity in use cases across occupation clusters, reflecting the degree to which they align with each occupation’s task composition. Topics such as productivity, learning, and career exhibit higher stickiness, as users are more likely to make consecutive queries within these categories. Over time, users also shift toward more cognitively oriented tasks. In addition, the environments in which agentic queries are made show significant variation in concentration across topics and subtopics. Although our paper is primarily descriptive and does not make normative claims or directly examine downstream impacts, its methods and findings offer valuable implications for researchers, businesses, policymakers, and educators. For researchers, we contribute to a nascent but rapidly expanding literature on the adoption and usage of LLMs and AI agents, and our agentic taxonomy provides a structure for future analysis to build on and extend. For firms developing AI agents, our results offer guidance on target user segments and high-frequency use cases. For businesses that provide the environments in which agents operate, our findings suggest opportunities to streamline interfaces to better serve users interacting with AI agents. For both policymakers and educators, a central concern is that uneven adoption and usage of AI agents could exacerbate existing productivity and learning disparities. Consequently, equipping citizens and students with the skills to leverage AI agents effectively and preparing them for a near future in which such agents are embedded in work and everyday life will become increasingly important. We note a few important caveats of our dataset. First, because Comet is a new product, our sample primarily reflects early adopters, who may skew toward more tech-savvy users. We characterize these early adopters using an internal survey in Appendix C. Relatedly, given the short time span of our data, we do not systematically investigate changes in usage patterns over time, and any longitudinal results should be interpreted within this context. Second, the classification of an agentic query depends on internal query understanding modules that trigger the agent based on predicted query intent. These intent predictors show high prediction accuracy in internal validation studies; nonetheless, the data may include both false positives (when a non-agentic intent triggers the agent) and false negatives (when an agentic intent does not trigger the agent).",
      "markdown": "6 Discussion\n\nOur paper provides the first systematic evidence on the adoption, usage intensity, and use cases of general-purpose AI agents, based on large-scale behavioral data from Comet by Perplexity. Our findings reveal substantial differences in the propensity to adopt and use the agent across user segments. Earlier adopters, users in countries with higher GDP per capita and higher average years of education, and individuals working in more digital or knowledge-intensive fields—such as digital technology, academia, finance, marketing, and entrepreneurship—tend to adopt and use the agent more actively. Agent use cases span a broad range of categories. The two largest topics—productivity and learning—together comprise 57% of all agentic queries. The two largest subtopics—courses and goods shopping—together account for 22% of all agentic queries. The top 10 out of 90 tasks represent 55% of all agentic queries. We also document heterogeneity in use cases across occupation clusters, reflecting the degree to which they align with each occupation’s task composition. Topics such as productivity, learning, and career exhibit higher stickiness, as users are more likely to make consecutive queries within these categories. Over time, users also shift toward more cognitively oriented tasks. In addition, the environments in which agentic queries are made show significant variation in concentration across topics and subtopics.\n\nAlthough our paper is primarily descriptive and does not make normative claims or directly examine downstream impacts, its methods and findings offer valuable implications for researchers, businesses, policymakers, and educators. For researchers, we contribute to a nascent but rapidly expanding literature on the adoption and usage of LLMs and AI agents, and our agentic taxonomy provides a structure for future analysis to build on and extend. For firms developing AI agents, our results offer guidance on target user segments and high-frequency use cases. For businesses that provide the environments in which agents operate, our findings suggest opportunities to streamline interfaces to better serve users interacting with AI agents. For both policymakers and educators, a central concern is that uneven adoption and usage of AI agents could exacerbate existing productivity and learning disparities. Consequently, equipping citizens and students with the skills to leverage AI agents effectively and preparing them for a near future in which such agents are embedded in work and everyday life will become increasingly important.\n\nWe note a few important caveats of our dataset. First, because Comet is a new product, our sample primarily reflects early adopters, who may skew toward more tech-savvy users. We characterize these early adopters using an internal survey in Appendix C. Relatedly, given the short time span of our data, we do not systematically investigate changes in usage patterns over time, and any longitudinal results should be interpreted within this context. Second, the classification of an agentic query depends on internal query understanding modules that trigger the agent based on predicted query intent. These intent predictors show high prediction accuracy in internal validation studies; nonetheless, the data may include both false positives (when a non-agentic intent triggers the agent) and false negatives (when an agentic intent does not trigger the agent).",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 23,
      "width": 1700,
      "height": 2200,
      "text": "Similarly, the classification into our agentic taxonomy, usage context, and occupation clusters also contains noise. Third, although AI agents’ autonomy and task horizons continue to expand, our results should not be interpreted as suggesting any particular balance between automation and augmentation in use cases. For instance, an agentic session may appear to be automation, but users may break a task into smaller pieces and delegate only some subtasks to the agent, which is closer to an augmentation case. A comprehensive treatment on such a topic would require having a complete picture of how users manage their workflows outside of Comet. There are several natural extensions to this study that we aim to pursue. First, with the expansion of Comet to mobile devices and other environments, it will be valuable to document cross-platform differences in how users interact with AI agents. In particular, whereas agentic queries on desktops are predominantly text-based, the voice-to-voice mode on mobile may offer a more natural interface. Second, while our sample does not capture enterprise users directly, the substantial share of professionally-oriented agentic queries suggests the need for complementary research on related topics in organizational settings. Third, the adoption and usage of AI agents is closely tied to their performance across tasks; we plan to investigate agent evaluation, common failure modes, and strategies for improvement. Fourth, identifying which tasks are best suited for delegation to the agent and designing optimal human-agent collaborative workflows are also important questions. For example, tasks that users can easily complete manually may not warrant delegation. High-stakes or irreversible tasks might require exceptionally reliable agent performance, a high degree of user trust, and increased human supervision. Fifth, in addition to awareness and performance, another key barrier to adoption and use is measuring and substantiating value and impact; we seek to quantify the economic value users derive from agent use, an essential dimension of the downstream impact of AI agents. General-purpose AI agents represent one of the most consequential technological advancements of our time. Understanding their real-world adoption and usage with large-scale behavioral data has become both urgent and essential for informing their development and deployment. We hope this work catalyzes further investigation in this rapidly evolving domain.",
      "markdown": "Similarly, the classification into our agentic taxonomy, usage context, and occupation clusters also contains noise. Third, although AI agents’ autonomy and task horizons continue to expand, our results should not be interpreted as suggesting any particular balance between automation and augmentation in use cases. For instance, an agentic session may appear to be automation, but users may break a task into smaller pieces and delegate only some subtasks to the agent, which is closer to an augmentation case. A comprehensive treatment on such a topic would require having a complete picture of how users manage their workflows outside of Comet.\n\nThere are several natural extensions to this study that we aim to pursue. First, with the expansion of Comet to mobile devices and other environments, it will be valuable to document cross-platform differences in how users interact with AI agents. In particular, whereas agentic queries on desktops are predominantly text-based, the voice-to-voice mode on mobile may offer a more natural interface. Second, while our sample does not capture enterprise users directly, the substantial share of professionally-oriented agentic queries suggests the need for complementary research on related topics in organizational settings. Third, the adoption and usage of AI agents is closely tied to their performance across tasks; we plan to investigate agent evaluation, common failure modes, and strategies for improvement. Fourth, identifying which tasks are best suited for delegation to the agent and designing optimal human-agent collaborative workflows are also important questions. For example, tasks that users can easily complete manually may not warrant delegation. High-stakes or irreversible tasks might require exceptionally reliable agent performance, a high degree of user trust, and increased human supervision. Fifth, in addition to awareness and performance, another key barrier to adoption and use is measuring and substantiating value and impact; we seek to quantify the economic value users derive from agent use, an essential dimension of the downstream impact of AI agents.\n\nGeneral-purpose AI agents represent one of the most consequential technological advancements of our time. Understanding their real-world adoption and usage with large-scale behavioral data has become both urgent and essential for informing their development and deployment. We hope this work catalyzes further investigation in this rapidly evolving domain.\n\n##",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": [
        "https://www.perplexity.ai/hub/blog/comet-for-android-is-here"
      ]
    },
    {
      "page_number": 24,
      "width": 1700,
      "height": 2200,
      "text": "References - Allowah et al. [2025] Allowah, O. Besbes, J. D. Figueroa, Y. Kanoria, and A. Kumar. What Is Your AI Agent Buying? Evaluation, Implications, and Emerging Questions for Agentic E-Commerce. arXiv preprint arXiv:2508.02630, 2025. - Anthropic [2025] Anthropic. Project Vend: Can Claude Run a Small Shop? (And Why Does That Matter?), 2025a. URL https://www.anthropic.com/research/project-vend-1. - Anthropic [2025b] Anthropic Economic Index: AI’s Impact on Software Development, 2025b. URL https://www.anthropic.com/research/impact-software-development. - Appel et al. [2025] R. Appel, P. McCrory, A. Tamkin, M. Stern, M. McCain, and T. Neylon. Anthropic Economic Index Report: Uneven Geographic and Enterprise AI Adoption, 2025. URL www.anthropic.com/research/anthropic-economic-index-september-2025-report. - Aubakirova et al. [2025] M. Aubakirova, A. Atallah, J. Summerville, and A. Midha. State of AI: An Empirical 100 Trillion Token Study with OpenRouter. Technical report, OpenRouter, 2025. - Bent et al. [2025] D. Bent, K. Handa, E. Durmus, A. Tamkin, M. McCain, S. Ritchie, R. Donegan, J. Martinez, and J. Jones. Anthropic Education Report: How Educators Use Claude, 2025. URL https://www.anthropic.com/news/anthropic-education-report-how-educators-use-claude. - Bick et al. [2024] A. Bick, A. Blandin, and D. J. Deming. The Rapid Adoption of Generative AI. Technical report, National Bureau of Economic Research, 2024. - Brynjolfsson et al. [2025] E. Brynjolfsson, D. Li, and L. Raymond. Generative AI at Work. The Quarterly Journal of Economics, 140(2):889–942, 2025. - Chatterji et al. [2025] A. Chatterji, T. Cunningham, D. J. Deming, Z. Hitzig, C. Ong, C. Y. Shan, and K. Wadman. How People Use ChatGPT. Technical report, National Bureau of Economic Research, 2025. - Cui et al. [2025] Z. K. Cui, M. Demirer, S. Jaffe, L. Musolff, S. Peng, and T. Salz. The Effects of Generative AI on High-Skilled Work: Evidence from Three Field Experiments with Software Developers. Available at SSRN 4945566, 2025. - Dell’Acqua et al. [2023] F. Dell’Acqua, E. McFowland III, E. R. Mollick, H. Lifshitz-Assaf, K. Kellogg, S. Rajendran, L. Krayer, F. Candelon, and K. R. Lakhani. Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality. Harvard Business School Technology & Operations Mgt. Unit Working Paper, (24-013), 2023. - Hadfield and Koh [2025] G. K. Hadfield and A. Koh. An Economy of AI Agents. arXiv preprint arXiv:2509.01063, 2025. - Handa et al. [2025] K. Handa, D. Bent, A. Tamkin, M. McCain, E. Durmus, M. Stern, M. Schiraldi, S. Huang, S. Ritchie, S. Syverud, K. Jagadish, M. Vo, M. Bell, and D. Ganguli. Anthropic Education Report: How University Students Use Claude, 2025a. URL https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude. -",
      "markdown": "References\n\n- Allowah et al. [2025] Allowah, O. Besbes, J. D. Figueroa, Y. Kanoria, and A. Kumar. What Is Your AI Agent Buying? Evaluation, Implications, and Emerging Questions for Agentic E-Commerce. arXiv preprint arXiv:2508.02630, 2025.\n- Anthropic [2025] Anthropic. Project Vend: Can Claude Run a Small Shop? (And Why Does That Matter?), 2025a. URL https://www.anthropic.com/research/project-vend-1.\n- Anthropic [2025b] Anthropic Economic Index: AI’s Impact on Software Development, 2025b. URL https://www.anthropic.com/research/impact-software-development.\n- Appel et al. [2025] R. Appel, P. McCrory, A. Tamkin, M. Stern, M. McCain, and T. Neylon. Anthropic Economic Index Report: Uneven Geographic and Enterprise AI Adoption, 2025. URL www.anthropic.com/research/anthropic-economic-index-september-2025-report.\n- Aubakirova et al. [2025] M. Aubakirova, A. Atallah, J. Summerville, and A. Midha. State of AI: An Empirical 100 Trillion Token Study with OpenRouter. Technical report, OpenRouter, 2025.\n- Bent et al. [2025] D. Bent, K. Handa, E. Durmus, A. Tamkin, M. McCain, S. Ritchie, R. Donegan, J. Martinez, and J. Jones. Anthropic Education Report: How Educators Use Claude, 2025. URL https://www.anthropic.com/news/anthropic-education-report-how-educators-use-claude.\n- Bick et al. [2024] A. Bick, A. Blandin, and D. J. Deming. The Rapid Adoption of Generative AI. Technical report, National Bureau of Economic Research, 2024.\n- Brynjolfsson et al. [2025] E. Brynjolfsson, D. Li, and L. Raymond. Generative AI at Work. The Quarterly Journal of Economics, 140(2):889–942, 2025.\n- Chatterji et al. [2025] A. Chatterji, T. Cunningham, D. J. Deming, Z. Hitzig, C. Ong, C. Y. Shan, and K. Wadman. How People Use ChatGPT. Technical report, National Bureau of Economic Research, 2025.\n- Cui et al. [2025] Z. K. Cui, M. Demirer, S. Jaffe, L. Musolff, S. Peng, and T. Salz. The Effects of Generative AI on High-Skilled Work: Evidence from Three Field Experiments with Software Developers. Available at SSRN 4945566, 2025.\n- Dell’Acqua et al. [2023] F. Dell’Acqua, E. McFowland III, E. R. Mollick, H. Lifshitz-Assaf, K. Kellogg, S. Rajendran, L. Krayer, F. Candelon, and K. R. Lakhani. Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality. Harvard Business School Technology & Operations Mgt. Unit Working Paper, (24-013), 2023.\n- Hadfield and Koh [2025] G. K. Hadfield and A. Koh. An Economy of AI Agents. arXiv preprint arXiv:2509.01063, 2025.\n- Handa et al. [2025] K. Handa, D. Bent, A. Tamkin, M. McCain, E. Durmus, M. Stern, M. Schiraldi, S. Huang, S. Ritchie, S. Syverud, K. Jagadish, M. Vo, M. Bell, and D. Ganguli. Anthropic Education Report: How University Students Use Claude, 2025a. URL https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude.\n-",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": [
        "https://www.anthropic.com/research/project-vend-1",
        "https://www.anthropic.com/research/impact-software-development",
        "https://www.anthropic.com/news/anthropic-education-report-how-educators-use-claude",
        "https://www.anthropic.com/news/anthropic-education-report-how-educators-use-claude",
        "https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude",
        "https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude"
      ]
    },
    {
      "page_number": 25,
      "width": 1700,
      "height": 2200,
      "text": "K. Handa, M. Stern, S. Huang, J. Hong, E. Durmus, M. McCain, G. Yun, A. Alt, T. Millar, A. Tamkin, J. Leibrock, S. Ritchie, and D. Ganguli. Introducing Anthropic Interviewer: What 1,250 Professionals Told Us About Working with AI, 2025b. URL https://anthropic.com/research/anthropic-interviewer. - K. Handa, A. Tamkin, M. McCain, S. Huang, E. Durmus, S. Heck, J. Mueller, J. Hong, S. Ritchie, T. Belonax, et al. Which Economic Tasks Are Performed with AI? Evidence from Millions of Claude Conversations. arXiv preprint arXiv:2503.04761, 2025c. - A. Humlum and E. Vestergaard. The Unequal Adoption of ChatGPT Exacerbates Existing Inequalities Among Workers. Proceedings of the National Academy of Sciences, 122(1): e2414972121, 2025. - H. Ju and S. Aral. Collaborating with AI Agents: Field Experiments on Teamwork, Productivity, and Performance. arXiv preprint arXiv:2503.18238, 2025. - A. Merali. Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Translation. arXiv preprint arXiv:2409.02391, 2024. - G. A. Moore. Crossing the Chasm: Marketing and Selling High-Tech Products to Mainstream Customers. HarperBusiness, New York, 1991. - S. Noy and W. Zhang. Experimental Evidence on the Productivity Effects of Generative Artificial Intelligence. Science, 381(6654):187–192, 2023. - M. Z. Pan, N. Arabzadeh, R. Cogo, Y. Zhu, A. Xiong, L. A. Agrawal, H. Mao, E. Shen, S. Pallerla, L. Patel, et al. Measuring Agents in Production. arXiv preprint arXiv:2512.04123, 2025. - S. Peng, E. Kalliamvakou, P. Cihon, and M. Demirer. The Impact of AI on Developer Productivity: Evidence from GitHub Copilot. arXiv preprint arXiv:2302.06590, 2023. - Perplexity Team. Agents or Bots? Making Sense of AI on the Open Web, 2025. URL https://www.perplexity.ai/hub/blog/agents-or-bots-making-sense-of-ai-on-the-open-web. - D. M. Rothschild, M. Mobius, J. M. Hofman, E. W. Dillon, D. G. Goldstein, N. Immorlica, S. Jaffe, B. Lucier, A. Slivkins, and M. Vogel. The Agentic Economy. arXiv preprint arXiv:2505.15799, 2025. - S. K. Sarkar. AI Agents, Productivity, and Higher-Order Thinking: Early Evidence from Software Development. Available at SSRN 5713646, 2025. - E. Schluntz and B. Zhang. Building Effective Agents, 2024. URL https://www.anthropic.com/engineering/building-effective-agents. - P. Shahidi, G. Rusak, B. S. Manning, A. Fradkin, and J. J. Horton. The Coasean Singularity? Demand, Supply, and Market Design with AI Agents. Technical report, National Bureau of Economic Research, 2025.",
      "markdown": "K. Handa, M. Stern, S. Huang, J. Hong, E. Durmus, M. McCain, G. Yun, A. Alt, T. Millar, A. Tamkin, J. Leibrock, S. Ritchie, and D. Ganguli. Introducing Anthropic Interviewer: What 1,250 Professionals Told Us About Working with AI, 2025b. URL https://anthropic.com/research/anthropic-interviewer.\n- K. Handa, A. Tamkin, M. McCain, S. Huang, E. Durmus, S. Heck, J. Mueller, J. Hong, S. Ritchie, T. Belonax, et al. Which Economic Tasks Are Performed with AI? Evidence from Millions of Claude Conversations. arXiv preprint arXiv:2503.04761, 2025c.\n- A. Humlum and E. Vestergaard. The Unequal Adoption of ChatGPT Exacerbates Existing Inequalities Among Workers. Proceedings of the National Academy of Sciences, 122(1): e2414972121, 2025.\n- H. Ju and S. Aral. Collaborating with AI Agents: Field Experiments on Teamwork, Productivity, and Performance. arXiv preprint arXiv:2503.18238, 2025.\n- A. Merali. Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Translation. arXiv preprint arXiv:2409.02391, 2024.\n- G. A. Moore. Crossing the Chasm: Marketing and Selling High-Tech Products to Mainstream Customers. HarperBusiness, New York, 1991.\n- S. Noy and W. Zhang. Experimental Evidence on the Productivity Effects of Generative Artificial Intelligence. Science, 381(6654):187–192, 2023.\n- M. Z. Pan, N. Arabzadeh, R. Cogo, Y. Zhu, A. Xiong, L. A. Agrawal, H. Mao, E. Shen, S. Pallerla, L. Patel, et al. Measuring Agents in Production. arXiv preprint arXiv:2512.04123, 2025.\n- S. Peng, E. Kalliamvakou, P. Cihon, and M. Demirer. The Impact of AI on Developer Productivity: Evidence from GitHub Copilot. arXiv preprint arXiv:2302.06590, 2023.\n- Perplexity Team. Agents or Bots? Making Sense of AI on the Open Web, 2025. URL https://www.perplexity.ai/hub/blog/agents-or-bots-making-sense-of-ai-on-the-open-web.\n- D. M. Rothschild, M. Mobius, J. M. Hofman, E. W. Dillon, D. G. Goldstein, N. Immorlica, S. Jaffe, B. Lucier, A. Slivkins, and M. Vogel. The Agentic Economy. arXiv preprint arXiv:2505.15799, 2025.\n- S. K. Sarkar. AI Agents, Productivity, and Higher-Order Thinking: Early Evidence from Software Development. Available at SSRN 5713646, 2025.\n- E. Schluntz and B. Zhang. Building Effective Agents, 2024. URL https://www.anthropic.com/engineering/building-effective-agents.\n- P. Shahidi, G. Rusak, B. S. Manning, A. Fradkin, and J. J. Horton. The Coasean Singularity? Demand, Supply, and Market Design with AI Agents. Technical report, National Bureau of Economic Research, 2025.",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": [
        "https://anthropic.com/research/anthropic-interviewer",
        "https://anthropic.com/research/anthropic-interviewer",
        "https://www.perplexity.ai/hub/blog/agents-or-bots-making-sense-of-ai-on-the-open-web",
        "https://www.perplexity.ai/hub/blog/agents-or-bots-making-sense-of-ai-on-the-open-web",
        "https://www.anthropic.com/engineering/building-effective-agents",
        "https://www.anthropic.com/engineering/building-effective-agents"
      ]
    },
    {
      "page_number": 26,
      "width": 1700,
      "height": 2200,
      "text": "Y. Shavit, S. Agarwal, M. Brundage, S. Adler, C. O’Keefe, R. Campbell, T. Lee, P. Mishkin, T. Eloundou, A. Hickey, et al. Practices for Governing Agentic AI Systems. Research Paper, OpenAI, 2023. L. Vendraminelli, M. DosSantos DiSorbo, A. Hildebrandt, E. McFowland III, A. Karunakaran, and I. Bojinov. The GenAI Wall Effect: Examining the Limits to Horizontal Expertise Transfer Between Occupational Insiders and Outsiders. Harvard Business School Technology &amp; Operations Mgt. Unit Working Paper, (26-011):26–011, 2025. E. Wiles, L. Krayer, M. Abbadi, U. Awasthi, R. Kennedy, P. Mishkin, D. Sack, and F. Candelon. Genai as an exoskeleton: Experimental evidence on knowledge workers using genai on new skills. Available at SSRN 4944588, 2024. M. Wooldridge and N. R. Jennings. Intelligent Agents: Theory and Practice. The Knowledge Engineering Review, 10(2):115–152, 1995. S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, and Y. Cao. ReAct: Synergizing Reasoning and Acting in Language Models. In The Eleventh International Conference on Learning Representations, 2022. W. Zhao, X. Ren, J. Hessel, C. Cardie, Y. Choi, and Y. Deng. WildChat: 1M ChatGPT Interaction Logs in the Wild. arXiv preprint arXiv:2405.01470, 2024.",
      "markdown": "Y. Shavit, S. Agarwal, M. Brundage, S. Adler, C. O’Keefe, R. Campbell, T. Lee, P. Mishkin, T. Eloundou, A. Hickey, et al. Practices for Governing Agentic AI Systems. Research Paper, OpenAI, 2023.\n\nL. Vendraminelli, M. DosSantos DiSorbo, A. Hildebrandt, E. McFowland III, A. Karunakaran, and I. Bojinov. The GenAI Wall Effect: Examining the Limits to Horizontal Expertise Transfer Between Occupational Insiders and Outsiders. Harvard Business School Technology &amp; Operations Mgt. Unit Working Paper, (26-011):26–011, 2025.\n\nE. Wiles, L. Krayer, M. Abbadi, U. Awasthi, R. Kennedy, P. Mishkin, D. Sack, and F. Candelon. Genai as an exoskeleton: Experimental evidence on knowledge workers using genai on new skills. Available at SSRN 4944588, 2024.\n\nM. Wooldridge and N. R. Jennings. Intelligent Agents: Theory and Practice. The Knowledge Engineering Review, 10(2):115–152, 1995.\n\nS. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, and Y. Cao. ReAct: Synergizing Reasoning and Acting in Language Models. In The Eleventh International Conference on Learning Representations, 2022.\n\nW. Zhao, X. Ren, J. Hessel, C. Cardie, Y. Choi, and Y. Deng. WildChat: 1M ChatGPT Interaction Logs in the Wild. arXiv preprint arXiv:2405.01470, 2024.",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 27,
      "width": 1700,
      "height": 2200,
      "text": "Appendices A Figures and Tables A.1 Adoption and Usage Intensity !img-7.jpeg (a) Cumulative Agent Adopter !img-8.jpeg (b) Cumulative Agentic Query Figure 6: Cumulative Agent Adopter and Agentic Query Note: The plots show the cumulative number of agent adopters and agentic queries. The exact numbers on the y-axis are masked, and the percentages show the relative magnitude of adopters and queries relative to the end date as the baseline. Adopter and query numbers grow steadily over time with a noticeable jump when Comet became generally available. The three dashed vertical lines mark the dates for the change in access. July 9: launch date and open to Max subscribers and selected users on a waitlist. August 13: extended access to Pro subscribers. October 2: extended access to everyone worldwide.",
      "markdown": "# Appendices\n\n# A Figures and Tables\n\n# A.1 Adoption and Usage Intensity\n\n![img-7.jpeg](img-7.jpeg)\n(a) Cumulative Agent Adopter\n\n![img-8.jpeg](img-8.jpeg)\n(b) Cumulative Agentic Query\nFigure 6: Cumulative Agent Adopter and Agentic Query\n\nNote: The plots show the cumulative number of agent adopters and agentic queries. The exact numbers on the y-axis are masked, and the percentages show the relative magnitude of adopters and queries relative to the end date as the baseline. Adopter and query numbers grow steadily over time with a noticeable jump when Comet became generally available. The three dashed vertical lines mark the dates for the change in access. July 9: launch date and open to Max subscribers and selected users on a waitlist. August 13: extended access to Pro subscribers. October 2: extended access to everyone worldwide.",
      "blocks": [],
      "tables": [],
      "images": [
        {
          "id": "img-7.jpeg",
          "top_left_x": 329,
          "top_left_y": 611,
          "bottom_right_x": 1341,
          "bottom_right_y": 1100,
          "image_base64": null,
          "image_annotation": null
        },
        {
          "id": "img-8.jpeg",
          "top_left_x": 329,
          "top_left_y": 1210,
          "bottom_right_x": 1341,
          "bottom_right_y": 1696,
          "image_base64": null,
          "image_annotation": null
        }
      ],
      "hyperlinks": []
    },
    {
      "page_number": 28,
      "width": 1700,
      "height": 2200,
      "text": "tbl-7.md Note: The tables show the top 10 O*NET occupation subclusters by adoption. The \"Other\" category is removed. When a user appears in multiple subclusters, their data is used in all relevant subclusters. User share is the number of users in each subcluster divided by the total users. Agent adopter share is the number of adopters in each subcluster, divided by the total number of adopters. AAR (Agent Adoption Ratio) is the ratio between agent adopter share and user share. AAR greater (less) than 1 indicates that a subcluster is over-represented (under-represented) in agent adoption relative to their user base. AAR rank is among the subclusters with a user share over $1\\%$ .",
      "markdown": "[tbl-7.md](tbl-7.md)\n\nNote: The tables show the top 10 O*NET occupation subclusters by adoption. The \"Other\" category is removed. When a user appears in multiple subclusters, their data is used in all relevant subclusters. User share is the number of users in each subcluster divided by the total users. Agent adopter share is the number of adopters in each subcluster, divided by the total number of adopters. AAR (Agent Adoption Ratio) is the ratio between agent adopter share and user share. AAR greater (less) than 1 indicates that a subcluster is over-represented (under-represented) in agent adoption relative to their user base. AAR rank is among the subclusters with a user share over  $1\\%$ .",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-7.md",
          "format": "markdown",
          "content": "|  Agent Adoption by Occupation Subcluster: The Top 10 Subclusters by Agent Adoption Share  |   |   |   |   |\n| --- | --- | --- | --- | --- |\n|  Cluster | Subcluster | User Share (%) | Agent Adopter Share (%) | AAR  |\n|  Digital Technology | Software Development & Engineering | 13.0 | 13.9 | 1.07  |\n|  Marketing & Sales | Digital Marketing & Social Media | 3.9 | 4.7 | 1.21  |\n|  Digital Technology | IT Support & Infrastructure | 4.0 | 4.3 | 1.08  |\n|  Arts, Entertainment, & Design | Design & Digital Arts | 5.0 | 4.3 | 0.86  |\n|  Financial Services | Financial Planning & Analysis | 4.1 | 4.3 | 1.05  |\n|  Digital Technology | Data Science & AI | 3.9 | 4.0 | 1.03  |\n|  Education | Teaching & Instruction | 4.9 | 4.0 | 0.82  |\n|  Financial Services | Financial Strategy & Investments | 3.8 | 3.9 | 1.03  |\n|  Management & Entrepreneurship | Business Information Management | 3.2 | 3.8 | 1.19  |\n|  Management & Entrepreneurship | Leadership & Operations | 2.6 | 3.1 | 1.19  |\n|  Agent Adoption by Occupation Subcluster: The Top 10 Subclusters by AAR  |   |   |   |   |\n|  Cluster | Subcluster | User Share (%) | Agent Adopter Share (%) | AAR  |\n|  Marketing & Sales | Business Development & Sales | 1.2 | 1.6 | 1.33  |\n|  Marketing & Sales | Digital Marketing & Social Media | 3.9 | 4.7 | 1.21  |\n|  Management & Entrepreneurship | Business Information Management | 3.2 | 3.8 | 1.19  |\n|  Management & Entrepreneurship | Leadership & Operations | 2.6 | 3.1 | 1.19  |\n|  Marketing & Sales | Market Research, Analytics, & Ethics | 1.1 | 1.3 | 1.18  |\n|  Management & Entrepreneurship | Strategy & Consulting | 2.2 | 2.5 | 1.14  |\n|  Supply Chain & Transportation | Planning & Logistics | 1.1 | 1.2 | 1.09  |\n|  Digital Technology | IT Support & Infrastructure | 4.0 | 4.3 | 1.08  |\n|  Digital Technology | Software Development & Engineering | 13.0 | 13.9 | 1.07  |\n|  Marketing & Sales | Brand Management & Strategy | 1.4 | 1.5 | 1.07  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 29,
      "width": 1700,
      "height": 2200,
      "text": "tbl-8.md Note: The tables show the top 10 O*NET occupation subclusters by usage intensity. The \"Other\" category is removed. When a user appears in multiple subclusters, their data is used in all relevant subclusters. User share is the number of users in each subcluster divided by the total users. Agent query share is the number of agentic queries in each subcluster divided by the total agentic queries. AUR (Agent Usage Ratio) is the ratio between agentic query share and user share. AUR greater (less) than 1 indicates that a subcluster is over-represented (under-represented) in agent usage relative to their user base. AUR rank is among the subclusters with a user share over $1\\%$ .",
      "markdown": "[tbl-8.md](tbl-8.md)\n\nNote: The tables show the top 10 O*NET occupation subclusters by usage intensity. The \"Other\" category is removed. When a user appears in multiple subclusters, their data is used in all relevant subclusters. User share is the number of users in each subcluster divided by the total users. Agent query share is the number of agentic queries in each subcluster divided by the total agentic queries. AUR (Agent Usage Ratio) is the ratio between agentic query share and user share. AUR greater (less) than 1 indicates that a subcluster is over-represented (under-represented) in agent usage relative to their user base. AUR rank is among the subclusters with a user share over  $1\\%$ .",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-8.md",
          "format": "markdown",
          "content": "|  Agentic Query by Occupation Subcluster: The Top 10 Subclusters by Agentic Query Share  |   |   |   |   |\n| --- | --- | --- | --- | --- |\n|  Cluster | Subcluster | User Share (%) | Agentic Query Share (%) | AUR  |\n|  Digital Technology | Software Development & Engineering | 13.0 | 15.4 | 1.18  |\n|  Marketing & Sales | Digital Marketing & Social Media | 3.9 | 5.9 | 1.51  |\n|  Digital Technology | IT Support & Infrastructure | 4.0 | 5.3 | 1.32  |\n|  Management & Entrepreneurship | Business Information Management | 3.2 | 4.7 | 1.47  |\n|  Financial Services | Financial Planning & Analysis | 4.1 | 3.9 | 1.05  |\n|  Digital Technology | Data Science & AI | 3.9 | 3.9 | 1.00  |\n|  Management & Entrepreneurship | Leadership & Operations | 2.6 | 3.9 | 1.50  |\n|  Arts, Entertainment, & Design | Design & Digital Arts | 5.0 | 3.8 | 0.76  |\n|  Education | Teaching & Instruction | 4.9 | 3.6 | 0.73  |\n|  Financial Services | Financial Strategy & Investments | 3.8 | 3.9 | 1.03  |\n|  Agentic Query by Occupation Subcluster: The Top 10 Subclusters by AUR  |   |   |   |   |\n|  Cluster | Subcluster | User Share (%) | Agentic Query Share (%) | AUR  |\n|  Marketing & Sales | Business Development & Sales | 1.2 | 2.1 | 1.75  |\n|  Marketing & Sales | Digital Marketing & Social Media | 3.9 | 5.9 | 1.51  |\n|  Management & Entrepreneurship | Leadership & Operations | 2.6 | 3.9 | 1.50  |\n|  Management & Entrepreneurship | Business Information Management | 3.2 | 4.7 | 1.47  |\n|  Marketing & Sales | Brand Management & Strategy | 1.4 | 1.9 | 1.36  |\n|  Management & Entrepreneurship | Strategy & Consulting | 2.2 | 3.0 | 1.36  |\n|  Digital Technology | IT Support & Infrastructure | 4.0 | 5.3 | 1.32  |\n|  Marketing & Sales | Market Research, Analytics, & Ethics | 1.1 | 1.4 | 1.27  |\n|  Digital Technology | Software Development & Engineering | 13.0 | 15.4 | 1.18  |\n|  Supply Chain & Transportation | Planning & Logistics | 1.1 | 1.1 | 1.00  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 30,
      "width": 1700,
      "height": 2200,
      "text": "A.2 Use Cases A.2.1 Topics and Subtopics tbl-9.md Note: The table shows the distribution of topics and subtopics. The topic percentage $(P(\\text{Topic}))$ is the topic's share among all agentic queries. Subtopic percentage $(P(\\text{Subtopic} \\mid \\text{Topic}))$ is the percentage of a subtopic within a topic. Overall percentage $(P(\\text{Subtopic}) = P(\\text{Topic}, \\text{Subtopic}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}))$ is the subtopic share among all agentic queries. Percentages may not sum to $100\\%$ due to rounding. Table 10: Topic and Subtopic Distribution",
      "markdown": "# A.2 Use Cases\n\n# A.2.1 Topics and Subtopics\n\n[tbl-9.md](tbl-9.md)\n\nNote: The table shows the distribution of topics and subtopics. The topic percentage  $(P(\\text{Topic}))$  is the topic's share among all agentic queries. Subtopic percentage  $(P(\\text{Subtopic} \\mid \\text{Topic}))$  is the percentage of a subtopic within a topic. Overall percentage  $(P(\\text{Subtopic}) = P(\\text{Topic}, \\text{Subtopic}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}))$  is the subtopic share among all agentic queries. Percentages may not sum to  $100\\%$  due to rounding.\n\nTable 10: Topic and Subtopic Distribution",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-9.md",
          "format": "markdown",
          "content": "|  Topic | Topic (%) | Subtopic | Subtopic (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Productivity & Workflow | 36.2 | Document & Form Editing | 21.5 | 7.78  |\n|   |   |  Account Management | 20.5 | 7.43  |\n|   |   |  Email Management | 15.8 | 5.73  |\n|   |   |  Spreadsheet & Data Editing | 11.1 | 4.01  |\n|   |   |  Computer Programming | 10.3 | 3.73  |\n|   |   |  Investments & Banking | 6.2 | 2.25  |\n|   |   |  Multimedia Editing | 6.1 | 2.22  |\n|   |   |  Project Management | 5.1 | 1.85  |\n|   |   |  Calendar Management | 2.5 | 0.91  |\n|   |   |  Other | 0.8 | 0.30  |\n|  Learning & Research | 20.8 | Courses | 61.9 | 12.86  |\n|   |   |  Research | 37.9 | 7.88  |\n|   |   |  Other | 0.2 | 0.04  |\n|  Media & Entertainment | 15.8 | Social Media & Messaging | 42.4 | 6.69  |\n|   |   |  Movies, TV, & Videos | 20.1 | 3.17  |\n|   |   |  Online Games | 19.6 | 3.08  |\n|   |   |  Music & Podcasts | 10.7 | 1.68  |\n|   |   |  News | 3.8 | 0.59  |\n|   |   |  Sports | 2.7 | 0.42  |\n|   |   |  Other | 0.8 | 0.13  |\n|  Shopping & Commerce | 10.0 | Goods | 89.0 | 8.94  |\n|   |   |  Services | 10.3 | 1.03  |\n|   |   |  Other | 0.7 | 0.07  |\n|  Job & Career | 7.1 | Professional Networking | 50.1 | 3.56  |\n|   |   |  Job Search & Application | 49.5 | 3.52  |\n|   |   |  Other | 0.4 | 0.03  |\n|  Travel & Leisure | 6.7 | Flights & Transportation | 40.7 | 2.73  |\n|   |   |  Lodging | 27.3 | 1.83  |\n|   |   |  Trip Itineraries | 24.8 | 1.66  |\n|   |   |  Restaurants | 5.7 | 0.38  |\n|   |   |  Other | 1.5 | 0.10  |\n|  Other | 3.4 | Other | 100.0 | 3.42  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 31,
      "width": 1700,
      "height": 2200,
      "text": "!img-9.jpeg Note: The plot shows the transition matrix from the previous query to the following query, aggregated from the user level. Most query topics transition into themselves (the off-diagonal). Other than themselves, topics are most likely to transition into Productivity &amp; Workflow (the first column). Productivity &amp; Workflow, Learning &amp; Research, and Job &amp; Career are the most sticky with the highest self-transition probabilities. Whereas Travel &amp; Leisure is the least sticky, and Media &amp; Entertainment and Shopping &amp; Commerce are in between. The steady state probability distribution based on this transition matrix and the observed share are closely matched— $39\\%$ vs $37\\%$ respectively for Productivity &amp; Workflow, $24\\%$ vs $22\\%$ for Learning &amp; Research, $16\\%$ vs. $16\\%$ for Media &amp; Entertainment, $10\\%$ vs. $10\\%$ for Shopping &amp; Commerce, $7\\%$ vs $7\\%$ for Job &amp; Career, and $7\\%$ vs $7\\%$ for Travel &amp; Leisure. Note that to be aligned with the transition matrix, the observed shares used here do not include the \"Other\" category in Table 10; the shares used here are based on the topic shares in that table divided by 0.96. Figure 7: Topic Transition Matrix: Previous vs. Next Agentic Query",
      "markdown": "![img-9.jpeg](img-9.jpeg)\nNote: The plot shows the transition matrix from the previous query to the following query, aggregated from the user level. Most query topics transition into themselves (the off-diagonal). Other than themselves, topics are most likely to transition into Productivity &amp; Workflow (the first column). Productivity &amp; Workflow, Learning &amp; Research, and Job &amp; Career are the most sticky with the highest self-transition probabilities. Whereas Travel &amp; Leisure is the least sticky, and Media &amp; Entertainment and Shopping &amp; Commerce are in between. The steady state probability distribution based on this transition matrix and the observed share are closely matched— $39\\%$  vs  $37\\%$  respectively for Productivity &amp; Workflow,  $24\\%$  vs  $22\\%$  for Learning &amp; Research,  $16\\%$  vs.  $16\\%$  for Media &amp; Entertainment,  $10\\%$  vs.  $10\\%$  for Shopping &amp; Commerce,  $7\\%$  vs  $7\\%$  for Job &amp; Career, and  $7\\%$  vs  $7\\%$  for Travel &amp; Leisure. Note that to be aligned with the transition matrix, the observed shares used here do not include the \"Other\" category in Table 10; the shares used here are based on the topic shares in that table divided by 0.96.\nFigure 7: Topic Transition Matrix: Previous vs. Next Agentic Query",
      "blocks": [],
      "tables": [],
      "images": [
        {
          "id": "img-9.jpeg",
          "top_left_x": 263,
          "top_left_y": 528,
          "bottom_right_x": 1411,
          "bottom_right_y": 1524,
          "image_base64": null,
          "image_annotation": null
        }
      ],
      "hyperlinks": []
    },
    {
      "page_number": 32,
      "width": 1700,
      "height": 2200,
      "text": "Figure 8: Topic Distribution by First vs. All Agentic Queries !img-10.jpeg Note: The plot shows the distribution of topics among users' first agentic queries versus all agentic queries. Over time, the query shares are shifting from Travel &amp; Leisure, and Media &amp; Entertainment to Productivity &amp; Workflow, Learning &amp; Research, and Job &amp; Career. Shopping &amp; Commerce share stays relatively stable.",
      "markdown": "Figure 8: Topic Distribution by First vs. All Agentic Queries\n![img-10.jpeg](img-10.jpeg)\nNote: The plot shows the distribution of topics among users' first agentic queries versus all agentic queries. Over time, the query shares are shifting from Travel &amp; Leisure, and Media &amp; Entertainment to Productivity &amp; Workflow, Learning &amp; Research, and Job &amp; Career. Shopping &amp; Commerce share stays relatively stable.",
      "blocks": [],
      "tables": [],
      "images": [
        {
          "id": "img-10.jpeg",
          "top_left_x": 333,
          "top_left_y": 721,
          "bottom_right_x": 1337,
          "bottom_right_y": 1460,
          "image_base64": null,
          "image_annotation": null
        }
      ],
      "hyperlinks": []
    },
    {
      "page_number": 33,
      "width": 1700,
      "height": 2200,
      "text": "A.2.2 Tasks tbl-10.md Note: The table shows all tasks under Productivity &amp; Workflow with a share of more than $5\\%$ within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage $(P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$ is the task share within the subtopic. The overall percentage is the task share among all agentic queries. $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100. Table 11: Task Distribution for Productivity &amp; Workflow",
      "markdown": "# A.2.2 Tasks\n\n[tbl-10.md](tbl-10.md)\n\nNote: The table shows all tasks under Productivity &amp; Workflow with a share of more than  $5\\%$  within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage  $(P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$  is the task share within the subtopic. The overall percentage is the task share among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\n\nTable 11: Task Distribution for Productivity &amp; Workflow",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-10.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Task | Task (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Productivity & Workflow (36.2) | Document & Form Editing (21.5) | Create/edit documents/forms | 84.6 | 6.58  |\n|   |   |  Summarize/analyze documents/forms | 24.1 | 1.87  |\n|   |   |  Search/filter documents/forms | 11.4 | 0.89  |\n|   |  Account Management (20.5) | Manage settings/profiles | 58.3 | 4.33  |\n|   |   |  Register/log in to accounts | 31.2 | 2.32  |\n|   |   |  Summarize/analyze account information | 24.0 | 1.79  |\n|   |   |  Manage files | 15.8 | 1.18  |\n|   |  Email Management (15.8) | Search/filter emails | 49.1 | 2.81  |\n|   |   |  Create/edit emails | 32.8 | 1.88  |\n|   |   |  Delete/unsubscribe emails | 30.6 | 1.75  |\n|   |   |  Summarize/analyze emails | 22.8 | 1.31  |\n|   |   |  Send emails | 9.6 | 0.55  |\n|   |  Spreadsheet & Data Editing (11.1) | Create/edit spreadsheets/data | 72.5 | 2.91  |\n|   |   |  Summarize/analyze spreadsheets/data | 38.7 | 1.55  |\n|   |   |  Search/filter spreadsheets/data | 27.5 | 1.10  |\n|   |  Computer Programming (10.3) | Create/edit code | 63.8 | 2.38  |\n|   |   |  Summarize/analyze code | 48.5 | 1.81  |\n|   |   |  Execute code | 20.3 | 0.76  |\n|   |  Investments & Banking (6.2) | Summarize/analyze investment information | 75.0 | 1.69  |\n|   |   |  Search/filter stocks | 28.8 | 0.65  |\n|   |   |  Summarize/analyze banking information | 11.7 | 0.26  |\n|   |   |  Buy/sell stocks | 7.8 | 0.18  |\n|   |  Multimedia Editing (6.1) | Create/edit multimedia | 81.0 | 1.80  |\n|   |   |  Summarize/analyze multimedia | 23.6 | 0.52  |\n|   |   |  Search/filter multimedia | 15.3 | 0.34  |\n|   |  Project Management (5.1) | Create/edit projects | 64.6 | 1.19  |\n|   |   |  Summarize/analyze project information | 48.0 | 0.89  |\n|   |  Calendar Management (2.5) | Create/edit events | 71.0 | 0.64  |\n|   |   |  Search/filter events | 24.6 | 0.22  |\n|  Summarize/analyze events |   | 22.0 | 0.20  |   |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 34,
      "width": 1700,
      "height": 2200,
      "text": "tbl-11.md Note: The table shows all tasks under Learning &amp; Research with a share of more than $5\\%$ within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage $(P(\\text{Task} \\text{Topic}, \\text{Subtopic}))$ is the task share within the subtopic. The overall percentage is the task share among all agentic queries. $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\text{Topic}) \\times P(\\text{Task} \\text{Topic}, \\text{Subtopic}))$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100. Table 12: Task Distribution for Learning &amp; Research",
      "markdown": "[tbl-11.md](tbl-11.md)\n\nNote: The table shows all tasks under Learning &amp; Research with a share of more than  $5\\%$  within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage  $(P(\\text{Task} | \\text{Topic}, \\text{Subtopic}))$  is the task share within the subtopic. The overall percentage is the task share among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} | \\text{Topic}) \\times P(\\text{Task} | \\text{Topic}, \\text{Subtopic}))$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\n\nTable 12: Task Distribution for Learning &amp; Research",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-11.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Task | Task (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Learning & Research (20.8) | Courses (61.9) | Assist exercises | 73.2 | 9.41  |\n|   |   |  Summarize/analyze course materials | 28.7 | 3.69  |\n|   |   |  Navigate courses | 25.6 | 3.29  |\n|   |  Research (37.9) | Summarize/analyze research information | 85.2 | 6.71  |\n|   |   |  Search/filter research information | 75.6 | 5.95  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 35,
      "width": 1700,
      "height": 2200,
      "text": "tbl-12.md Note: The table shows all tasks under Media &amp; Entertainment with a share of more than $5\\%$ within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage $(P(\\text{Task} \\text{Topic}, \\text{Subtopic}))$ is the task share within the subtopic. The overall percentage is the task share among all agentic queries. $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\text{Topic}) \\times P(\\text{Task} \\text{Topic}, \\text{Subtopic}))$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100. Table 13: Task Distribution for Media &amp; Entertainment",
      "markdown": "[tbl-12.md](tbl-12.md)\n\nNote: The table shows all tasks under Media &amp; Entertainment with a share of more than  $5\\%$  within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage  $(P(\\text{Task} | \\text{Topic}, \\text{Subtopic}))$  is the task share within the subtopic. The overall percentage is the task share among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} | \\text{Topic}) \\times P(\\text{Task} | \\text{Topic}, \\text{Subtopic}))$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\n\nTable 13: Task Distribution for Media &amp; Entertainment",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-12.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Task | Task (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Media & Entertainment (15.8) | Social Media & Messaging (42.4) | Search/filter social media posts/messages | 49.5 | 3.31  |\n|   |   |  Summarize/analyze social media posts/messages | 35.3 | 2.36  |\n|   |   |  Create social media posts/messages | 34.0 | 2.28  |\n|   |   |  Engage with social media posts/messages | 29.3 | 1.96  |\n|   |   |  Send social media/text messages | 20.7 | 1.39  |\n|   |  Movies, TV, & Videos (20.1) | Search/filter videos | 48.4 | 1.53  |\n|   |   |  Summarize/analyze videos | 43.8 | 1.39  |\n|   |   |  Play videos | 27.1 | 0.86  |\n|   |   |  Navigate within videos | 18.4 | 0.58  |\n|   |   |  Manage playlists | 6.2 | 0.20  |\n|   |  Online Games (19.6) | Play online games | 76.8 | 2.37  |\n|   |   |  Summarize/analyze online game information | 30.7 | 0.95  |\n|   |   |  Search/filter online games | 14.5 | 0.45  |\n|   |  Music & Podcasts (10.7) | Search/filter music/podcasts | 75.4 | 1.27  |\n|   |   |  Play music/podcasts | 61.2 | 1.03  |\n|   |   |  Manage playlists | 25.5 | 0.43  |\n|   |   |  Summarize/analyze music/podcasts | 9.7 | 0.16  |\n|   |  News (3.8) | Search/filter news | 70.7 | 0.42  |\n|   |   |  Summarize/analyze news | 56.6 | 0.34  |\n|   |  Sports (2.7) | Summarize/analyze match/player information | 77.0 | 0.32  |\n|   |   |  Search/filter match/player information | 67.7 | 0.28  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 36,
      "width": 1700,
      "height": 2200,
      "text": "tbl-13.md Note: The table shows all tasks under Shopping &amp; Commerce with a share of more than $5\\%$ within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage $(P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$ is the task share within the subtopic. The overall percentage is the task share among all agentic queries. $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100. Table 14: Task Distribution for Shopping &amp; Commerce",
      "markdown": "[tbl-13.md](tbl-13.md)\n\nNote: The table shows all tasks under Shopping &amp; Commerce with a share of more than  $5\\%$  within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage  $(P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$  is the task share within the subtopic. The overall percentage is the task share among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\n\nTable 14: Task Distribution for Shopping &amp; Commerce",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-13.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Task | Task (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Shopping & Commerce (10.0) | Goods (89.0) | Search/filter products | 71.9 | 6.43  |\n|   |   |  Summarize/analyze product information | 57.9 | 5.18  |\n|   |   |  Add products to cart | 19.8 | 1.77  |\n|   |   |  Search discounts | 10.2 | 0.92  |\n|   |  Services (10.3) | Search/filter products | 54.5 | 0.56  |\n|   |   |  Summarize/analyze product information | 45.1 | 0.46  |\n|   |   |  Make product purchase | 20.2 | 0.21  |\n|   |   |  Search discounts | 12.5 | 0.13  |\n|   |   |  Add products to cart | 7.6 | 0.08  |\n|   |   |  Manage orders | 7.0 | 0.07  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 37,
      "width": 1700,
      "height": 2200,
      "text": "tbl-14.md Note: The table shows all tasks under Job &amp; Career with a share of more than $5\\%$ within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage $(P(\\text{Task} \\text{Topic}, \\text{Subtopic}))$ is the task share within the subtopic. The overall percentage is the task share among all agentic queries. $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\text{Topic}) \\times P(\\text{Task} \\text{Topic}, \\text{Subtopic})$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100. Table 15: Task Distribution for Job &amp; Career",
      "markdown": "[tbl-14.md](tbl-14.md)\n\nNote: The table shows all tasks under Job &amp; Career with a share of more than  $5\\%$  within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage  $(P(\\text{Task} | \\text{Topic}, \\text{Subtopic}))$  is the task share within the subtopic. The overall percentage is the task share among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} | \\text{Topic}) \\times P(\\text{Task} | \\text{Topic}, \\text{Subtopic})$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\n\nTable 15: Task Distribution for Job &amp; Career",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-14.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Task | Task (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Job & Career (7.1) | Job Search & Application (50.1) | Complete applications | 65.7 | 2.31  |\n|   |   |  Search/filter jobs | 57.1 | 2.01  |\n|   |   |  Summarize/analyze job descriptions | 26.3 | 0.93  |\n|   |  Professional Networking (49.5) | Search/filter professional profiles | 53.8 | 1.92  |\n|   |   |  Summarize/analyze professional profiles | 39.9 | 1.42  |\n|   |   |  Send professional connection requests/messages | 31.4 | 1.12  |\n|   |   |  Engage with professional profiles/posts | 24.0 | 0.85  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 38,
      "width": 1700,
      "height": 2200,
      "text": "tbl-15.md Note: The table shows all tasks under Travel &amp; Leisure with a share of more than $5\\%$ within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage $(P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$ is the task share within the subtopic. The overall percentage is the task share among all agentic queries. $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100. Table 16: Task Distribution for Travel &amp; Leisure",
      "markdown": "[tbl-15.md](tbl-15.md)\n\nNote: The table shows all tasks under Travel &amp; Leisure with a share of more than  $5\\%$  within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage  $(P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$  is the task share within the subtopic. The overall percentage is the task share among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\n\nTable 16: Task Distribution for Travel &amp; Leisure",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-15.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Task | Task (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Travel & Leisure (6.7) | Flights & Transportation (40.7) | Search/filter flights & transportation | 93.4 | 2.55  |\n|   |   |  Summarize/analyze flights & transportation | 63.1 | 1.72  |\n|   |   |  Book flights & transportation | 9.5 | 0.26  |\n|   |  Lodging (27.3) | Search/filter lodging | 92.9 | 1.70  |\n|   |   |  Summarize/analyze lodging information | 67.5 | 1.23  |\n|   |   |  Book lodging | 5.5 | 0.10  |\n|   |  Trip Itineraries (24.8) | Plan trips | 87.4 | 1.45  |\n|   |   |  Summarize/analyze trips | 48.9 | 0.81  |\n|   |   |  Search/filter destinations | 48.8 | 0.81  |\n|   |  Restaurants (5.7) | Search/filter restaurants | 73.8 | 0.28  |\n|   |   |  Summarize/analyze restaurant information | 54.2 | 0.21  |\n|   |   |  Book restaurants | 25.0 | 0.09  |\n|  Manage bookings |   | 5.7 | 0.02  |   |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 39,
      "width": 1700,
      "height": 2200,
      "text": "tbl-16.md Note: The table shows the top 5 tasks under each occupation cluster. Task percentage $(P(\\text{Task} \\text{Cluster}))$ is the task share among all agentic queries within a cluster. Table 17: The Top 5 Tasks by Occupation Cluster",
      "markdown": "[tbl-16.md](tbl-16.md)\n\nNote: The table shows the top 5 tasks under each occupation cluster. Task percentage  $(P(\\text{Task} | \\text{Cluster}))$  is the task share among all agentic queries within a cluster.\n\nTable 17: The Top 5 Tasks by Occupation Cluster",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-16.md",
          "format": "markdown",
          "content": "|  Cluster | Task | Task (%)  |\n| --- | --- | --- |\n|  Digital Technology | Assist exercises | 9.1  |\n|   |  Search/filter products | 6.4  |\n|   |  Create/edit documents/forms | 6.2  |\n|   |  Summarize/analyze research information | 6.2  |\n|   |  Manage settings/profiles | 5.7  |\n|  Student | Assist exercises | 26.5  |\n|   |  Summarize/analyze course materials | 10.7  |\n|   |  Navigate courses | 7.8  |\n|   |  Create/edit documents/forms | 7.1  |\n|   |  Summarize/analyze research information | 5.4  |\n|  Management & Entrepreneurship | Summarize/analyze research information | 7.7  |\n|   |  Create/edit documents/forms | 7.5  |\n|   |  Search/filter research information | 6.8  |\n|   |  Search/filter products | 6.3  |\n|   |  Create/edit spreadsheets/data | 5.2  |\n|  Marketing & Sales | Create social media posts/messages | 8.1  |\n|   |  Search/filter social media posts/messages | 8.1  |\n|   |  Summarize/analyze product information | 8.1  |\n|   |  Summarize/analyze research information | 8.0  |\n|   |  Search/filter products | 7.6  |\n|  Financial Services | Summarize/analyze investment information | 11.9  |\n|   |  Summarize/analyze research information | 7.0  |\n|   |  Search/filter products | 6.7  |\n|   |  Search/filter research information | 6.1  |\n|   |  Summarize/analyze product information | 5.2  |\n|  Education | Assist exercises | 19.6  |\n|   |  Create/edit documents/forms | 9.8  |\n|   |  Summarize/analyze course materials | 8.6  |\n|   |  Summarize/analyze research information | 7.0  |\n|   |  Search/filter research information | 6.9  |\n|  Arts, Entertainment, & Design | Search/filter products | 7.8  |\n|   |  Create/edit documents/forms | 7.4  |\n|   |  Create/edit multimedia | 7.3  |\n|   |  Summarize/analyze product information | 6.1  |\n|   |  Summarize/analyze research information | 5.8  |\n|  Healthcare & Human Services | Summarize/analyze research information | 9.5  |\n|   |  Search/filter research information | 9.4  |\n|   |  Create/edit documents/forms | 7.9  |\n|   |  Search/filter products | 6.6  |\n|   |  Assist exercises | 5.5  |\n|  Advanced Manufacturing | Search/filter products | 20.9  |\n|   |  Summarize/analyze product information | 18.1  |\n|   |  Summarize/analyze research information | 7.8  |\n|   |  Search/filter research information | 7.5  |\n|   |  Assist exercises | 6.6  |\n|  Public Service & Safety | Search/filter research information | 15.7  |\n|   |  Summarize/analyze research information | 15.1  |\n|   |  Create/edit documents/forms | 10.2  |\n|   |  Search/filter products | 5.1  |\n|   |  Assist exercises | 4.3  |\n|  Hospitality, Events, & Tourism | Search/filter flights & transportation | 11.9  |\n|   |  Search/filter lodging | 9.6  |\n|   |  Search/filter products | 8.3  |\n|   |  Summarize/analyze flights & transportation information | 8.1  |\n|   |  Summarize/analyze lodging information | 7.6  |\n|  Supply Chain & Transportation | Search/filter products | 12.7  |\n|   |  Summarize/analyze product information | 10.6  |\n|   |  Create/edit documents/forms | 7.4  |\n|   |  Summarize/analyze research information | 7.2  |\n|   |  Search/filter research information | 6.4  |\n|  Construction | Search/filter products | 11.0  |\n|   |  Summarize/analyze product information | 9.1  |\n|   |  Summarize/analyze research information | 8.8  |\n|   |  Search/filter research information | 8.3  |\n|   |  Create/edit documents/forms | 5.6  |\n|  Energy & Natural Resources | Create/edit documents/forms | 10.5  |\n|   |  Summarize/analyze research information | 10.4  |\n|   |  Search/filter research information | 10.4  |\n|   |  Search/filter products | 7.7  |\n|   |  Summarize/analyze product information | 6.0  |\n|  Agriculture | Create/edit documents/forms | 10.3  |\n|   |  Search/filter products | 8.5  |\n|   |  Summarize/analyze research information | 8.4  |\n|   |  Search/filter research information | 8.4  |\n|   |  Summarize/analyze product information | 7.2  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 40,
      "width": 1700,
      "height": 2200,
      "text": "A.2.3 Environments tbl-17.md Note: The table shows the top 5 environments under Productivity &amp; Workflow. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries. $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$ is the share of an environment when it is used under that subtopic and does not equal $P(\\text{Environment})$ , which is the share under all subtopics. Table 18: The Top 5 Environments Distribution for Productivity &amp; Workflow",
      "markdown": "# A.2.3 Environments\n\n[tbl-17.md](tbl-17.md)\n\nNote: The table shows the top 5 environments under Productivity &amp; Workflow. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries.  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$  is the share of an environment when it is used under that subtopic and does not equal  $P(\\text{Environment})$ , which is the share under all subtopics.\n\nTable 18: The Top 5 Environments Distribution for Productivity &amp; Workflow",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-17.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Environment | Environment (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Productivity & Workflow (36.2) | Document & Form Editing (21.5) | docs.google.com | 66.6 | 5.18  |\n|   |   |  notion.so | 6.4 | 0.50  |\n|   |   |  canva.com | 2.5 | 0.19  |\n|   |   |  overleaf.com | 2.0 | 0.16  |\n|   |   |  perplexity.ai | 1.3 | 0.10  |\n|   |  Account Management (20.5) | perplexity.ai | 10.4 | 0.77  |\n|   |   |  docs.google.com | 7.6 | 0.56  |\n|   |   |  settings | 4.0 | 0.30  |\n|   |   |  github.com | 3.2 | 0.24  |\n|   |   |  linkedin.com | 3.1 | 0.23  |\n|   |  Email Management (15.8) | mail.google.com | 69.9 | 4.00  |\n|   |   |  outlook.office.com | 10.8 | 0.62  |\n|   |   |  outlook/live.com | 2.9 | 0.17  |\n|   |   |  mail.yahoo.com | 1.5 | 0.09  |\n|   |   |  mail.yandex.ru | 0.5 | 0.03  |\n|   |  Spreadsheet & Data Editing (11.1) | docs.google.com | 78.9 | 3.17  |\n|   |   |  notion.so | 4.4 | 0.18  |\n|   |   |  airtable.com | 2.3 | 0.09  |\n|   |   |  excel.cloud.microsoft | 1.4 | 0.06  |\n|   |   |  app.powerbi.com | 1.1 | 0.04  |\n|   |  Computer Programming (10.3) | github.com | 30.7 | 1.14  |\n|   |   |  colab.research.google.com | 5.3 | 0.20  |\n|   |   |  leetcode.com | 4.9 | 0.18  |\n|   |   |  aistudio.google.com | 4.2 | 0.16  |\n|   |   |  script.google.com | 3.1 | 0.12  |\n|   |  Investments & Banking (6.2) | tradingview.com | 47.3 | 1.06  |\n|   |   |  binance.com | 5.7 | 0.13  |\n|   |   |  kite.zerodha.com | 4.9 | 0.11  |\n|   |   |  groww.in | 4.6 | 0.10  |\n|   |   |  perplexity.ai | 4.4 | 0.10  |\n|   |  Multimedia Editing (6.1) | canva.com | 42.9 | 0.95  |\n|   |   |  figma.com | 8.6 | 0.19  |\n|   |   |  docs.google.com | 5.3 | 0.12  |\n|   |   |  youtube.com | 5.3 | 0.12  |\n|   |   |  aistudio.google.com | 3.5 | 0.08  |\n|   |  Project Management (5.1) | app.clickup.com | 9.6 | 0.18  |\n|   |   |  trello.com | 8.1 | 0.15  |\n|   |   |  notion.so | 7.3 | 0.13  |\n|   |   |  linear.app | 6.5 | 0.12  |\n|   |   |  adsmanager.facebook.com | 5.4 | 0.10  |\n|   |  Calendar Management (2.5) | calendar.google.com | 50.3 | 0.45  |\n|   |   |  outlook.office.com | 7.7 | 0.07  |\n|   |   |  meet.google.com | 3.7 | 0.03  |\n|   |   |  mail.google.com | 3.5 | 0.03  |\n|   |   |  teams.microsoft.com | 1.4 | 0.01  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 41,
      "width": 1700,
      "height": 2200,
      "text": "tbl-18.md Note: The table shows the top 5 environments under Learning &amp; Research. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries. $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$ is the share of an environment when it is used under that subtopic and does not equal $P(\\text{Environment})$ , which is the share under all subtopics. Table 19: The Top 5 Environments Distribution for Learning &amp; Research",
      "markdown": "[tbl-18.md](tbl-18.md)\n\nNote: The table shows the top 5 environments under Learning &amp; Research. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries.  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$  is the share of an environment when it is used under that subtopic and does not equal  $P(\\text{Environment})$ , which is the share under all subtopics.\n\nTable 19: The Top 5 Environments Distribution for Learning &amp; Research",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-18.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Environment | Environment (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Learning & Research (20.8) | Courses (61.9) | coursera.org | 18.0 | 2.32  |\n|   |   |  netacad.com | 15.6 | 2.01  |\n|   |   |  canvas.com | 12.6 | 1.62  |\n|   |   |  learning.mheducation.com | 8.3 | 1.07  |\n|   |   |  docs.google.com | 6.4 | 0.82  |\n|   |  Research (37.9) | youtube.com | 17.8 | 1.40  |\n|   |   |  perplexity.ai | 6.1 | 0.48  |\n|   |   |  github.com | 5.8 | 0.46  |\n|   |   |  maps.google.com | 5.4 | 0.43  |\n|   |   |  docs.google.com | 3.9 | 0.31  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 42,
      "width": 1700,
      "height": 2200,
      "text": "tbl-19.md Note: The table shows the top 5 environments under Media &amp; Entertainment. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage $(P(\\text{Environment} \\text{Topic}, \\text{Subtopic}))$ is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries. $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\text{Topic}) \\times P(\\text{Environment} \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$ is the share of an environment when it is used under that subtopic and does not equal $P(\\text{Environment})$ , which is the share under all subtopics. Table 20: The Top 5 Environments Distribution for Media &amp; Entertainment",
      "markdown": "[tbl-19.md](tbl-19.md)\n\nNote: The table shows the top 5 environments under Media &amp; Entertainment. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage  $(P(\\text{Environment} | \\text{Topic}, \\text{Subtopic}))$  is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries.  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} | \\text{Topic}) \\times P(\\text{Environment} | \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$  is the share of an environment when it is used under that subtopic and does not equal  $P(\\text{Environment})$ , which is the share under all subtopics.\n\nTable 20: The Top 5 Environments Distribution for Media &amp; Entertainment",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-19.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Environment | Environment (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Media & Entertainment (15.8) | Social Media & Messaging (42.4) | instagram.com | 21.3 | 1.43  |\n|   |   |  x.com | 18.0 | 1.21  |\n|   |   |  whatsapp.com | 13.6 | 0.91  |\n|   |   |  facebook.com | 10.1 | 0.68  |\n|   |   |  linkedin | 6.1 | 0.41  |\n|   |  Movies, TV, & Videos (20.1) | youtube.com | 89.9 | 2.85  |\n|   |   |  netflix.com | 4.1 | 0.13  |\n|   |   |  in.bookmyshow.com | 1.3 | 0.04  |\n|   |   |  twitch.tv | 0.7 | 0.02  |\n|   |   |  tiktok.com | 0.6 | 0.02  |\n|   |  Online Games (19.6) | chess.com | 32.5 | 1.01  |\n|   |   |  store.steampowered.com | 15.0 | 0.46  |\n|   |   |  nytimes.com | 14.2 | 0.44  |\n|   |   |  roblox.com | 6.8 | 0.21  |\n|   |   |  humanbenchmark.com | 5.4 | 0.17  |\n|   |  Music & Podcasts (10.7) | open.spotify.com | 46.1 | 0.78  |\n|   |   |  youtube.com | 39.9 | 0.67  |\n|   |   |  suno.com | 6.2 | 0.10  |\n|   |   |  soundcloud.com | 2.7 | 0.05  |\n|   |   |  music.apple.com | 2.4 | 0.04  |\n|   |  News (3.8) | youtube.com | 21.0 | 0.13  |\n|   |   |  trends.google.com | 13.6 | 0.08  |\n|   |   |  nytimes.com | 8.7 | 0.05  |\n|   |   |  perplexity.ai | 7.9 | 0.05  |\n|   |   |  x.com | 5.8 | 0.03  |\n|   |  Sports (2.7) | youtube.com | 28.3 | 0.12  |\n|   |   |  fantasy.espn.com | 20.1 | 0.09  |\n|   |   |  sleeper.com | 7.8 | 0.03  |\n|   |   |  sofascore.com | 3.3 | 0.01  |\n|   |   |  livescore.in | 1.8 | 0.01  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 43,
      "width": 1700,
      "height": 2200,
      "text": "tbl-20.md Note: The table shows the top 5 environments under Shopping &amp; Commerce. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries. $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$ is the share of an environment when it is used under that subtopic and does not equal $P(\\text{Environment})$ , which is the share under all subtopics. Table 21: The Top 5 Environments Distribution for Shopping &amp; Commerce",
      "markdown": "[tbl-20.md](tbl-20.md)\n\nNote: The table shows the top 5 environments under Shopping &amp; Commerce. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries.  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$  is the share of an environment when it is used under that subtopic and does not equal  $P(\\text{Environment})$ , which is the share under all subtopics.\n\nTable 21: The Top 5 Environments Distribution for Shopping &amp; Commerce",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-20.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Environment | Environment (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Shopping & Commerce (10.0) | Goods (89.0) | amazon.com | 43.2 | 3.84  |\n|   |   |  flipkart.com | 6.2 | 0.55  |\n|   |   |  admin.shopify.com | 5.3 | 0.47  |\n|   |   |  alibaba.com | 3.7 | 0.33  |\n|   |   |  ozon.ru | 3.4 | 0.30  |\n|   |  Services (10.3) | perplexity.ai | 12.2 | 0.13  |\n|   |   |  maps.google.com | 8.7 | 0.09  |\n|   |   |  amazon.com | 5.1 | 0.05  |\n|   |   |  fiverr.com | 5.1 | 0.05  |\n|   |   |  avito.ru | 4.1 | 0.04  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 44,
      "width": 1700,
      "height": 2200,
      "text": "tbl-21.md Note: The table shows the top 5 environments under Job &amp; Career. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries. $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$ is the share of an environment when it is used under that subtopic and does not equal $P(\\text{Environment})$ , which is the share under all subtopics. Table 22: The Top 5 Environments Distribution for Job &amp; Career",
      "markdown": "[tbl-21.md](tbl-21.md)\n\nNote: The table shows the top 5 environments under Job &amp; Career. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries.  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$  is the share of an environment when it is used under that subtopic and does not equal  $P(\\text{Environment})$ , which is the share under all subtopics.\n\nTable 22: The Top 5 Environments Distribution for Job &amp; Career",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-21.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Environment | Environment (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Job & Career (7.1) | Professional Networking (50.1) | linkedin.com | 92.5 | 3.29  |\n|   |   |  upwork.com | 1.3 | 0.05  |\n|   |   |  app.apollo.io | 0.8 | 0.03  |\n|   |   |  naukri.com | 0.6 | 0.02  |\n|   |   |  instagram.com | 0.5 | 0.02  |\n|   |  Job Search & Application (49.5) | linkedin.com | 60.2 | 2.12  |\n|   |   |  naukri.com | 6.3 | 0.22  |\n|   |   |  ziprecruiter.com | 2.7 | 0.09  |\n|   |   |  indeed.com | 2.5 | 0.09  |\n|   |   |  dice.com | 2.4 | 0.08  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 45,
      "width": 1700,
      "height": 2200,
      "text": "tbl-22.md Note: The table shows the top 5 environments under Travel &amp; Leisure. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries. $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$ is the share of an environment when it is used under that subtopic and does not equal $P(\\text{Environment})$ , which is the share under all subtopics. Table 23: The Top 5 Environments Distribution for Travel &amp; Leisure",
      "markdown": "[tbl-22.md](tbl-22.md)\n\nNote: The table shows the top 5 environments under Travel &amp; Leisure. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries.  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$  is the share of an environment when it is used under that subtopic and does not equal  $P(\\text{Environment})$ , which is the share under all subtopics.\n\nTable 23: The Top 5 Environments Distribution for Travel &amp; Leisure",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-22.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Environment | Environment (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Travel & Leisure (6.7) | Flights & Transportation (40.7) | skyscanner.com | 35.6 | 0.97  |\n|   |   |  maps.google.com | 18.4 | 0.50  |\n|   |   |  makemytrip.com | 7.2 | 0.20  |\n|   |   |  irctc.co.in | 6.1 | 0.17  |\n|   |   |  expedia.com | 4.0 | 0.11  |\n|   |  Lodging (27.3) | booking.com | 54.9 | 1.00  |\n|   |   |  airbnb.com | 19.5 | 0.36  |\n|   |   |  expedia.com | 4.6 | 0.08  |\n|   |   |  maps.google.com | 4.0 | 0.07  |\n|   |   |  agoda.com | 3.5 | 0.06  |\n|   |  Trip Itineraries (24.8) | maps.google.com | 85.2 | 1.42  |\n|   |   |  docs.google.com | 4.2 | 0.07  |\n|   |   |  yandex.ru | 1.3 | 0.02  |\n|   |   |  skyscanner.com | 1.2 | 0.02  |\n|   |   |  booking.com | 0.8 | 0.01  |\n|   |  Restaurants (5.7) | maps.google.com | 54.7 | 0.21  |\n|   |   |  opentable.com | 6.5 | 0.02  |\n|   |   |  map.naver.com | 5.2 | 0.02  |\n|   |   |  swiggy.com | 4.6 | 0.02  |\n|   |   |  ubereats.com | 3.9 | 0.01  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 46,
      "width": 1700,
      "height": 2200,
      "text": "tbl-23.md Note: The table shows the sum of the top 5 environments' shares by topic and subtopic. A higher (lower) share indicates agentic queries are more (less) concentrated in a small number of environments. This metric can be interpreted as the agent usage market share of environments among agent adopters on Comet. Table 24: Sum of the Top 5 Environment Shares by Topic and Subtopic",
      "markdown": "[tbl-23.md](tbl-23.md)\n\nNote: The table shows the sum of the top 5 environments' shares by topic and subtopic. A higher (lower) share indicates agentic queries are more (less) concentrated in a small number of environments. This metric can be interpreted as the agent usage market share of environments among agent adopters on Comet.\n\nTable 24: Sum of the Top 5 Environment Shares by Topic and Subtopic",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-23.md",
          "format": "markdown",
          "content": "|  Topic | Subtopic | Sum of the Top 5 Environments (%)  |\n| --- | --- | --- |\n|  Productivity & Workflow | Spreadsheet & Data Editing | 88.1  |\n|   |  Email Management | 85.1  |\n|   |  Document & Form Editing | 78.8  |\n|   |  Investments & Banking | 66.9  |\n|   |  Calendar Management | 66.6  |\n|   |  Multimedia Editing | 65.6  |\n|   |  Computer Programming | 48.2  |\n|   |  Project Management | 36.9  |\n|   |  Account Management | 28.3  |\n|  Learning & Research | Courses | 60.9  |\n|   |  Research | 39.0  |\n|  Media & Entertainment | Music & Podcasts | 97.3  |\n|   |  Movies, TV, & Videos | 96.6  |\n|   |  Online Games | 73.9  |\n|   |  Social Media & Messaging | 69.1  |\n|   |  Sports | 61.3  |\n|   |  News | 57.0  |\n|  Shopping & Commerce | Goods | 61.8  |\n|   |  Services | 35.2  |\n|  Job & Career | Professional Networking | 95.7  |\n|   |  Job Search & Application | 74.1  |\n|  Travel & Leisure | Trip Itineraries | 92.7  |\n|   |  Lodging | 86.5  |\n|   |  Restaurants | 74.9  |\n|   |  Flights & Transportation | 71.3  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 47,
      "width": 1700,
      "height": 2200,
      "text": "tbl-24.md Note: The table shows the top 5 environments by occupation cluster. Environment percentage $(P(\\text{Environment} \\text{Cluster}))$ is the environment share among all agentic queries in that cluster. docs.google.com includes Google Docs, Sheets, Slides, and Forms. All email accounts are grouped into \"email services combined\". Table 25: The Top 5 Environments by Occupation Cluster",
      "markdown": "[tbl-24.md](tbl-24.md)\n\nNote: The table shows the top 5 environments by occupation cluster. Environment percentage  $(P(\\text{Environment} | \\text{Cluster}))$  is the environment share among all agentic queries in that cluster. docs.google.com includes Google Docs, Sheets, Slides, and Forms. All email accounts are grouped into \"email services combined\".\n\nTable 25: The Top 5 Environments by Occupation Cluster",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-24.md",
          "format": "markdown",
          "content": "|  Cluster | Environment | Environment (%)  |\n| --- | --- | --- |\n|  Digital Technology | linkedin.com | 6.5  |\n|   |  email services combined | 5.4  |\n|   |  docs.google.com | 4.0  |\n|   |  youtube.com | 3.3  |\n|   |  amazon.com | 2.4  |\n|  Student | docs.google.com | 7.8  |\n|   |  linkedin.com | 6.1  |\n|   |  email services combined | 4.3  |\n|   |  canvas.com | 3.4  |\n|   |  youtube.com | 3.0  |\n|  Management & Entrepreneurship | linkedin.com | 10.3  |\n|   |  email services combined | 8.8  |\n|   |  docs.google.com | 7.7  |\n|   |  youtube.com | 2.0  |\n|   |  amazon.com | 1.8  |\n|  Marketing & Sales | linkedin.com | 7.8  |\n|   |  docs.google.com | 6.8  |\n|   |  instagram.com | 6.5  |\n|   |  x.com | 5.2  |\n|   |  email services combined | 4.5  |\n|  Financial Services | email services combined | 6.6  |\n|   |  docs.google.com | 5.0  |\n|   |  linkedin.com | 4.3  |\n|   |  youtube.com | 3.6  |\n|   |  tradingview.com | 2.6  |\n|  Education | docs.google.com | 9.9  |\n|   |  email services combined | 6.5  |\n|   |  youtube.com | 4.4  |\n|   |  canvas.com | 2.4  |\n|   |  amazon.com | 2.1  |\n|  Arts, Entertainment, & Design | youtube.com | 7.0  |\n|   |  email services combined | 5.1  |\n|   |  docs.google.com | 4.9  |\n|   |  linkedin.com | 3.6  |\n|   |  instagram.com | 3.2  |\n|  Healthcare & Human Services | email services combined | 7.3  |\n|   |  docs.google.com | 5.8  |\n|   |  linkedin.com | 4.7  |\n|   |  youtube.com | 3.0  |\n|   |  amazon.com | 2.5  |\n|  Advanced Manufacturing | email services combined | 5.5  |\n|   |  linkedin.com | 4.6  |\n|   |  docs.google.com | 4.3  |\n|   |  youtube.com | 3.7  |\n|   |  amazon.com | 3.4  |\n|  Public Service & Safety | email services combined | 6.2  |\n|   |  docs.google.com | 4.9  |\n|   |  youtube.com | 4.1  |\n|   |  trends.google.com | 3.9  |\n|   |  linkedin.com | 2.8  |\n|  Hospitality, Events, & Tourism | email services combined | 6.4  |\n|   |  maps.google.com | 5.6  |\n|   |  docs.google.com | 5.4  |\n|   |  booking.com | 3.6  |\n|   |  skyscanner.com | 2.9  |\n|  Supply Chain & Transportation | email services combined | 8.0  |\n|   |  docs.google.com | 4.9  |\n|   |  linkedin.com | 3.7  |\n|   |  amazon.com | 3.0  |\n|   |  maps.google.com | 2.5  |\n|  Construction | email services combined | 8.2  |\n|   |  linkedin.com | 6.3  |\n|   |  docs.google.com | 4.3  |\n|   |  youtube.com | 3.1  |\n|   |  amazon.com | 2.8  |\n|  Energy & Natural Resources | email services combined | 7.4  |\n|   |  docs.google.com | 6.6  |\n|   |  linkedin.com | 3.8  |\n|   |  amazon.com | 3.4  |\n|   |  youtube.com | 2.9  |\n|  Agriculture | docs.google.com | 7.4  |\n|   |  email services combined | 6.9  |\n|   |  youtube.com | 3.6  |\n|   |  linkedin.com | 3.6  |\n|   |  amazon.com | 2.4  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 48,
      "width": 1700,
      "height": 2200,
      "text": "A.2.4 Usage Context tbl-25.md Note: The table shows the distribution of the top 5 subtopics by usage context. Subtopic percentage $(P(\\text{Subtopic} \\text{Context}))$ is the subtopic share among all agentic queries in a given usage context. Table 26: The Top 5 Subtopic Distribution by Usage Context",
      "markdown": "# A.2.4 Usage Context\n\n[tbl-25.md](tbl-25.md)\n\nNote: The table shows the distribution of the top 5 subtopics by usage context. Subtopic percentage  $(P(\\text{Subtopic} | \\text{Context}))$  is the subtopic share among all agentic queries in a given usage context.\n\nTable 26: The Top 5 Subtopic Distribution by Usage Context",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-25.md",
          "format": "markdown",
          "content": "|  Context | Topic | Subtopic | Subtopic (%)  |\n| --- | --- | --- | --- |\n|  Personal | Shopping & Commerce | Goods | 15.6  |\n|   |  Media & Entertainment | Social Media & Messaging | 9.9  |\n|   |  Productivity & Workflow | Account Management | 8.0  |\n|   |  Productivity & Workflow | Email Management | 7.6  |\n|   |  Media & Entertainment | Online Games | 6.0  |\n|  Professional | Productivity & Workflow | Document & Form Editing | 13.3  |\n|   |  Job & Career | Professional Networking | 12.5  |\n|   |  Job & Career | Job Search & Application | 11.0  |\n|   |  Productivity & Workflow | Account Management | 10.2  |\n|   |  Learning & Research | Research | 8.9  |\n|  Educational | Learning & Research | Courses | 83.9  |\n|   |  Learning & Research | Research | 5.3  |\n|   |  Productivity & Workflow | Document & Form Editing | 5.0  |\n|   |  Productivity & Workflow | Account Management | 1.1  |\n|   |  Productivity & Workflow | Computer Programming | 0.9  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 49,
      "width": 1700,
      "height": 2200,
      "text": "tbl-26.md Note: The table shows the distribution of the top 5 tasks by usage context. Task percentage $(P(\\text{Task} \\text{Context}))$ is the task share among all agentic queries in a given usage context. Table 27: The Top 5 Task Distribution by Usage Context",
      "markdown": "[tbl-26.md](tbl-26.md)\n\nNote: The table shows the distribution of the top 5 tasks by usage context. Task percentage  $(P(\\text{Task} | \\text{Context}))$  is the task share among all agentic queries in a given usage context.\n\nTable 27: The Top 5 Task Distribution by Usage Context",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-26.md",
          "format": "markdown",
          "content": "|  Context | Topic | Subtopic | Task | Task (%)  |\n| --- | --- | --- | --- | --- |\n|  Personal | Shopping & Commerce | Goods | Search/filter products | 8.6  |\n|   |  Shopping & Commerce | Goods | Summarize/analyze product information | 6.5  |\n|   |  Travel & Leisure | Flights & Transportation | Search/filter flights & transportation | 3.4  |\n|   |  Media & Entertainment | Social Media & Messaging | Search/filter social media posts/messages | 3.4  |\n|   |  Productivity & Workflow | Document & Form Editing | Create/edit documents/forms | 3.2  |\n|  Professional | Productivity & Workflow | Document & Form Editing | Create/edit documents/forms | 8.1  |\n|   |  Learning & Research | Research | Summarize/analyze research information | 5.9  |\n|   |  Job & Career | Job Search & Application | Complete applications | 5.4  |\n|   |  Productivity & Workflow | Account Management | Manage settings/profiles | 5.1  |\n|   |  Job & Career | Professional Networking | Search/filter professional profiles | 4.8  |\n|  Educational | Learning & Research | Courses | Assist exercises | 48.1  |\n|   |  Learning & Research | Courses | Summarize/analyze course materials | 18.8  |\n|   |  Learning & Research | Courses | Navigate courses | 16.0  |\n|   |  Productivity & Workflow | Document & Form Editing | Create/edit documents/forms | 3.6  |\n|   |  Learning & Research | Research | Summarize/analyze research information | 3.4  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 50,
      "width": 1700,
      "height": 2200,
      "text": "tbl-27.md Note: The table shows the distribution of the top 5 environments by usage context. Environment percentage $(P(\\text{Environment} \\mid \\text{Context}))$ is the environment share among all agentic queries in a given usage context. docs.google.com includes Google Docs, Sheets, Slides, and Forms. All email domains are grouped into \"email services combined\". Table 28: The Top 5 Environment Distribution by Usage Context",
      "markdown": "[tbl-27.md](tbl-27.md)\n\nNote: The table shows the distribution of the top 5 environments by usage context. Environment percentage  $(P(\\text{Environment} \\mid \\text{Context}))$  is the environment share among all agentic queries in a given usage context. docs.google.com includes Google Docs, Sheets, Slides, and Forms. All email domains are grouped into \"email services combined\".\n\nTable 28: The Top 5 Environment Distribution by Usage Context",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-27.md",
          "format": "markdown",
          "content": "|  Context | Environment | Environment (%)  |\n| --- | --- | --- |\n|  Personal | email services combined | 14.5  |\n|   |  youtube.com | 10.8  |\n|   |  docs.google.com | 10.7  |\n|   |  amazon.com | 6.3  |\n|   |  maps.google.com | 3.8  |\n|  Professional | linkedin.com | 29.6  |\n|   |  docs.google.com | 11.4  |\n|   |  email services combined | 9.6  |\n|   |  github.com | 3.8  |\n|   |  admin.shopify.com | 2.8  |\n|  Educational | docs.google.com | 14.8  |\n|   |  coursera.org | 14.6  |\n|   |  netacad.com | 12.7  |\n|   |  canvas.com | 10.2  |\n|   |  learning.mheducation.com | 6.8  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 51,
      "width": 1700,
      "height": 2200,
      "text": "B Agent Demo B.1 Sample Agentic Queries Useful Prompts for Agentic actions tbl-28.md Figure 9: Sample Agentic Queries from Perplexity at Work",
      "markdown": "# B Agent Demo\n\n# B.1 Sample Agentic Queries\n\n# Useful Prompts for Agentic actions\n\n[tbl-28.md](tbl-28.md)\n\nFigure 9: Sample Agentic Queries from Perplexity at Work",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-28.md",
          "format": "markdown",
          "content": "|  \"Find the latest published journal articles that focus on [insert topic]. Next, open each one in a new tab. Then create a comparison table analyzing research methodologies and results.\"  |\n| --- |\n|  \"Find all unanswered emails from the last 3 days that require a response and draft brief replies. Ignore calendar invites.\"  |\n|  \"Group my tabs by topic and close any that aren't relevant to my current project\"  |\n|  \"Apply for the open job listings opened in this window with my resume.\"  |\n|  \"Find and pull up the Youtube video at the section where Jensen Huang talks about Perplexity at GTC.\"  |\n|  \"Look through these customer case studies and identify any use cases relevant to how our company would use this vendor.\"  |\n|  \"Go through Amazon and see any supplies I haven't ordered in awhile and have it ship to the office address.\"  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 52,
      "width": 1700,
      "height": 2200,
      "text": "tbl-29.md Note: The table shows how the sample agentic queries map to our taxonomy. Table 29: Sample Agentic Queries Mapped to the Taxonomy",
      "markdown": "[tbl-29.md](tbl-29.md)\n\nNote: The table shows how the sample agentic queries map to our taxonomy.\n\nTable 29: Sample Agentic Queries Mapped to the Taxonomy",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-29.md",
          "format": "markdown",
          "content": "|  Sample Query | Topic | Subtopic | Task  |\n| --- | --- | --- | --- |\n|  Find the latest published journal articles... | Learning & Research | Research | Search/filter research information, Summarize/analyze research information  |\n|  Find all unanswered emails... | Productivity & Workflow | Email Management | Search/filter emails, Create/edit emails  |\n|  Group my tabs by topic... | Productivity & Workflow | Account Management | Manage settings/profiles  |\n|  Apply for the open job listings... | Job & Career | Job Search & Application | Complete application  |\n|  Find and pull up the YouTube video... | Media & Entertainment | Movies, TV, & Videos | Search/filter videos, Navigate within videos  |\n|  Look through these customer case studies... | Learning & Research | Research | Search/filter research information, Summarize/analyze research information  |\n|  Go through Amazon... | Shopping & Commerce | Goods | Search/filter products, Make product purchase  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 53,
      "width": 1700,
      "height": 2200,
      "text": "B.2 Agent Behavior for a Real Task The prompt asks the agent to find a round-trip flight between Boston and San Diego to attend the 2025 NeurIPS conference. The user prefers late-night direct flights and a lower price. The Figures below show some key steps in how the agent completes the task.[32] 35 steps completed $\\nvdash$ Preparing to assist you - I'll help you search for flights between Boston and San Diego for the NeurIPS conference. Let me start by creating a tab and searching for information about the conference dates, then look for flights that match your preferences. $\\mathbb{O}$ Creating to-do list Searching for NeurIPS conference dates Search for direct flights from Boston to San Diego Filter for late night departures and cheaper prices Searching $\\mathbb{Q}$ NeurIPS 2025 conference dates location Reviewing sources·10 2025 Dates and Deadlines 2025 Conference [D] Neurips 2025 being hosted at 3 locations.: r/MachineLearning NeurIPS 2025 Expo Schedule Overview NeurIPS 2025: The 39th Annual Conference on Neural Information ... NeurIPS 2025 - Mexico City Satellite Conference Conferences Future Meetings - NeurIPS 2025 neurips - Great! I found that NeurIPS 2025 is from December 2-7, 2025 in San Diego. Now let me create a tab and search for flights. Note: The agent first creates a to-do list that breaks the task into three steps. Because the flight dates are not specified, the agent first searches for the 2025 NeurIPS conference dates and confirms that they are found. Figure 10: Agent Behavior 1",
      "markdown": "# B.2 Agent Behavior for a Real Task\n\nThe prompt asks the agent to find a round-trip flight between Boston and San Diego to attend the 2025 NeurIPS conference. The user prefers late-night direct flights and a lower price. The Figures below show some key steps in how the agent completes the task.[32]\n\n35 steps completed  $\\nvdash$\nPreparing to assist you\n- I'll help you search for flights between Boston and San Diego for the NeurIPS conference. Let me start by creating a tab and searching for information about the conference dates, then look for flights that match your preferences.\n\n$\\mathbb{O}$  Creating to-do list\n\nSearching for NeurIPS conference dates\nSearch for direct flights from Boston to San Diego\nFilter for late night departures and cheaper prices\n\nSearching\n\n$\\mathbb{Q}$  NeurIPS 2025 conference dates location\n\nReviewing sources·10\n\n2025 Dates and Deadlines\n\n2025 Conference\n\n[D] Neurips 2025 being hosted at 3 locations.: r/MachineLearning\n\nNeurIPS 2025 Expo Schedule Overview\n\nNeurIPS 2025: The 39th Annual Conference on Neural Information ...\n\nNeurIPS 2025 - Mexico City Satellite Conference\n\nConferences Future Meetings - NeurIPS 2025\n\nneurips\n\n- Great! I found that NeurIPS 2025 is from December 2-7, 2025 in San Diego. Now let me create a tab and search for flights.\n\nNote: The agent first creates a to-do list that breaks the task into three steps. Because the flight dates are not specified, the agent first searches for the 2025 NeurIPS conference dates and confirms that they are found.\n\nFigure 10: Agent Behavior 1",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": [
        "https://www.perplexity.ai/search/search-for-the-best-flights-be-TNxDicWmSiW9gmcpa2pHNg#0"
      ]
    },
    {
      "page_number": 54,
      "width": 1700,
      "height": 2200,
      "text": "Updating to-do list Search for NeurIPS conference dates Searching for direct flights Filter for late night departures and cheaper prices !img-11.jpeg Creating tab !img-12.jpeg Perfect! Google Flights is loaded with Boston already in the origin field. Now I need to enter San Diego as the destination and set the dates around the conference (December 2-7, 2025). Let me fill in the destination and dates. !img-13.jpeg Clicking !img-14.jpeg Note: The agent then updates the to-do list and proceeds to the next item by searching flights. It operates on the website by entering destinations and dates. Figure 11: Agent Behavior 2",
      "markdown": "Updating to-do list\n\nSearch for NeurIPS conference dates\nSearching for direct flights\nFilter for late night departures and cheaper prices\n\n![img-11.jpeg](img-11.jpeg)\nCreating tab\n\n![img-12.jpeg](img-12.jpeg)\n\nPerfect! Google Flights is loaded with Boston already in the origin field. Now I need to enter San Diego as the destination and set the dates around the conference (December 2-7, 2025). Let me fill in the destination and dates.\n\n![img-13.jpeg](img-13.jpeg)\nClicking\n\n![img-14.jpeg](img-14.jpeg)\nNote: The agent then updates the to-do list and proceeds to the next item by searching flights. It operates on the website by entering destinations and dates.\nFigure 11: Agent Behavior 2",
      "blocks": [],
      "tables": [],
      "images": [
        {
          "id": "img-11.jpeg",
          "top_left_x": 244,
          "top_left_y": 774,
          "bottom_right_x": 518,
          "bottom_right_y": 961,
          "image_base64": null,
          "image_annotation": null
        },
        {
          "id": "img-12.jpeg",
          "top_left_x": 244,
          "top_left_y": 963,
          "bottom_right_x": 518,
          "bottom_right_y": 1150,
          "image_base64": null,
          "image_annotation": null
        },
        {
          "id": "img-13.jpeg",
          "top_left_x": 244,
          "top_left_y": 1344,
          "bottom_right_x": 518,
          "bottom_right_y": 1529,
          "image_base64": null,
          "image_annotation": null
        },
        {
          "id": "img-14.jpeg",
          "top_left_x": 244,
          "top_left_y": 1533,
          "bottom_right_x": 518,
          "bottom_right_y": 1718,
          "image_base64": null,
          "image_annotation": null
        }
      ],
      "hyperlinks": []
    },
    {
      "page_number": 55,
      "width": 1700,
      "height": 2200,
      "text": "!img-15.jpeg Figure 12: Agent Behavior 3",
      "markdown": "![img-15.jpeg](img-15.jpeg)\nFigure 12: Agent Behavior 3",
      "blocks": [],
      "tables": [],
      "images": [
        {
          "id": "img-15.jpeg",
          "top_left_x": 251,
          "top_left_y": 536,
          "bottom_right_x": 1443,
          "bottom_right_y": 1680,
          "image_base64": null,
          "image_annotation": null
        }
      ],
      "hyperlinks": []
    },
    {
      "page_number": 56,
      "width": 1700,
      "height": 2200,
      "text": "Good! Now it's \"Sorted by price\". The flights are now in price order: JetBlue 3:50 PM - 7:21 PM (Nonstop, 6h 31m) - $1,134 (cheapest) Alaska/American 4:26 PM - 8:06 PM (Nonstop, 6h 40m) - $1,502 Delta 5:25 PM - 8:56 PM (Nonstop, 6h 31m) - $1,857 Now let me check if there might be red-eye flights by changing the departure date to November 30th (Sunday night) which would arrive December 1st. Let me click on the departure date to change it. Clicking !img-16.jpeg Figure 13: Agent Behavior 4 !img-17.jpeg Note: The agent applies a price filter and observes options. Because options are limited, it expands the travel dates to look for red-eye flights.",
      "markdown": "Good! Now it's \"Sorted by price\". The flights are now in price order:\n\nJetBlue 3:50 PM - 7:21 PM (Nonstop, 6h 31m) - $1,134 (cheapest)\n\nAlaska/American 4:26 PM - 8:06 PM (Nonstop, 6h 40m) - $1,502\n\nDelta 5:25 PM - 8:56 PM (Nonstop, 6h 31m) - $1,857\n\nNow let me check if there might be red-eye flights by changing the departure date to November 30th (Sunday night) which would arrive December 1st. Let me click on the departure date to change it.\n\nClicking\n\n![img-16.jpeg](img-16.jpeg)\nFigure 13: Agent Behavior 4\n\n![img-17.jpeg](img-17.jpeg)\n\nNote: The agent applies a price filter and observes options. Because options are limited, it expands the travel dates to look for red-eye flights.",
      "blocks": [],
      "tables": [],
      "images": [
        {
          "id": "img-16.jpeg",
          "top_left_x": 258,
          "top_left_y": 1056,
          "bottom_right_x": 547,
          "bottom_right_y": 1249,
          "image_base64": null,
          "image_annotation": null
        },
        {
          "id": "img-17.jpeg",
          "top_left_x": 258,
          "top_left_y": 1254,
          "bottom_right_x": 547,
          "bottom_right_y": 1447,
          "image_base64": null,
          "image_annotation": null
        }
      ],
      "hyperlinks": []
    },
    {
      "page_number": 57,
      "width": 1700,
      "height": 2200,
      "text": "Excellent! Now I can see flights departing November 30 (Sunday). This is much better! I can see there are more nonstop options and the prices are cheaper. The flights shown are: JetBlue 7:00 AM - 10:39 AM (Nonstop, 6h 39m) - $1,173 JetBlue 10:02 AM - 1:34 PM (Nonstop, 6h 32m) - $1,173 JetBlue 3:50 PM - 7:21 PM (Nonstop, 6h 31m) - $1,173 Alaska/American 4:26 PM - 8:06 PM (Nonstop, 6h 40m) - $1,702 Delta 5:25 PM - 8:56 PM (Nonstop, 6h 31m) - $1,897 These are all Sunday flights. Now let me scroll down to see if there are any late night/red-eye flights departing Sunday night (which would arrive Monday). !img-18.jpeg $\\odot$ Scrolling !img-19.jpeg Figure 14: Agent Behavior 5 Note: The agent expands the dates and confirms that red-eye flights departing a day earlier are much cheaper.",
      "markdown": "Excellent! Now I can see flights departing November 30 (Sunday). This is much better! I can see there are more nonstop options and the prices are cheaper. The flights shown are:\n\nJetBlue 7:00 AM - 10:39 AM (Nonstop, 6h 39m) - $1,173\n\nJetBlue 10:02 AM - 1:34 PM (Nonstop, 6h 32m) - $1,173\n\nJetBlue 3:50 PM - 7:21 PM (Nonstop, 6h 31m) - $1,173\n\nAlaska/American 4:26 PM - 8:06 PM (Nonstop, 6h 40m) - $1,702\n\nDelta 5:25 PM - 8:56 PM (Nonstop, 6h 31m) - $1,897\n\nThese are all Sunday flights. Now let me scroll down to see if there are any late night/red-eye flights departing Sunday night (which would arrive Monday).\n\n![img-18.jpeg](img-18.jpeg)\n$\\odot$  Scrolling\n\n![img-19.jpeg](img-19.jpeg)\nFigure 14: Agent Behavior 5\n\nNote: The agent expands the dates and confirms that red-eye flights departing a day earlier are much cheaper.",
      "blocks": [],
      "tables": [],
      "images": [
        {
          "id": "img-18.jpeg",
          "top_left_x": 251,
          "top_left_y": 1104,
          "bottom_right_x": 525,
          "bottom_right_y": 1287,
          "image_base64": null,
          "image_annotation": null
        },
        {
          "id": "img-19.jpeg",
          "top_left_x": 251,
          "top_left_y": 1291,
          "bottom_right_x": 525,
          "bottom_right_y": 1474,
          "image_base64": null,
          "image_annotation": null
        }
      ],
      "hyperlinks": []
    },
    {
      "page_number": 58,
      "width": 1700,
      "height": 2200,
      "text": "Perfect! I selected the JetBlue 7:00 AM flight and now I can see the return flight options. The page shows: Outbound: BOS-SAN (selected: JetBlue 7:00 AM - 10:39 AM on Nov 30) Returning flights: Shows two options: JetBlue 8:31 PM - 5:02 AM+1 (Red-eye, arrives next day) - $1,173 JetBlue 11:38 AM - 8:14 PM - $1,313 Great! There's actually a red-eye return flight option. Now let me go back to see all the outbound flight options to compile a comprehensive summary. Let me click on \"BOS-SAN\" to go back. Clicking !img-20.jpeg Figure 15: Agent Behavior 6 !img-21.jpeg !img-22.jpeg !img-23.jpeg Note: The agent clicks on an outbound flight with the lowest price and proceeds to the inbound flight.",
      "markdown": "Perfect! I selected the JetBlue 7:00 AM flight and now I can see the return flight options. The page shows:\n\nOutbound: BOS-SAN (selected: JetBlue 7:00 AM - 10:39 AM on Nov 30)\n\nReturning flights: Shows two options:\n\nJetBlue 8:31 PM - 5:02 AM+1 (Red-eye, arrives next day) - $1,173\n\nJetBlue 11:38 AM - 8:14 PM - $1,313\n\nGreat! There's actually a red-eye return flight option. Now let me go back to see all the outbound flight options to compile a comprehensive summary. Let me click on \"BOS-SAN\" to go back.\n\nClicking\n\n![img-20.jpeg](img-20.jpeg)\nFigure 15: Agent Behavior 6\n\n![img-21.jpeg](img-21.jpeg)\n\n![img-22.jpeg](img-22.jpeg)\n\n![img-23.jpeg](img-23.jpeg)\n\nNote: The agent clicks on an outbound flight with the lowest price and proceeds to the inbound flight.",
      "blocks": [],
      "tables": [],
      "images": [
        {
          "id": "img-20.jpeg",
          "top_left_x": 246,
          "top_left_y": 888,
          "bottom_right_x": 525,
          "bottom_right_y": 1075,
          "image_base64": null,
          "image_annotation": null
        },
        {
          "id": "img-21.jpeg",
          "top_left_x": 246,
          "top_left_y": 1078,
          "bottom_right_x": 525,
          "bottom_right_y": 1262,
          "image_base64": null,
          "image_annotation": null
        },
        {
          "id": "img-22.jpeg",
          "top_left_x": 246,
          "top_left_y": 1265,
          "bottom_right_x": 525,
          "bottom_right_y": 1449,
          "image_base64": null,
          "image_annotation": null
        },
        {
          "id": "img-23.jpeg",
          "top_left_x": 246,
          "top_left_y": 1452,
          "bottom_right_x": 525,
          "bottom_right_y": 1639,
          "image_base64": null,
          "image_annotation": null
        }
      ],
      "hyperlinks": []
    },
    {
      "page_number": 59,
      "width": 1700,
      "height": 2200,
      "text": "Updating to-do list Search for NeurIPS conference dates Search for direct flights from Boston to San Diego Filter for late night departures and cheaper prices Perfect! I've completed the search for the best flights for the NeurIPS conference. Let me provide a comprehensive summary. Finished I've searched for the best flights between Boston and San Diego for the NeurIPS conference (December 2-7, 2025). Here's what I found: Conference Details - NeurIPS 2025: December 2-7, 2025 at the San Diego Convention Center neurips Direct Flight Options (sorted by price) Unfortunately, there are no true late-night/red-eye nonstop flights from Boston to San Diego. However, I found these nonstop options: Departing Sunday, November 30 (arriving day before conference): 1. JetBlue 7:00 AM - 10:39 AM - $1,173 (6h 39m) √ Best Price 2. JetBlue 10:02 AM - 1:34 PM - $1,173 (6h 32m) √ Best Price 3. JetBlue 3:50 PM - 7:21 PM - $1,173 (6h 31m) √ Best Price, Latest budget option 4. Alaska/American 4:26 PM - 8:06 PM - $1,702 (6h 40m) 5. Delta 5:25 PM - 8:56 PM - $1,897 (6h 31m) - Latest departure Departing Monday, December 1 (conference start date): 1. JetBlue 3:50 PM - 7:21 PM - $1,134 (6h 31m) √ Cheapest 2. Alaska/American 4:26 PM - 8:06 PM - $1,502 (6h 40m) 3. Delta 5:25 PM - 8:56 PM - $1,857 (6h 31m) Recommendation For your preference of late departures and cheaper prices, I recommend: Option 1 (Best Value): JetBlue departing Sunday, Nov 30 at 3:50 PM for $1,173 - This gives you: - Evening departure (closest to \"late night\" available) - Cheapest nonstop option - Arrival day before conference starts for buffer time Option 2 (Conference Day): JetBlue departing Monday, Dec 1 at 3:50 PM for $1,134 - Slightly cheaper but arrives evening of conference start Note: The latest nonstop departure is Delta at 5:25 PM, but it costs $1,897 (significantly more expensive). Note: The agent completes the task by presenting the recommendations to the user. Figure 16: Agent Behavior 7",
      "markdown": "# Updating to-do list\n\nSearch for NeurIPS conference dates\nSearch for direct flights from Boston to San Diego\nFilter for late night departures and cheaper prices\n\nPerfect! I've completed the search for the best flights for the NeurIPS conference. Let me provide a comprehensive summary.\nFinished\n\nI've searched for the best flights between Boston and San Diego for the NeurIPS conference (December 2-7, 2025). Here's what I found:\n\n# Conference Details\n\n- NeurIPS 2025: December 2-7, 2025 at the San Diego Convention Center neurips\n\n# Direct Flight Options (sorted by price)\n\nUnfortunately, there are no true late-night/red-eye nonstop flights from Boston to San Diego. However, I found these nonstop options:\n\nDeparting Sunday, November 30 (arriving day before conference):\n\n1. JetBlue 7:00 AM - 10:39 AM - $1,173 (6h 39m) √ Best Price\n2. JetBlue 10:02 AM - 1:34 PM - $1,173 (6h 32m) √ Best Price\n3. JetBlue 3:50 PM - 7:21 PM - $1,173 (6h 31m) √ Best Price, Latest budget option\n4. Alaska/American 4:26 PM - 8:06 PM - $1,702 (6h 40m)\n5. Delta 5:25 PM - 8:56 PM - $1,897 (6h 31m) - Latest departure\n\nDeparting Monday, December 1 (conference start date):\n\n1. JetBlue 3:50 PM - 7:21 PM - $1,134 (6h 31m) √ Cheapest\n2. Alaska/American 4:26 PM - 8:06 PM - $1,502 (6h 40m)\n3. Delta 5:25 PM - 8:56 PM - $1,857 (6h 31m)\n\n# Recommendation\n\nFor your preference of late departures and cheaper prices, I recommend:\n\nOption 1 (Best Value): JetBlue departing Sunday, Nov 30 at 3:50 PM for $1,173 - This gives you:\n\n- Evening departure (closest to \"late night\" available)\n- Cheapest nonstop option\n- Arrival day before conference starts for buffer time\n\nOption 2 (Conference Day): JetBlue departing Monday, Dec 1 at 3:50 PM for $1,134 - Slightly cheaper but arrives evening of conference start\n\nNote: The latest nonstop departure is Delta at 5:25 PM, but it costs $1,897 (significantly more expensive).\n\nNote: The agent completes the task by presenting the recommendations to the user.\n\nFigure 16: Agent Behavior 7",
      "blocks": [],
      "tables": [],
      "images": [],
      "hyperlinks": []
    },
    {
      "page_number": 60,
      "width": 1700,
      "height": 2200,
      "text": "C Early Adopter Survey To better understand who the early users of Comet are, we invited a subset of users to complete a survey in November 2025. A typical respondent is a male aged 35 or older who works full-time in the technology industry, is either a current Perplexity user or has a strong interest in AI-powered browsing, and uses Comet roughly equally across professional and personal contexts. As is often the case with new technology products, we expect user composition to change significantly over time as Comet diffuses into the population. D Validation of Agent Use Cases Classifier We randomly select 1,000 agentic queries for manual labeling.33 These queries are sampled from a larger set previously classified as containing no harmful content. To preserve representativeness, we retain queries that may include personal information, while redacting names, email addresses, physical addresses, and phone numbers. Each query in the sample is independently labeled by two or three annotators using our agentic taxonomy. Out of the 1,000 queries, 370 show disagreement among annotators on what the primary topic and subtopic are. Most disagreements stemmed from variations in labeling quality across annotators. For each query that shows disagreement, our team manually reviews it and labels it against our taxonomy. The final golden dataset includes the 630 queries on which all annotators agreed, along with the 370 queries we labeled. We validate the classifier against the golden dataset and across multiple runs, and the agreement rates are listed in Table 30. tbl-30.md Note: The table shows the agreement rate between the classifier label and the golden dataset and across runs. The tasks are specific to subtopics, so when the classifier disagrees with the golden dataset or across runs on topics or subtopics, the tasks will by definition have zero agreement rates. Therefore, the task agreement rate is conditional on topic- and subtopic-level agreement. The across-runs agreement rate is the average pairwise agreement rate across three runs. Table 30: Agent Use Case Classification Validation",
      "markdown": "# C Early Adopter Survey\n\nTo better understand who the early users of Comet are, we invited a subset of users to complete a survey in November 2025. A typical respondent is a male aged 35 or older who works full-time in the technology industry, is either a current Perplexity user or has a strong interest in AI-powered browsing, and uses Comet roughly equally across professional and personal contexts. As is often the case with new technology products, we expect user composition to change significantly over time as Comet diffuses into the population.\n\n# D Validation of Agent Use Cases Classifier\n\nWe randomly select 1,000 agentic queries for manual labeling.33 These queries are sampled from a larger set previously classified as containing no harmful content. To preserve representativeness, we retain queries that may include personal information, while redacting names, email addresses, physical addresses, and phone numbers. Each query in the sample is independently labeled by two or three annotators using our agentic taxonomy. Out of the 1,000 queries, 370 show disagreement among annotators on what the primary topic and subtopic are. Most disagreements stemmed from variations in labeling quality across annotators. For each query that shows disagreement, our team manually reviews it and labels it against our taxonomy. The final golden dataset includes the 630 queries on which all annotators agreed, along with the 370 queries we labeled. We validate the classifier against the golden dataset and across multiple runs, and the agreement rates are listed in Table 30.\n\n[tbl-30.md](tbl-30.md)\n\nNote: The table shows the agreement rate between the classifier label and the golden dataset and across runs. The tasks are specific to subtopics, so when the classifier disagrees with the golden dataset or across runs on topics or subtopics, the tasks will by definition have zero agreement rates. Therefore, the task agreement rate is conditional on topic- and subtopic-level agreement. The across-runs agreement rate is the average pairwise agreement rate across three runs.\n\nTable 30: Agent Use Case Classification Validation",
      "blocks": [],
      "tables": [
        {
          "table_id": "tbl-30.md",
          "format": "markdown",
          "content": "|  Variable | Golden Dataset (%) | Across Runs (%)  |\n| --- | --- | --- |\n|  Topic | 89.4 | 97.2  |\n|  Subtopic | 83.2 | 94.6  |\n|  Task | 81.3 | 88.2  |\n|  Usage Context | 82.9 | 96.3  |",
          "bbox": [
            0,
            0,
            0,
            0
          ]
        }
      ],
      "images": [],
      "hyperlinks": [
        "https://wildchat.allen.ai/"
      ]
    }
  ],
  "metadata": {
    "page_count": 60,
    "language": "en",
    "created_at": "2025-12-30T07:01:10.379396+00:00",
    "ocr_runtime_ms": 7450,
    "model": "mistral-ocr-latest",
    "usage_info": {
      "pages_processed": 60,
      "doc_size_bytes": 2715976
    },
    "warnings": []
  },
  "raw": {
    "provider": "mistral",
    "response": {
      "pages": [
        {
          "index": 0,
          "markdown": "# The Adoption and Usage of AI Agents: Early Evidence from Perplexity\n\nJeremy Yang^{1} Noah Yonack^{2}\nKate Zyskowski^{2} Denis Yarats^{2} Johnny Ho^{2} Jerry Ma^{2}\n^{1}Harvard University\n^{2}Perplexity\n\n###### Abstract\n\nThis paper presents the first large-scale field study of the adoption, usage intensity, and use cases of general-purpose AI agents operating in open-world web environments. Our analysis centers on Comet, an AI-powered browser developed by Perplexity, and its integrated agent, Comet Assistant. Drawing on hundreds of millions of anonymized user interactions, we address three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for? Our findings reveal substantial heterogeneity in adoption and usage across user segments. Earlier adopters, users in countries with higher GDP per capita and educational attainment, and individuals working in digital or knowledge-intensive sectors—such as digital technology, academia, finance, marketing, and entrepreneurship—are more likely to adopt or actively use the agent. To systematically characterize the substance of agent usage, we introduce a hierarchical agentic taxonomy that organizes use cases across three levels: topic, subtopic, and task. The two largest topics—Productivity & Workflow and Learning & Research—account for 57% of all agentic queries, while the two largest subtopics—Courses and Shopping for Goods—make up 22%. The top 10 out of 90 tasks represent 55% of queries. Personal use constitutes 55% of queries, while professional and educational contexts comprise 30% and 16%, respectively. In the short term, use cases exhibit strong stickiness, but over time, users tend to shift toward more cognitively oriented topics. The diffusion of increasingly capable AI agents carries important implications for researchers, businesses, policymakers, and educators, inviting new lines of inquiry into this rapidly emerging class of AI capabilities.\n\n##",
          "images": [],
          "tables": [],
          "hyperlinks": [
            "https://arxiv.org/abs/2512.07828v2",
            "mailto:jeryang%40hbs.edu",
            "mailto:jerry%40perplexity.ai"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 1,
          "markdown": "# 1 Introduction\n\n2025 is frequently heralded as the year of agentic AI, as the frontier shifts from conversational Large Language Model (LLM) chatbots to action-oriented AI agents. This narrative has emerged as AI agents have progressed from a largely theoretical construct to widely productized assistants, demonstrating strong potential to transform work and daily life by planning and executing complex tasks in response to high-level human instructions with little supervision [Wooldridge and Jennings, 1995]. AI agents could profoundly reshape individual workflows, as well as organizational and market structures, by increasing productivity and efficiency and lowering transaction costs as autonomous participants in both consumption and production processes [Hadfield and Koh, 2025, Rothschild et al., 2025, Shahidi et al., 2025]. In aggregate, Precedence Research estimates that the global agentic AI market size will grow from $8 billion in 2025 to $199 billion by 2034. PwC forecasts that the overall associated economic contribution could reach between $2.6 trillion and $4.4 trillion annually by 2030.\n\nDespite this enthusiasm and its far-reaching economic implications, systematic behavioral evidence on how people actually adopt and use AI agents in the field remains limited, often relying on non-representative firm surveys [Pan et al., 2025] or focusing on specialized agents such as coding assistants [Sarkar, 2025]. Launched in July 2025, Comet by Perplexity is among the first widely adopted AI browsers and offers the embedded Comet Assistant as a general-purpose AI agent capable of performing user-specified tasks across open-world web environments. By studying hundreds of millions of anonymized user interactions with Comet and Comet Assistant, we narrow the gap by providing early insights into three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for?\n\n# AI Agents\n\nWe define agentic AI systems as AI assistants capable of autonomously pursuing user-defined goals by planning and taking multi-step actions on a user's behalf to interact with and effect outcomes across real-world environments.\n\nIn general, agentic AI is a concept that resists precise definition. Despite variations, the definitions share several common themes: goal orientation, action taking, and autonomy. For instance, Shavit et al. [2023] defines agentic AI systems as those capable of taking actions that consistently contribute toward achieving goals over extended periods without their behavior being explicitly specified in advance, and Schluntz and Zhang [2024] describes agents as systems that dynamically direct their own processes and tool use, maintaining control over how they",
          "images": [],
          "tables": [],
          "hyperlinks": [
            "https://finance.yahoo.com/news/nvidia-jensen-huang-says-ai-044815659.html",
            "https://x.com/gdb/status/1879327050819104778",
            "https://www.aboutamazon.com/news/company-news/amazon-ceo-andy-jassy-on-generative-ai",
            "https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality",
            "https://www.precedenceresearch.com/agentic-ai-market",
            "https://www.pwc.com/m1/en/publications/agentic-ai-the-new-frontier-in-genai.html",
            "https://knowledge.wharton.upenn.edu/special-report/2025-ai-adoption-report/"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 2,
          "markdown": "complete tasks. Perplexity Team [2025] refines these definitions by replacing the term \"agent\" with \"assistant,\" arguing that each AI agent is best understood as a personal, powerful generalist serving the interests of a single user or customer, in contrast to a human agent who typically manages multiple clients within narrow professional roles or licensing constraints and often faces conflicting incentives. In addition, we place particular emphasis on the agent's ability not only to exchange information with its environment but also to actively modify it.\n\nUnder the ReAct framework, an agentic workflow typically cycles automatically between three iterative phases to achieve the end goal: thinking, acting, and observing [Yao et al., 2022]. In the thinking phase, the agent interprets the goal from the query and devises a step-by-step plan to achieve it. In the acting phase, the agent executes actions by controlling external tools to interact with its environment. In the observing phase, the agent processes feedback from its environment and returns to the thinking phase to confirm or revise its plan as needed.\n\nIt is also useful to contrast LLM chatbots and AI agents. Both chatbots and agents build on LLMs, but agents extend chatbots' capabilities beyond conversations to include autonomous actions. LLMs serve as the \"brain\" of an agent, functioning as the central reasoning engine that processes information, evaluates options, and makes decisions. Tools are the \"hands\" that connect the agent's reasoning to the external world, enabling it to act upon its environment. More advanced agent capabilities also include multi-agent orchestration—the ability to interface with and manage workflows across multiple collaborating agents—and self-evolution—the ability to identify gaps in pre-specified resources and dynamically expand them.\n\n# Research Setting: Perplexity and Comet\n\nPerplexity is an AI-powered platform that helps users discover, analyze, and act on information. Instead of requiring users to navigate through pages of results (\"blue links\"), as traditional search engines do, Perplexity interacts with the web on users' behalf to deliver direct, verifiable, and conversational answers. Each answer includes inline citations and links to original sources, enabling users to verify information and explore topics in more detail.[9]\n\nComet is a browser from Perplexity that embeds an AI assistant directly into the browsing experience, helping users discover, analyze, and act on information more effectively. Its core feature, Comet Assistant, operates as an autonomous agent that takes actions and completes open-world web-based tasks on behalf of users. To fulfill user requests, Comet Assistant can execute a variety of tasks, including scheduling meetings, editing documents, sending emails, booking flights, making purchases, and more.[10]\n\nComet was launched on July 9, 2025, on desktop for subscribers to Perplexity's Max tier $^{11}$ , along with selected users from a pre-launch waitlist. $^{12}$  Access expanded to Pro subscribers on",
          "images": [],
          "tables": [],
          "hyperlinks": [
            "https://huggingface.co/learn/agents-course/en/unit1/agent-steps-and-structure",
            "https://www.kaggle.com/whitepaper-introduction-to-agents",
            "https://www.perplexity.ai/help-center/en/articles/10352155-what-is-perplexity",
            "https://www.perplexity.ai/hub/blog/introducing-comet"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 3,
          "markdown": "August 13, 2025, beginning with users in the United States.¹³ On October 2, 2025, Comet became available to all users worldwide.¹⁴ In addition to these general cohorts, Comet was opened to university students globally on September 3, 2025.\n\n## Data\n\nOur analysis relies on three samples collected from Comet desktop users between July 9 and October 22, 2025.¹⁵ First, we use anonymized data from the entire population of Comet users and their queries to provide high-level, aggregated statistics on agent adoption and usage intensity; this sample includes millions of users and hundreds of millions of queries. Second, we analyze a random sample of 100,000 Comet users and classify their O*NET occupation clusters and subclusters based on the National Career Clusters Framework to examine variation across occupations.¹⁶ Third, we analyze a separate random sample of 100,000 agent users and classify all of their agentic queries using a novel hierarchical agentic taxonomy to better understand common use cases at the topic, subtopic, and task levels.\n\n## Summary of Findings\n\nWe report two sets of results on the adoption and use of AI agents: the extensive and intensive margins and a comprehensive taxonomy of use cases.\n\n## Adoption and usage intensity\n\nOverall, agent adoption and usage intensity demonstrate sustained growth with acceleration following the general availability (GA) of Comet. The post-GA period accounts for 60% of agent adopters and 50% of agentic queries throughout our sampling period. Earlier Comet adopters (those with pre-GA access) represent a disproportionately large share of agent adopters and agentic queries relative to their user share. The disparity is more pronounced in usage intensity than in adoption—an average user in the first cohort (July 9) is twice as likely to adopt the agent and makes nine times as many agentic queries as an average user in the GA cohort (October 2). At the country level, adoption and usage intensity show strong positive correlations with GDP per capita and average years of education. At the occupational level, adopters and queries tend to come more from digital or knowledge-intensive domains. Digital technology¹⁷ represents the largest occupational cluster, comprising 28% of adopters and 30% of queries, followed by academia, finance, marketing, and entrepreneurship. These occupational clusters collectively\n\n¹³ https://www.perplexity.ai/hub/blog/the-intelligent-business-introducing-comet-for-enterprise-pro\n¹⁴ https://www.perplexity.ai/hub/blog/comet-is-now-available-to-everyone-worldwide\n¹⁵ We define Comet users as those who made at least one query on Comet during our study period. We use October 22, 2025, as the cutoff date because a major agent update began rolling out to selected users on October 23, which could affect adoption and usage patterns thereafter. The new agent was launched to all users on November 6. The updated agent performs 23% better than the previous version and offers greater multitasking capacity across multiple tabs. The agent we analyze in our data operates in a single web environment. For more details, see: https://www.perplexity.ai/hub/blog/the-new-comet-assistant.\n¹⁶ https://www.ometonline.org/find/career?c=0 https://careertech.org/career-clusters/\n¹⁷ The Digital Technology Career Cluster focuses on developing digital systems for communication and data storage using critical technologies such as artificial intelligence (AI), data analytics, and cybersecurity. https://careertech.org/career-clusters/digital-technology/",
          "images": [],
          "tables": [],
          "hyperlinks": [
            "https://www.perplexity.ai/hub/blog/the-intelligent-business-introducing-comet-for-enterprise-pro",
            "https://www.perplexity.ai/hub/blog/comet-is-now-available-to-everyone-worldwide",
            "https://www.perplexity.ai/hub/blog/the-new-comet-assistant",
            "https://www.onetonline.org/find/career?c=0",
            "https://careertech.org/career-clusters/",
            "https://careertech.org/career-clusters/digital-technology/"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 4,
          "markdown": "account for over 70% of total adopters and queries. They also tend to have higher agent adopter or agentic query shares than their user shares.\n\n### Use cases\n\nWe illustrate the hierarchical structure of our agentic taxonomy in Figure 1 and report our complete taxonomy in Table 1. Productivity is the dominant topic with a 36% share. It is followed by learning (21%), media (16%), and shopping (10%). The most prevalent subtopics with over 5% query share include courses (13%), goods shopping (9%), research (8%), document editing (8%), account management (7%), and social media (7%). The most frequently observed tasks are exercise assistance (9%), research information summarization and analysis (7%), document creation and editing (7%), product search and filtering (6%), and research information search and filtering (6%). We also study the use of agents across environments, which are the websites on which these tasks are performed. The concentration of environments varies substantially across subtopics: the top 5 environments account for 97% of queries in music, 97% in videos, and 96% in professional networking, compared to only 28% in account management, 35% in shopping for services, and 37% in project management. Across all use cases, 55% of agentic queries originate from personal use settings, 30% from professional use settings, and 16% from educational use settings. In the short term, users show strong within-topic persistence, demonstrating stickiness in use cases; when topic transitions occur, they are more likely to migrate toward productivity, learning, or media topics. Over time, query shares shift from travel and media topics to productivity, learning, and career topics.",
          "images": [],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 5,
          "markdown": "Figure 1: Hierarchical Structure of the Agentic Taxonomy\n![img-0.jpeg](img-0.jpeg)\nNote: A topic contains multiple subtopics; a subtopic contains multiple tasks; a task can be connected to multiple environments; and an environment can be connected to one or multiple tasks within or across different topics and subtopics. The colors indicate different topics, solid lines indicate connections between topics, subtopics, and tasks, and dashed lines indicate which tasks are performed in which environments. Note that task 1.1.1 can be performed in environments A and B, whereas task 1.1.2 can only be performed in environment B. Tasks 2.1.1 and 2.1.2 indicate similar patterns. Environment B spans subtopics 1.1 and 2.1, whereas environments A and C are specific to a single subtopic. We substantiate the structure with some examples. The query \"unsubscribe me from all promotional emails that I receive more than twice per month\" would be labeled as {Topic: Productivity &amp; Workflow, Subtopic: Email Management, Task: Search or filter emails, Delete or unsubscribe emails}. In this case, searching or filtering emails, and deleting or unsubscribing from them, can both be performed in environments such as Gmail or Outlook. Now imagine another query that gets classified into {Topic: Shopping &amp; Commerce, Subtopic: Shopping for Goods, Task: Search discounts, Make product purchase}; both tasks can be performed on Instacart, whereas only search discounts can be performed on SimplyCodes, as it only shows discount codes and does not sell products directly. Facebook is one example of a cross-topic environment—it could be the environment for Media &amp; Entertainment queries, but also for Shopping &amp; Commerce queries when they are about products listed on Facebook Marketplace.",
          "images": [
            {
              "id": "img-0.jpeg",
              "top_left_x": 341,
              "top_left_y": 666,
              "bottom_right_x": 1329,
              "bottom_right_y": 1174,
              "image_base64": null,
              "image_annotation": null
            }
          ],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 6,
          "markdown": "[tbl-0.md](tbl-0.md)\n\nNote: The table contains all topics, subtopics, and tasks in the agentic taxonomy, except \"Other\". Topics and subtopics are general goals, and tasks are specific tasks the agent is expected to complete to achieve those goals. A query is classified into one topic, one subtopic underneath that topic, and one or more tasks underneath that subtopic. Queries that cannot be classified into the taxonomy at a given level are labeled as \"Other\" at that level and all subsequent levels. For example, a query that does not belong to any of the topics would be labeled as \"Other\" at topic, subtopic, and task levels; a query that belongs to productivity but does not belong to any of the subtopics under productivity will be labeled as \"Other\" at subtopic and task levels; a query that belongs to productivity and email management but does not belong to any of the tasks under email management will be labeled as \"Other\" at the task level.\n\nTable 1: Agentic Taxonomy—Topics, Subtopics, and Tasks",
          "images": [],
          "tables": [
            {
              "id": "tbl-0.md",
              "content": "|  Topics | Subtopics | Tasks  |\n| --- | --- | --- |\n|  Productivity & Workflow | Account Management | Register/log in to accounts, Manage settings/profiles, Manage files, Summarize/analyze account information  |\n|   |  Document & Form Editing | Create/edit documents, Search/filter documents, Summarize/analyze documents  |\n|   |  Multimedia Editing | Create/edit multimedia, Search/filter multimedia, Summarize/analyze multimedia  |\n|   |  Email Management | Search/filter emails, Create/edit emails, Send emails, Delete/unsubscribe emails, Summarize/analyze emails  |\n|   |  Spreadsheet & Data Editing | Create/edit spreadsheets, Search/filter spreadsheets, Summarize/analyze spreadsheets  |\n|   |  Computer Programming | Create/edit code, Execute code, Summarize/analyze code  |\n|   |  Investments & Banking | Search/filter stocks, Buy/sell stocks, Summarize/analyze investment information, Summarize/analyze banking information  |\n|   |  Project Management | Create/edit projects, Summarize/analyze project information  |\n|   |  Calendar Management | Create/edit events, Check availability, Search/filter events, Summarize/analyze events  |\n|  Learning & Research | Courses | Navigate courses, Summarize/analyze course materials, Assist exercises  |\n|   |  Research | Search/filter research information, Summarize/analyze research information  |\n|  Media & Entertainment | Social Media & Messaging | Search/filter social media posts, Summarize/analyze social media posts, Create social media posts, Engage with social media posts, Send social media/text messages  |\n|   |  Online Games | Search/filter online games, Summarize/analyze online game information, Play online games  |\n|   |  Movies, TV, & Videos | Search/filter videos, Summarize/analyze videos, Play videos, Navigate within videos, Manage playlists  |\n|   |  Music & Podcasts | Search/filter music/podcasts, Summarize/analyze music/podcasts, Play music/podcasts, Manage playlists  |\n|   |  News | Search/filter news, Summarize/analyze news  |\n|   |  Sports | Search/filter match/player information, Summarize/analyze match/player statistics  |\n|  Shopping & Commerce | Goods | Search/filter products, Search discounts, Summarize/analyze product information, Add products to cart, Make product purchase, Manage orders  |\n|   |  Services | Search/filter products, Search discounts, Summarize/analyze product information, Add products to cart, Make product purchase, Manage orders  |\n|  Travel & Leisure | Flights & Transportation | Search/filter flights & transportation, Summarize/analyze flights & transportation, Add flights & transportation to cart, Book flights & transportation  |\n|   |  Trip Itineraries | Search/filter destinations, Plan trips, Summarize/analyze trips  |\n|   |  Lodging | Search/filter lodging, Summarize/analyze lodging information, Add lodging to cart, Book lodging  |\n|   |  Restaurants | Search/filter restaurants, Summarize/analyze restaurant information, Book restaurants  |\n|  Job & Career | Job Search & Application | Search/filter jobs, Summarize/analyze job descriptions, Complete applications  |\n|   |  Professional Networking | Search/filter professional profiles, Summarize/analyze professional profiles, Send professional connection requests/messages, Engage with professional profiles/posts  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 7,
          "markdown": "The remainder of this paper is structured as follows. Section 2 reviews related literature and highlights our contributions. Section 3 describes our sampling methodology and data privacy safeguards. Section 4 explains the development of our hierarchical agentic taxonomy. Section 5 presents our main findings on AI agent adoption patterns, usage intensity, and use cases. Finally, Section 6 discusses the implications of our findings for researchers, businesses, and policymakers, while acknowledging limitations and identifying promising avenues for future research that we aim to pursue. Key figures and tables are included in the main text. Additional figures, tables, and other supplementary materials are provided in the Appendices.\n\n# 2 Related Work\n\nOur paper is directly related to the literature on how people use LLMs and AI agents in real-world settings. $^{18}$  Our paper extends recent work on the adoption and usage of LLM chatbots. Several prominent studies have examined this topic, including Handa et al. [2025c], which documents user interactions with Claude, and Zhao et al. [2024] and Chatterji et al. [2025], which analyze how people use ChatGPT. Anthropic has also released detailed analyses focusing on specific user groups, such as university students [Handa et al., 2025a], educators [Bent et al., 2025], and different geographies and enterprises [Appel et al., 2025]. In addition, Aubakirova et al. [2025] uses OpenRouter data to study LLM chatbot usage across both open- and closed-source models. These papers developed taxonomies to categorize standard Q&amp;A queries. We also create a taxonomy using internal data from an AI product; however, our key contribution is the focus on agentic queries. The main difference is that Q&amp;A queries focus on information exchange between the user and model in a conversation. In contrast, agentic queries focus on the agent executing tasks on the user's behalf in an external environment.\n\nEvidence on how people use AI agents in the field is limited and typically focuses on specific use cases, such as coding. For example, Anthropic [2025b] studies the usage of Claude Code, a coding agent, in software development, and Sarkar [2025] investigates the adoption, usage, and productivity impact of coding agents in Cursor. Our contribution differs in that we analyze a general-purpose agent operating across all common use cases.[19]\n\n# 3 Data\n\n# Sampling\n\nOur analysis leverages three samples collected between July 9 and October 22, 2025—that is, from the launch date to 20 days after general availability. Each sample is tailored to a particular",
          "images": [],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 8,
          "markdown": "set of research questions.\n\nWe define a Comet user as a user who has made at least one query on Comet during the study period. At the user level, we exclude all enterprise users, users under the Perplexity for Government program, users who deleted their accounts during the sampling period, users who opted out of data retention for model training during that period, and logged-out users. At the query level, we define an agentic query as one that involves the agent taking control of the browser or taking actions on external applications—such as email or calendar clients—through connectors built on the Model Context Protocol (MCP) or via API calls. Under this stricter definition, we do not consider all queries with tool use (such as web search or code interpreter) as agentic, since these tools merely exchange information with external environments but do not manipulate them. When users onboard onto Comet, sample agentic queries are shown for demonstration purposes; we remove these queries to focus only on user-initiated ones. In rare cases, a single agentic query might trigger multiple browser-control, MCP, or API calls; we exclude such cases to focus on queries that trigger a single call, ensuring a clean inference of user intent. Lastly, we exclude queries made in Comet’s incognito mode. We describe the three samples we analyze below.\n\n### Sample A: The population of Comet users and queries\n\nWe use the entire population of millions of users and hundreds of millions of queries on Comet—both agentic and non-agentic—during the sampling period to understand overall patterns in adoption and usage intensity.\n\n### Sample B: A random sample of Comet users and queries\n\nWe draw random samples of 100,000 Comet users and their recent queries—both agentic and non-agentic—during the study period to infer their O*NET occupation clusters and subclusters, enabling us to examine variation in adoption and usage intensity across occupations. The sampling includes two stages. First, a random set of users is selected, then for each user, a random set of queries from recent dates is selected. The sampled queries are then concatenated into a single string and labeled using a classifier against the occupation taxonomy. We include university students as a separate cluster as they are not included in the occupation taxonomy.\n\n### Sample C: A random sample of Comet agent users and all their agentic queries\n\nWe draw another random sample of 100,000 agent users and classify all their agentic queries using a novel agentic taxonomy to identify common use cases. The sampling is performed only at the user level: once a user is selected, all their agentic queries are included in the analysis. This procedure allows us to track within-user agent usage trajectories and uncover longitudinal patterns. In large user samples, the queries are also representative of query-level estimands,",
          "images": [],
          "tables": [],
          "hyperlinks": [
            "https://www.anthropic.com/news/model-context-protocol",
            "https://www.onetonline.org/find/career?c=0"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 9,
          "markdown": "including common use cases. For the same sample of users, we further infer their O*NET occupation clusters and subclusters.\n\n### Data Privacy\n\nWe follow industry standards and implement multiple safeguards to ensure that no human uses any personally identifiable information (PII) at any point in the analysis.\n\nFirst, as noted above, enterprise users, users under the Perplexity for Government program, users who deleted their accounts during the sampling period, users who opted out of data retention for model training during that period, logged-out users, and queries made in incognito mode are excluded from the analysis. Second, our analysis does not use any demographic information, names, email addresses, or other real-world identifiers; all user-level matching is performed through internal numerical user IDs. Third, we employ automated classifiers to label occupations and use cases. The classifier input is not the raw query text but a reformulated description of the underlying intent, enriched with context such as prior queries in the same conversation and the website on which the query was made. Lastly, all results reported in the paper are presented only in a highly aggregated form.\n\n## 4 Agentic Taxonomy\n\nWe develop a hierarchical agentic taxonomy guided by two principles. First, it should comprehensively capture common agentic intents so that it can generalize to other agentic products beyond Comet. Second, it should have a hierarchical structure that reveals higher-level goals while distinguishing specific lower-level tasks and actions.\n\nTo achieve these goals, we adopt a bottom-up approach consisting of three phases: exploration, refinement, and classification. In the exploration phase, we draw a random sample of agentic queries, extract their embeddings, and apply K-means clustering to group them based on semantic similarity. Queries are then sampled from each cluster and concatenated into a single string representing that cluster. We then summarize each concatenated string to interpret the meaning of each cluster. In the refinement phase, we manually examine the cluster labels identified in the previous step to merge, split, trim, or expand them, following the guiding principles. When a significant share of queries is labeled as “Other”, suggesting that the provided taxonomy does not sufficiently capture them, we re-classify the queries in that cluster using the bottom-up approach in the first step to identify clusters missing from the taxonomy and update it. Finally, we classify agentic queries within the finalized taxonomy using a query classification model.\n\nOur final taxonomy consists of three hierarchical levels—*topic*, *subtopic*, and *task*—as illustrated in a stylized diagram in Figure 1, along with their connections to the environments the tasks are performed in. The full taxonomy is summarized in Table 1.",
          "images": [],
          "tables": [],
          "hyperlinks": [
            "https://www.perplexity.ai/hub/legal/privacy-policy"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 10,
          "markdown": "Topics and subtopics are top- and mid-level use cases of the agent, indicating the overall goal, while tasks are the specific tasks the agent is expected to complete to achieve that goal. Each query is classified into one topic, one subtopic, and one or more tasks. For instance, the query “unsubscribe me from all promotional emails that I receive more than twice per month” would be labeled as {Topic: Productivity & Workflow, Subtopic: Email Management, Task: Search or filter emails, Delete or unsubscribe emails}.\n\nThe environments the agent operates in are observed in the data and can be connected to our taxonomy. Tasks in a particular subtopic are performed in a specific set of environments, and each environment might involve one or more of these tasks. For instance, under the subtopic Email Management, tasks such as Search or filter emails and Delete or unsubscribe emails can both be performed in environments such as Gmail or Outlook; under Shopping for Goods, Search discounts and Make product purchase can both be performed on Instacart, whereas only Search discounts can be performed on SimplyCodes as it only shows discount codes and does not sell products directly. Furthermore, an environment might cut across multiple topics and subtopics. For instance, Facebook could be the environment for Media & Entertainment queries, but also Shopping & Commerce queries when they are about products listed on Facebook Marketplace. We further categorize the usage context into personal, professional, and educational domains.\n\nWe validate the classification accuracy against a golden dataset of 1,000 anonymized and desensitized queries. The classifier-assigned labels agree with the topics, subtopics, tasks, and usage context in the golden dataset 89%, 83%, 81%, and 83% of the time, respectively. More details about the validation are provided in Appendix D.\n\n## 5 Main Results\n\nWe first discuss the results on the adoption (extensive margin) and usage intensity (intensive margin), and then the use cases (agentic taxonomy).\n\n### 5.1 Adoption and Usage Intensity\n\nWe define agent adopters as users who had at least one agentic query in the sampling period. The results below are all based on Sample A, except for occupation, which is based on Sample B.\n\nFigure 6 in Appendix A shows that agent adoption and overall usage as measured by agentic query volumes are growing steadily over the period studied, with an increased pace after Comet became generally available. About 60% of agent users were acquired, and 50% of agentic queries occurred post-GA. The query volumes grow at a slightly higher rate than adopters.\n\nWe analyze the adoption and usage patterns of user segments defined by cohort, country, and occupation. To capture the magnitude of adoption and usage within a user segment relative to its user share, we define the Perplexity Agent Adoption Ratio (AAR) and the Agent Usage Ratio (AUR) as the ratio of a segment’s agent adopter share or agentic query share to its user share.",
          "images": [],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 11,
          "markdown": "An AAR or AUR greater than one indicates that a segment is over-represented in the adopters or queries relative to their population base, and vice versa.\n\n# By cohort\n\nTable 2 shows that among the three cohorts by access dates, earlier adopters (those with access before GA) account for about  $30\\%$  of total users, but about  $50\\%$  of agent adopters and  $70\\%$  of agentic queries. The disparity is more pronounced in usage intensity than in adoption—an average user in the first cohort (July 9) is twice as likely to adopt the agent but makes nine times as many agentic queries as an average user in the GA cohort (October 2). AAR and AUR both decrease in the order of access cohorts.\n\nIn general, the composition of early adopters is endogenous to the rollout plan; in our case, it is based on the subscription tiers. Nonetheless, these results are consistent with general patterns in the adoption and usage of new technologies [Moore, 1991]: early adopters disproportionately drive initial adoption and usage, and subsequent diffusion may require additional educational efforts. With improved agent-to-agent collaboration capabilities and standardized protocols, one might expect stronger network effects that could accelerate adoption and usage in the future.[26]\n\n[tbl-1.md](tbl-1.md)\n\nNote: The table shows the agent adoption and agentic query by cohort. User share is the number of users in each cohort divided by the total users. Agent adopter and query share are the numbers of adopters and agentic queries in each cohort, divided by the total number of adopters and agentic queries. AAR (Agent Adoption Ratio) is the ratio between agent adopter share and user share. AUR (Agent Usage Ratio) is the ratio between agentic query share and user share. AAR and AUR greater (less) than 1 indicate that a cohort is over-represented (under-represented) in agent adopters and queries relative to their user base.\n\nTable 2: Agent Adoption and Agentic Query by Cohort\n\n# By country\n\nFigure 2 and 3 show that there are strong positive correlations between log agent adopters per million population and log GDP per capita ( $r = 0.85$ ,  $p &lt; 0.001$ ,  $R^2 = 0.73$ ) and years of education ( $r = 0.75$ ,  $p &lt; 0.001$ ,  $R^2 = 0.56$ ), where  $r$  is the correlation coefficient,  $p$  is the p-value of the correlation coefficient, and  $R^2$  is the R-squared of the regression lines. The correlations between log agentic queries per million population and log GDP per capita ( $r = 0.86$ ,  $p &lt; 0.001$ ,  $R^2 = 0.74$ ) and years of education ( $r = 0.75$ ,  $p &lt; 0.001$ ,  $R^2 = 0.57$ ) follow a similar pattern. Together, they suggest that relatively more economically developed and educated countries tend to adopt and use the agent more.[27]",
          "images": [],
          "tables": [
            {
              "id": "tbl-1.md",
              "content": "|  Cohort | User Share (%) | Agent Adopter Share (%) | Agentic Query Share (%) | AAR | AUR  |\n| --- | --- | --- | --- | --- | --- |\n|  July 9 | 4.3 | 7.7 | 18.9 | 1.79 | 4.40  |\n|  August 13 | 28.3 | 38.1 | 48.5 | 1.35 | 1.71  |\n|  October 2 | 67.4 | 54.2 | 32.7 | 0.80 | 0.49  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [
            "https://a2a-protocol.org/latest/"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 12,
          "markdown": "![img-1.jpeg](img-1.jpeg)\n(a) Log GDP Per Capita vs. Log Agent Adopters Per Million Population\n\n![img-2.jpeg](img-2.jpeg)\n(b) Average Years of Education vs. Log Agent Adopters Per Million Population\nFigure 2: Log GDP Per Capita and Average Years of Education vs. Log Agent Adopters Per Million Population by Country\n\nNote: The plots show the scatterplots and best-fitting lines of log GDP per capita and average years of education vs. the log of agent adopter per million population for the top 100 countries by agent adopter count. The plots are on a log scale, but the labels are in absolute values for better readability. Jitter is applied to the country labels to provide better visual separation.  $r$  is the correlation coefficient,  $p$  is the p-value of the regression coefficient, and  $R^2$  is the R-squared of the regression lines. The GDP and population data are from World Bank World Development Indicators (2024) $^a$  and the average years of education data are from UNDP Human Development Report (2024) $^b$ .",
          "images": [
            {
              "id": "img-1.jpeg",
              "top_left_x": 387,
              "top_left_y": 301,
              "bottom_right_x": 1283,
              "bottom_right_y": 871,
              "image_base64": null,
              "image_annotation": null
            },
            {
              "id": "img-2.jpeg",
              "top_left_x": 387,
              "top_left_y": 968,
              "bottom_right_x": 1283,
              "bottom_right_y": 1537,
              "image_base64": null,
              "image_annotation": null
            }
          ],
          "tables": [],
          "hyperlinks": [
            "https://data.worldbank.org/",
            "https://hdr.undp.org/content/human-development-report-2023-24"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 13,
          "markdown": "![img-3.jpeg](img-3.jpeg)\n(a) Log GDP Per Capita vs. Log Agentic Queries Per Million Population\n\n![img-4.jpeg](img-4.jpeg)\n(b) Average Years of Education vs. Log Agentic Queries Per Million Population\nFigure 3: Log GDP Per Capita and Average Years of Education vs. Log Agentic Queries Per Million Population by Country\n\nNote: The plots show the scatterplots and best-fitting lines of log GDP per capita and average years of education vs. the log of agentic query per million population for the top 100 countries by agentic query count. The plots are on a log scale, but the labels are in absolute values for better readability. Jitter is applied to the country labels to provide better visual separation.  $r$  is the correlation coefficient,  $p$  is the  $p$ -value of the regression coefficient, and  $R^2$  is the R-squared of the regression lines. The GDP and population data are from World Bank World Development Indicators (2024) $^a$ , and the average years of education data are from UNDP Human Development Report (2024) $^b$",
          "images": [
            {
              "id": "img-3.jpeg",
              "top_left_x": 387,
              "top_left_y": 301,
              "bottom_right_x": 1283,
              "bottom_right_y": 871,
              "image_base64": null,
              "image_annotation": null
            },
            {
              "id": "img-4.jpeg",
              "top_left_x": 387,
              "top_left_y": 968,
              "bottom_right_x": 1283,
              "bottom_right_y": 1535,
              "image_base64": null,
              "image_annotation": null
            }
          ],
          "tables": [],
          "hyperlinks": [
            "https://data.worldbank.org/",
            "https://hdr.undp.org/content/human-development-report-2023-24"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 14,
          "markdown": "By occupation\n\nTable 3 ranks occupation clusters (including the student cluster) by user share, adopter share, and AAR. Digital technology is by far the largest cluster, accounting for 28% of adopters, slightly higher than its user share. Academics (including the student and education clusters) and financial workers have an adopter share of more than 10%. Workers in marketing, design, and entrepreneurship have an adopter share of more than 5%. Clusters with lower adopter shares are typically those that require interacting with the physical environment. The hospitality cluster has the highest AAR at 1.36, although the sample size is significantly smaller; it is followed by marketing and entrepreneurship at 1.24 and 1.17, respectively.\n\nTable 4 ranks occupation clusters by user share, query share, and AUR. The patterns track adoption closely—top clusters remain the same with slight changes in the rank. Comparing the AUR and AAR for the same cluster reveals patterns in the degree of usage intensity relative to the degree of adoption: students and workers in entrepreneurship, marketing, and digital technology all have AUR / AAR greater than one, suggesting that their tendency to use the agent conditional on adoption is even stronger than their tendency to adopt.\n\nTables 8 and 9 in Appendix A show the top 10 occupation subclusters and their user shares by agent adopter shares and AAR, and agentic query share and AUR, respectively. Patterns at the subcluster level are largely consistent with those at the cluster level, with software engineers being the largest subcluster, accounting for 14% of adopters and 15% of queries, and having AAR and AUR around 1.1 and 1.2, respectively. All other subclusters are below 6% in both adopter and query shares. Subclusters in marketing—such as business development and sales, digital marketing, and market research—and in entrepreneurship—such as information management, operations, and strategy—tend to have the highest AAR and AUR.\n\nThese results may reflect differences in the task composition of each occupation and how closely those tasks align with common agent use cases, which the next section examines.",
          "images": [],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 15,
          "markdown": "[tbl-2.md](tbl-2.md)\n\nNote: The table shows agent adoption by O*NET occupation cluster. The \"Other\" category is removed. We put students in a separate cluster and educators in the Education cluster. User share is the number of users in each cluster divided by the total users. Agent adopter share is the number of adopters in each cluster divided by the total adopters. AAR (Agent Adoption Ratio) is the ratio between agent adopter share and user share. AAR greater (less) than 1 indicates that a cluster is over-represented (under-represented) in agent adoption relative to their user base.\n\nTable 3: Agent Adoption by Occupation Cluster\n\n[tbl-3.md](tbl-3.md)\n\nNote: The table shows usage intensity by O*NET occupation cluster. The \"Other\" category is removed. We put students in a separate cluster and educators in the Education cluster. User share is the number of users in each cluster divided by the total users. Agent query share is the number of agentic queries in each cluster divided by the total agentic queries. AUR (Agent Usage Ratio) is the ratio between agentic query share and user share. AUR greater (less) than 1 indicates that a cluster is over-represented (under-represented) in agent usage relative to their user base.\n\nTable 4: Agentic Query by Occupation Cluster",
          "images": [],
          "tables": [
            {
              "id": "tbl-2.md",
              "content": "|  Agent Adoption by Occupation Cluster: By AAR  |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Cluster | User Share (%) | User Share Rank | Agent Adopter Share (%) | Agent Adopter Share Rank | AAR  |\n|  Hospitality, Events, & Tourism | 2.5 | 11 | 3.4 | 9 | 1.36  |\n|  Marketing & Sales | 7.2 | 6 | 8.9 | 4 | 1.24  |\n|  Management & Entrepreneurship | 6.5 | 7 | 7.6 | 6 | 1.17  |\n|  Digital Technology | 26.4 | 1 | 27.7 | 1 | 1.05  |\n|  Supply Chain & Transportation | 2.2 | 13 | 2.3 | 12 | 1.05  |\n|  Financial Services | 10.0 | 3 | 10.1 | 3 | 1.01  |\n|  Student | 12.4 | 2 | 12.4 | 2 | 1.00  |\n|  Construction | 2.3 | 12 | 2.2 | 13 | 0.96  |\n|  Energy & Natural Resources | 0.9 | 14 | 0.8 | 14 | 0.89  |\n|  Arts, Entertainment, & Design | 9.1 | 4 | 8.0 | 5 | 0.88  |\n|  Education | 7.7 | 5 | 6.4 | 7 | 0.83  |\n|  Healthcare & Human Services | 4.9 | 8 | 4.0 | 8 | 0.82  |\n|  Advanced Manufacturing | 3.5 | 9 | 2.8 | 10 | 0.80  |\n|  Public Service & Safety | 3.4 | 10 | 2.7 | 11 | 0.79  |\n|  Agriculture | 0.9 | 15 | 0.7 | 15 | 0.78  |",
              "format": "markdown"
            },
            {
              "id": "tbl-3.md",
              "content": "|  Agentic Query by Occupation Cluster: By AUR  |   |   |   |   |   |\n| --- | --- | --- | --- | --- | --- |\n|  Cluster | User Share (%) | User Share Rank | Agentic Query Share (%) | Agentic Query Share Rank | AUR  |\n|  Marketing & Sales | 7.2 | 6 | 10.5 | 3 | 1.46  |\n|  Management & Entrepreneurship | 6.5 | 7 | 9.0 | 4 | 1.38  |\n|  Student | 12.4 | 2 | 15.6 | 2 | 1.26  |\n|  Digital Technology | 26.4 | 1 | 29.6 | 1 | 1.12  |\n|  Hospitality, Events, & Tourism | 2.5 | 11 | 2.6 | 9 | 1.04  |\n|  Supply Chain & Transportation | 2.2 | 13 | 2.0 | 10 | 0.91  |\n|  Financial Services | 10.0 | 3 | 8.6 | 5 | 0.86  |\n|  Arts, Entertainment, & Design | 9.1 | 4 | 6.9 | 6 | 0.76  |\n|  Education | 7.7 | 5 | 5.6 | 7 | 0.73  |\n|  Construction | 2.3 | 12 | 1.6 | 13 | 0.70  |\n|  Healthcare & Human Services | 4.9 | 8 | 3.3 | 8 | 0.67  |\n|  Agriculture | 0.9 | 15 | 0.5 | 15 | 0.56  |\n|  Energy & Natural Resources | 0.9 | 14 | 0.5 | 14 | 0.56  |\n|  Advanced Manufacturing | 3.5 | 9 | 1.9 | 11 | 0.54  |\n|  Public Service & Safety | 3.4 | 10 | 1.8 | 12 | 0.53  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 16,
          "markdown": "# 5.2 Use Cases\n\nWe document the use cases by topic, subtopic, task, environment (the websites on which the tasks are performed), and usage context. All results are based on Sample C.\n\n# Topics and subtopics\n\nTopics and subtopics capture the high-level goals of an agentic query. Figure 4 presents the topic share and subtopic share breakdown by topic. Productivity is the largest category, accounting for  $36\\%$  of all agentic queries. Learning, media, and shopping are the other topics with over  $10\\%$  query share. The two largest topics—productivity and learning—together account for  $57\\%$  of all queries. Some topics, such as learning, shopping, and career, have a dominant subtopic that accounts for more than half of the queries in that topic. Table 10 in Appendix A also shows the overall query share of each subtopic. Courses account for  $13\\%$  of all queries, followed by goods shopping, document editing, account management, social media, and email.\n\nFigure 4: Topic Breakdown by Subtopic Percentage\n![img-5.jpeg](img-5.jpeg)\nNote: The plot shows the percentage shares of subtopics within each topic. Bar width is proportional to topic percentage, and box height within each bar is proportional to subtopic percentage. \"Other\" category  $(3.4\\%)$  is not shown among the topics. The labels for subtopics that account for less than  $5\\%$  within a topic are suppressed. Topic shares are shown in the labels on the x-axis. The subtopics within each topic are sorted by percentage in decreasing order from top to bottom. The darker shades within a topic represent subtopics with higher percentages.",
          "images": [
            {
              "id": "img-5.jpeg",
              "top_left_x": 200,
              "top_left_y": 919,
              "bottom_right_x": 1475,
              "bottom_right_y": 1586,
              "image_base64": null,
              "image_annotation": null
            }
          ],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 17,
          "markdown": "Table 5 shows the topic distribution by occupation cluster. Topic-wise, productivity remains the largest topic for most occupations, whereas learning and research is the largest for students and educators, and travel is the largest for the hospitality cluster. Occupation-wise, workers in finance have the largest query share in productivity, students have the largest share in learning, designers have the largest share in media, workers in advanced manufacturing have the largest share in shopping, workers in entrepreneurship have the largest share in career, and workers in hospitality have the largest share in travel.\n\n[tbl-4.md](tbl-4.md)\n\nNote: The table shows the distribution of topics by occupation cluster. Topic percentage  $(P(\\text{Topic | Occupation}))$  is the topic share among all agentic queries from a given occupation cluster. Percentages may not sum to  $100\\%$  due to rounding.\n\nTable 5: Topic Distribution by Occupation Cluster\n\nWe also examine transition patterns between consecutive queries. Figure 7 in Appendix A shows the transition probability matrix from the previous query to the next query for all query pairs, aggregated at the user level. The results show that in most cases, topics transition into themselves, suggesting the stickiness of agent use cases. Productivity, learning, and career topics are the most sticky, whereas travel is the least sticky; media and shopping topics fall in between. When cross-topic transitions occur, they most likely transition into productivity, learning, or media topics. Then we compare users' first queries—their entry points into the agent—and all queries. Figure 8 in Appendix A contrasts the topic distribution among the first agentic query for each user with the overall distribution. Over time, the share of queries on productivity, learning, and career topics has increased, suggesting a shift toward more cognitively oriented use cases.\n\n# Tasks\n\nTasks under topics and subtopics capture the low-level tasks the agent is expected to complete to achieve the end goals. We show the top 10 tasks in Table 6. Half of the top 10 are in learning, including various learning and research assistance. The other five are split across productivity (edit documents and manage account settings), shopping (search or summarize product information), and media (search social media).",
          "images": [],
          "tables": [
            {
              "id": "tbl-4.md",
              "content": "|  Cluster / Topic | Productivity & Workflow (%) | Learning & Research (%) | Media & Entertainment (%) | Shopping & Commerce (%) | Job & Career (%) | Travel & Leisure (%)  |\n| --- | --- | --- | --- | --- | --- | --- |\n|  Digital Technology | 41.0 | 19.9 | 14.7 | 9.3 | 9.1 | 6.0  |\n|  Student | 29.1 | 43.3 | 10.6 | 5.3 | 8.1 | 3.7  |\n|  Management & Entrepreneurship | 45.8 | 13.7 | 12.3 | 9.8 | 12.2 | 6.2  |\n|  Marketing & Sales | 37.5 | 12.1 | 23.8 | 14.0 | 8.2 | 4.5  |\n|  Financial Services | 46.7 | 15.2 | 14.0 | 9.8 | 5.7 | 8.6  |\n|  Education | 34.1 | 37.0 | 13.8 | 6.6 | 2.6 | 5.8  |\n|  Arts, Entertainment, & Design | 39.4 | 12.1 | 25.0 | 11.3 | 6.0 | 6.2  |\n|  Healthcare & Human Services | 38.6 | 23.3 | 14.3 | 10.2 | 5.9 | 7.7  |\n|  Advanced Manufacturing | 30.4 | 19.8 | 11.8 | 25.4 | 5.4 | 7.1  |\n|  Public Service & Safety | 39.7 | 26.2 | 17.7 | 7.2 | 3.2 | 6.0  |\n|  Hospitality, Events, & Tourism | 29.9 | 6.6 | 13.4 | 12.2 | 2.7 | 35.2  |\n|  Supply Chain & Transportation | 40.3 | 13.4 | 12.5 | 18.6 | 5.3 | 10.0  |\n|  Construction | 39.1 | 14.9 | 14.1 | 16.3 | 7.7 | 7.9  |\n|  Energy & Natural Resources | 42.9 | 18.8 | 13.1 | 10.4 | 4.9 | 9.8  |\n|  Agriculture | 41.5 | 20.5 | 13.9 | 12.4 | 5.4 | 6.3  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 18,
          "markdown": "[tbl-5.md](tbl-5.md)\n\nNote: The table shows the top 10 tasks among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} | \\text{Topic}) \\times P(\\text{Task} | \\text{Topic}, \\text{Subtopic})$ .\n\nTable 6: The Top 10 Tasks\n\nTables 11, 12, 13, 14, 15, and 16 in Appendix A show the main tasks under each topic and subtopic with over  $5\\%$  query shares within a subtopic. Note that because query share measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic can add up to over 100. A few subtopics contain a dominant task that appears in over  $80\\%$  of all queries in that subtopic. For instance, searching for flights and lodging both appear in  $93\\%$  of queries in the flight and lodging subtopics; editing documents and summarizing research information both appear in  $85\\%$  of queries in the document editing and research subtopics, respectively. In contrast, some subtopics show more dispersed task distributions: for instance, searching videos—the top task in the video subtopic—appears in only  $48\\%$  of all queries in that category; searching email—the top task in the email subtopic—appears in only  $49\\%$  of all queries in that category.\n\nTable 17 in Appendix A shows the top 5 tasks in each occupation cluster. In general, research, document editing, and shopping-related tasks appear consistently across clusters. Some occupation clusters feature a prominent task. For instance, search products appear in  $21\\%$  of queries from the advanced manufacturing cluster. Other clusters, in contrast, have a more diffuse task composition. The top tasks in the entrepreneurship and design clusters—summarizing research information and searching products—appear in fewer than  $8\\%$  of their queries. The top tasks by occupation also shed light on why certain occupations tend to adopt and use the agent more. Knowledge-intensive sectors such as digital technology, entrepreneurship, finance, and academia tend to use the agent for research and learning-related tasks. In contrast, highly digitized sectors such as marketing and design tend to use the agent for media-related tasks.\n\n# Environments\n\nEnvironment refers to the external world with which the agent interacts while performing a task to achieve its goals. In our context, the environment is the specific website on which the agent operates for a given query. We show the top environments by overall query shares in Table 7. The top 16 environments together account for  $64\\%$  of queries, with the top 5 alone representing  $43\\%$ . These environments are typically the dominant websites within their respective domains.\n\nWe break down the top 5 environments under each subtopic and their query shares in Tables 18, 19, 20, 21, 22, and 23 in Appendix A. A single environment dominates some subtopics.",
          "images": [],
          "tables": [
            {
              "id": "tbl-5.md",
              "content": "|  Topic | Subtopic | Task | Overall (%)  |\n| --- | --- | --- | --- |\n|  Learning & Research | Courses | Assist exercises | 9.41  |\n|  Learning & Research | Research | Summarize/analyze research information | 6.71  |\n|  Productivity & Workflow | Document & Form Editing | Create/edit documents/forms | 6.58  |\n|  Shopping & Commerce | Goods | Search/filter products | 6.43  |\n|  Learning & Research | Research | Search/filter research information | 5.95  |\n|  Shopping & Commerce | Goods | Summarize/analyze product information | 5.18  |\n|  Productivity & Workflow | Account Management | Manage settings/profiles | 4.33  |\n|  Learning & Research | Courses | Summarize/analyze course materials | 3.69  |\n|  Learning & Research | Courses | Navigate courses | 3.31  |\n|  Media & Entertainment | Social Media & Messaging | Search/filter social media posts/messages | 3.29  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 19,
          "markdown": "For instance, linkedin.com alone accounts for  $93\\%$  of queries in professional networking, and the query shares of youtube.com and docs.google.com[28]—the top environments in video and spreadsheet editing subtopics—are more than twenty times larger than the share of the second environments in those subtopics. On the other hand, there is only a  $2\\%$  difference between coursera.org and netacad.com under courses, and a  $3\\%$  difference between instagram.com and x.com under social media. Table 24 in Appendix A shows the combined shares of the top 5 environments in each subtopic. A higher share indicates the agent usage is more concentrated in a few environments. The level of concentration varies significantly: the top 5 environments account for  $97\\%$  of queries in music,  $97\\%$  in videos, and  $96\\%$  in professional networking, compared to only  $28\\%$  in account management,  $35\\%$  in services shopping, and  $37\\%$  in project management, respectively. Lastly, Table 25 in Appendix A shows the top 5 environments for each occupation cluster, which are closely related to the main use cases for each occupation.\n\n[tbl-6.md](tbl-6.md)\n\nNote: The table shows all environments with a query share above  $1\\%$  among all agentic queries. docs.google.com includes Google Docs, Sheets, Slides, and Forms. All email domains are grouped into \"email services combined\" and all online messengers are grouped into \"messenger services combined\".\n\nTable 7: Top Agent Environments",
          "images": [],
          "tables": [
            {
              "id": "tbl-6.md",
              "content": "|  Environment | Overall (%)  |\n| --- | --- |\n|  docs.google.com | 11.97  |\n|  email services combined | 11.23  |\n|  linkedin.com | 9.42  |\n|  youtube.com | 7.03  |\n|  amazon.com | 3.46  |\n|  instagram.com | 2.56  |\n|  messenger services combined | 2.47  |\n|  maps.google.com | 2.20  |\n|  coursera.org | 2.04  |\n|  x.com | 2.00  |\n|  github.com | 1.85  |\n|  facebook.com | 1.77  |\n|  netacad.com | 1.75  |\n|  canva.com | 1.49  |\n|  canvas.com | 1.44  |\n|  notion.so | 1.13  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 20,
          "markdown": "# Usage context\n\nLastly, we investigate agent usage across personal, professional, and educational contexts.[29] Personal use comprises about  $55\\%$  of total agentic queries, with professional and educational contexts representing  $30\\%$  and  $16\\%$ , respectively. There is a slight increase in the share of educational use and a slight decrease in the share of personal use over time, while the share of professional use remains stable. This could be driven by the public launch time of Comet overlapping with the start of the fall semester and by on-campus promotional efforts, such as early access for university students, rather than by a systematic shift in the underlying composition of user groups and use cases.\n\nWe show the distribution of topics by usage context in Figure 5. For personal use, productivity and media together account for  $62\\%$  of all agentic queries. For professional use,  $80\\%$  of agentic queries are productivity- and career-related. Educational usage is dominated by learning, comprising  $89\\%$  of agentic queries. We also show the distribution of subtopic, task, and environment by usage context in Tables 26, 27, and 28 in Appendix A. The top subtopics for personal, professional, and educational use are goods shopping, document editing, and courses, respectively. The top environments for personal, professional, and educational use are emails, linkedin.com, and docs.google.com, respectively.\n\nFigure 5: Topic Distribution by Usage Context\n![img-6.jpeg](img-6.jpeg)\nNote: The plot shows the percentage shares of topics within each usage context. The \"Other\" category is removed from contexts. Bar width is proportional to context percentage, and box height within each bar is proportional to topic percentage. The labels for topics that account for less than  $5\\%$  within a context are suppressed. Context shares are shown in the x-axis labels. The same topic is shown in the same color across contexts. The topic percentage overall is shown as a baseline for comparison. The topics within each context are sorted in the same order as the overall for easier comparison across contexts. The topics in the overall category are sorted by topic percentage, from highest to lowest.",
          "images": [
            {
              "id": "img-6.jpeg",
              "top_left_x": 200,
              "top_left_y": 1045,
              "bottom_right_x": 1475,
              "bottom_right_y": 1687,
              "image_base64": null,
              "image_annotation": null
            }
          ],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 21,
          "markdown": "6 Discussion\n\nOur paper provides the first systematic evidence on the adoption, usage intensity, and use cases of general-purpose AI agents, based on large-scale behavioral data from Comet by Perplexity. Our findings reveal substantial differences in the propensity to adopt and use the agent across user segments. Earlier adopters, users in countries with higher GDP per capita and higher average years of education, and individuals working in more digital or knowledge-intensive fields—such as digital technology, academia, finance, marketing, and entrepreneurship—tend to adopt and use the agent more actively. Agent use cases span a broad range of categories. The two largest topics—productivity and learning—together comprise 57% of all agentic queries. The two largest subtopics—courses and goods shopping—together account for 22% of all agentic queries. The top 10 out of 90 tasks represent 55% of all agentic queries. We also document heterogeneity in use cases across occupation clusters, reflecting the degree to which they align with each occupation’s task composition. Topics such as productivity, learning, and career exhibit higher stickiness, as users are more likely to make consecutive queries within these categories. Over time, users also shift toward more cognitively oriented tasks. In addition, the environments in which agentic queries are made show significant variation in concentration across topics and subtopics.\n\nAlthough our paper is primarily descriptive and does not make normative claims or directly examine downstream impacts, its methods and findings offer valuable implications for researchers, businesses, policymakers, and educators. For researchers, we contribute to a nascent but rapidly expanding literature on the adoption and usage of LLMs and AI agents, and our agentic taxonomy provides a structure for future analysis to build on and extend. For firms developing AI agents, our results offer guidance on target user segments and high-frequency use cases. For businesses that provide the environments in which agents operate, our findings suggest opportunities to streamline interfaces to better serve users interacting with AI agents. For both policymakers and educators, a central concern is that uneven adoption and usage of AI agents could exacerbate existing productivity and learning disparities. Consequently, equipping citizens and students with the skills to leverage AI agents effectively and preparing them for a near future in which such agents are embedded in work and everyday life will become increasingly important.\n\nWe note a few important caveats of our dataset. First, because Comet is a new product, our sample primarily reflects early adopters, who may skew toward more tech-savvy users. We characterize these early adopters using an internal survey in Appendix C. Relatedly, given the short time span of our data, we do not systematically investigate changes in usage patterns over time, and any longitudinal results should be interpreted within this context. Second, the classification of an agentic query depends on internal query understanding modules that trigger the agent based on predicted query intent. These intent predictors show high prediction accuracy in internal validation studies; nonetheless, the data may include both false positives (when a non-agentic intent triggers the agent) and false negatives (when an agentic intent does not trigger the agent).",
          "images": [],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 22,
          "markdown": "Similarly, the classification into our agentic taxonomy, usage context, and occupation clusters also contains noise. Third, although AI agents’ autonomy and task horizons continue to expand, our results should not be interpreted as suggesting any particular balance between automation and augmentation in use cases. For instance, an agentic session may appear to be automation, but users may break a task into smaller pieces and delegate only some subtasks to the agent, which is closer to an augmentation case. A comprehensive treatment on such a topic would require having a complete picture of how users manage their workflows outside of Comet.\n\nThere are several natural extensions to this study that we aim to pursue. First, with the expansion of Comet to mobile devices and other environments, it will be valuable to document cross-platform differences in how users interact with AI agents. In particular, whereas agentic queries on desktops are predominantly text-based, the voice-to-voice mode on mobile may offer a more natural interface. Second, while our sample does not capture enterprise users directly, the substantial share of professionally-oriented agentic queries suggests the need for complementary research on related topics in organizational settings. Third, the adoption and usage of AI agents is closely tied to their performance across tasks; we plan to investigate agent evaluation, common failure modes, and strategies for improvement. Fourth, identifying which tasks are best suited for delegation to the agent and designing optimal human-agent collaborative workflows are also important questions. For example, tasks that users can easily complete manually may not warrant delegation. High-stakes or irreversible tasks might require exceptionally reliable agent performance, a high degree of user trust, and increased human supervision. Fifth, in addition to awareness and performance, another key barrier to adoption and use is measuring and substantiating value and impact; we seek to quantify the economic value users derive from agent use, an essential dimension of the downstream impact of AI agents.\n\nGeneral-purpose AI agents represent one of the most consequential technological advancements of our time. Understanding their real-world adoption and usage with large-scale behavioral data has become both urgent and essential for informing their development and deployment. We hope this work catalyzes further investigation in this rapidly evolving domain.\n\n##",
          "images": [],
          "tables": [],
          "hyperlinks": [
            "https://www.perplexity.ai/hub/blog/comet-for-android-is-here"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 23,
          "markdown": "References\n\n- Allowah et al. [2025] Allowah, O. Besbes, J. D. Figueroa, Y. Kanoria, and A. Kumar. What Is Your AI Agent Buying? Evaluation, Implications, and Emerging Questions for Agentic E-Commerce. arXiv preprint arXiv:2508.02630, 2025.\n- Anthropic [2025] Anthropic. Project Vend: Can Claude Run a Small Shop? (And Why Does That Matter?), 2025a. URL https://www.anthropic.com/research/project-vend-1.\n- Anthropic [2025b] Anthropic Economic Index: AI’s Impact on Software Development, 2025b. URL https://www.anthropic.com/research/impact-software-development.\n- Appel et al. [2025] R. Appel, P. McCrory, A. Tamkin, M. Stern, M. McCain, and T. Neylon. Anthropic Economic Index Report: Uneven Geographic and Enterprise AI Adoption, 2025. URL www.anthropic.com/research/anthropic-economic-index-september-2025-report.\n- Aubakirova et al. [2025] M. Aubakirova, A. Atallah, J. Summerville, and A. Midha. State of AI: An Empirical 100 Trillion Token Study with OpenRouter. Technical report, OpenRouter, 2025.\n- Bent et al. [2025] D. Bent, K. Handa, E. Durmus, A. Tamkin, M. McCain, S. Ritchie, R. Donegan, J. Martinez, and J. Jones. Anthropic Education Report: How Educators Use Claude, 2025. URL https://www.anthropic.com/news/anthropic-education-report-how-educators-use-claude.\n- Bick et al. [2024] A. Bick, A. Blandin, and D. J. Deming. The Rapid Adoption of Generative AI. Technical report, National Bureau of Economic Research, 2024.\n- Brynjolfsson et al. [2025] E. Brynjolfsson, D. Li, and L. Raymond. Generative AI at Work. The Quarterly Journal of Economics, 140(2):889–942, 2025.\n- Chatterji et al. [2025] A. Chatterji, T. Cunningham, D. J. Deming, Z. Hitzig, C. Ong, C. Y. Shan, and K. Wadman. How People Use ChatGPT. Technical report, National Bureau of Economic Research, 2025.\n- Cui et al. [2025] Z. K. Cui, M. Demirer, S. Jaffe, L. Musolff, S. Peng, and T. Salz. The Effects of Generative AI on High-Skilled Work: Evidence from Three Field Experiments with Software Developers. Available at SSRN 4945566, 2025.\n- Dell’Acqua et al. [2023] F. Dell’Acqua, E. McFowland III, E. R. Mollick, H. Lifshitz-Assaf, K. Kellogg, S. Rajendran, L. Krayer, F. Candelon, and K. R. Lakhani. Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality. Harvard Business School Technology & Operations Mgt. Unit Working Paper, (24-013), 2023.\n- Hadfield and Koh [2025] G. K. Hadfield and A. Koh. An Economy of AI Agents. arXiv preprint arXiv:2509.01063, 2025.\n- Handa et al. [2025] K. Handa, D. Bent, A. Tamkin, M. McCain, E. Durmus, M. Stern, M. Schiraldi, S. Huang, S. Ritchie, S. Syverud, K. Jagadish, M. Vo, M. Bell, and D. Ganguli. Anthropic Education Report: How University Students Use Claude, 2025a. URL https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude.\n-",
          "images": [],
          "tables": [],
          "hyperlinks": [
            "https://www.anthropic.com/research/project-vend-1",
            "https://www.anthropic.com/research/impact-software-development",
            "https://www.anthropic.com/news/anthropic-education-report-how-educators-use-claude",
            "https://www.anthropic.com/news/anthropic-education-report-how-educators-use-claude",
            "https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude",
            "https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 24,
          "markdown": "K. Handa, M. Stern, S. Huang, J. Hong, E. Durmus, M. McCain, G. Yun, A. Alt, T. Millar, A. Tamkin, J. Leibrock, S. Ritchie, and D. Ganguli. Introducing Anthropic Interviewer: What 1,250 Professionals Told Us About Working with AI, 2025b. URL https://anthropic.com/research/anthropic-interviewer.\n- K. Handa, A. Tamkin, M. McCain, S. Huang, E. Durmus, S. Heck, J. Mueller, J. Hong, S. Ritchie, T. Belonax, et al. Which Economic Tasks Are Performed with AI? Evidence from Millions of Claude Conversations. arXiv preprint arXiv:2503.04761, 2025c.\n- A. Humlum and E. Vestergaard. The Unequal Adoption of ChatGPT Exacerbates Existing Inequalities Among Workers. Proceedings of the National Academy of Sciences, 122(1): e2414972121, 2025.\n- H. Ju and S. Aral. Collaborating with AI Agents: Field Experiments on Teamwork, Productivity, and Performance. arXiv preprint arXiv:2503.18238, 2025.\n- A. Merali. Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Translation. arXiv preprint arXiv:2409.02391, 2024.\n- G. A. Moore. Crossing the Chasm: Marketing and Selling High-Tech Products to Mainstream Customers. HarperBusiness, New York, 1991.\n- S. Noy and W. Zhang. Experimental Evidence on the Productivity Effects of Generative Artificial Intelligence. Science, 381(6654):187–192, 2023.\n- M. Z. Pan, N. Arabzadeh, R. Cogo, Y. Zhu, A. Xiong, L. A. Agrawal, H. Mao, E. Shen, S. Pallerla, L. Patel, et al. Measuring Agents in Production. arXiv preprint arXiv:2512.04123, 2025.\n- S. Peng, E. Kalliamvakou, P. Cihon, and M. Demirer. The Impact of AI on Developer Productivity: Evidence from GitHub Copilot. arXiv preprint arXiv:2302.06590, 2023.\n- Perplexity Team. Agents or Bots? Making Sense of AI on the Open Web, 2025. URL https://www.perplexity.ai/hub/blog/agents-or-bots-making-sense-of-ai-on-the-open-web.\n- D. M. Rothschild, M. Mobius, J. M. Hofman, E. W. Dillon, D. G. Goldstein, N. Immorlica, S. Jaffe, B. Lucier, A. Slivkins, and M. Vogel. The Agentic Economy. arXiv preprint arXiv:2505.15799, 2025.\n- S. K. Sarkar. AI Agents, Productivity, and Higher-Order Thinking: Early Evidence from Software Development. Available at SSRN 5713646, 2025.\n- E. Schluntz and B. Zhang. Building Effective Agents, 2024. URL https://www.anthropic.com/engineering/building-effective-agents.\n- P. Shahidi, G. Rusak, B. S. Manning, A. Fradkin, and J. J. Horton. The Coasean Singularity? Demand, Supply, and Market Design with AI Agents. Technical report, National Bureau of Economic Research, 2025.",
          "images": [],
          "tables": [],
          "hyperlinks": [
            "https://anthropic.com/research/anthropic-interviewer",
            "https://anthropic.com/research/anthropic-interviewer",
            "https://www.perplexity.ai/hub/blog/agents-or-bots-making-sense-of-ai-on-the-open-web",
            "https://www.perplexity.ai/hub/blog/agents-or-bots-making-sense-of-ai-on-the-open-web",
            "https://www.anthropic.com/engineering/building-effective-agents",
            "https://www.anthropic.com/engineering/building-effective-agents"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 25,
          "markdown": "Y. Shavit, S. Agarwal, M. Brundage, S. Adler, C. O’Keefe, R. Campbell, T. Lee, P. Mishkin, T. Eloundou, A. Hickey, et al. Practices for Governing Agentic AI Systems. Research Paper, OpenAI, 2023.\n\nL. Vendraminelli, M. DosSantos DiSorbo, A. Hildebrandt, E. McFowland III, A. Karunakaran, and I. Bojinov. The GenAI Wall Effect: Examining the Limits to Horizontal Expertise Transfer Between Occupational Insiders and Outsiders. Harvard Business School Technology &amp; Operations Mgt. Unit Working Paper, (26-011):26–011, 2025.\n\nE. Wiles, L. Krayer, M. Abbadi, U. Awasthi, R. Kennedy, P. Mishkin, D. Sack, and F. Candelon. Genai as an exoskeleton: Experimental evidence on knowledge workers using genai on new skills. Available at SSRN 4944588, 2024.\n\nM. Wooldridge and N. R. Jennings. Intelligent Agents: Theory and Practice. The Knowledge Engineering Review, 10(2):115–152, 1995.\n\nS. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, and Y. Cao. ReAct: Synergizing Reasoning and Acting in Language Models. In The Eleventh International Conference on Learning Representations, 2022.\n\nW. Zhao, X. Ren, J. Hessel, C. Cardie, Y. Choi, and Y. Deng. WildChat: 1M ChatGPT Interaction Logs in the Wild. arXiv preprint arXiv:2405.01470, 2024.",
          "images": [],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 26,
          "markdown": "# Appendices\n\n# A Figures and Tables\n\n# A.1 Adoption and Usage Intensity\n\n![img-7.jpeg](img-7.jpeg)\n(a) Cumulative Agent Adopter\n\n![img-8.jpeg](img-8.jpeg)\n(b) Cumulative Agentic Query\nFigure 6: Cumulative Agent Adopter and Agentic Query\n\nNote: The plots show the cumulative number of agent adopters and agentic queries. The exact numbers on the y-axis are masked, and the percentages show the relative magnitude of adopters and queries relative to the end date as the baseline. Adopter and query numbers grow steadily over time with a noticeable jump when Comet became generally available. The three dashed vertical lines mark the dates for the change in access. July 9: launch date and open to Max subscribers and selected users on a waitlist. August 13: extended access to Pro subscribers. October 2: extended access to everyone worldwide.",
          "images": [
            {
              "id": "img-7.jpeg",
              "top_left_x": 329,
              "top_left_y": 611,
              "bottom_right_x": 1341,
              "bottom_right_y": 1100,
              "image_base64": null,
              "image_annotation": null
            },
            {
              "id": "img-8.jpeg",
              "top_left_x": 329,
              "top_left_y": 1210,
              "bottom_right_x": 1341,
              "bottom_right_y": 1696,
              "image_base64": null,
              "image_annotation": null
            }
          ],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 27,
          "markdown": "[tbl-7.md](tbl-7.md)\n\nNote: The tables show the top 10 O*NET occupation subclusters by adoption. The \"Other\" category is removed. When a user appears in multiple subclusters, their data is used in all relevant subclusters. User share is the number of users in each subcluster divided by the total users. Agent adopter share is the number of adopters in each subcluster, divided by the total number of adopters. AAR (Agent Adoption Ratio) is the ratio between agent adopter share and user share. AAR greater (less) than 1 indicates that a subcluster is over-represented (under-represented) in agent adoption relative to their user base. AAR rank is among the subclusters with a user share over  $1\\%$ .",
          "images": [],
          "tables": [
            {
              "id": "tbl-7.md",
              "content": "|  Agent Adoption by Occupation Subcluster: The Top 10 Subclusters by Agent Adoption Share  |   |   |   |   |\n| --- | --- | --- | --- | --- |\n|  Cluster | Subcluster | User Share (%) | Agent Adopter Share (%) | AAR  |\n|  Digital Technology | Software Development & Engineering | 13.0 | 13.9 | 1.07  |\n|  Marketing & Sales | Digital Marketing & Social Media | 3.9 | 4.7 | 1.21  |\n|  Digital Technology | IT Support & Infrastructure | 4.0 | 4.3 | 1.08  |\n|  Arts, Entertainment, & Design | Design & Digital Arts | 5.0 | 4.3 | 0.86  |\n|  Financial Services | Financial Planning & Analysis | 4.1 | 4.3 | 1.05  |\n|  Digital Technology | Data Science & AI | 3.9 | 4.0 | 1.03  |\n|  Education | Teaching & Instruction | 4.9 | 4.0 | 0.82  |\n|  Financial Services | Financial Strategy & Investments | 3.8 | 3.9 | 1.03  |\n|  Management & Entrepreneurship | Business Information Management | 3.2 | 3.8 | 1.19  |\n|  Management & Entrepreneurship | Leadership & Operations | 2.6 | 3.1 | 1.19  |\n|  Agent Adoption by Occupation Subcluster: The Top 10 Subclusters by AAR  |   |   |   |   |\n|  Cluster | Subcluster | User Share (%) | Agent Adopter Share (%) | AAR  |\n|  Marketing & Sales | Business Development & Sales | 1.2 | 1.6 | 1.33  |\n|  Marketing & Sales | Digital Marketing & Social Media | 3.9 | 4.7 | 1.21  |\n|  Management & Entrepreneurship | Business Information Management | 3.2 | 3.8 | 1.19  |\n|  Management & Entrepreneurship | Leadership & Operations | 2.6 | 3.1 | 1.19  |\n|  Marketing & Sales | Market Research, Analytics, & Ethics | 1.1 | 1.3 | 1.18  |\n|  Management & Entrepreneurship | Strategy & Consulting | 2.2 | 2.5 | 1.14  |\n|  Supply Chain & Transportation | Planning & Logistics | 1.1 | 1.2 | 1.09  |\n|  Digital Technology | IT Support & Infrastructure | 4.0 | 4.3 | 1.08  |\n|  Digital Technology | Software Development & Engineering | 13.0 | 13.9 | 1.07  |\n|  Marketing & Sales | Brand Management & Strategy | 1.4 | 1.5 | 1.07  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 28,
          "markdown": "[tbl-8.md](tbl-8.md)\n\nNote: The tables show the top 10 O*NET occupation subclusters by usage intensity. The \"Other\" category is removed. When a user appears in multiple subclusters, their data is used in all relevant subclusters. User share is the number of users in each subcluster divided by the total users. Agent query share is the number of agentic queries in each subcluster divided by the total agentic queries. AUR (Agent Usage Ratio) is the ratio between agentic query share and user share. AUR greater (less) than 1 indicates that a subcluster is over-represented (under-represented) in agent usage relative to their user base. AUR rank is among the subclusters with a user share over  $1\\%$ .",
          "images": [],
          "tables": [
            {
              "id": "tbl-8.md",
              "content": "|  Agentic Query by Occupation Subcluster: The Top 10 Subclusters by Agentic Query Share  |   |   |   |   |\n| --- | --- | --- | --- | --- |\n|  Cluster | Subcluster | User Share (%) | Agentic Query Share (%) | AUR  |\n|  Digital Technology | Software Development & Engineering | 13.0 | 15.4 | 1.18  |\n|  Marketing & Sales | Digital Marketing & Social Media | 3.9 | 5.9 | 1.51  |\n|  Digital Technology | IT Support & Infrastructure | 4.0 | 5.3 | 1.32  |\n|  Management & Entrepreneurship | Business Information Management | 3.2 | 4.7 | 1.47  |\n|  Financial Services | Financial Planning & Analysis | 4.1 | 3.9 | 1.05  |\n|  Digital Technology | Data Science & AI | 3.9 | 3.9 | 1.00  |\n|  Management & Entrepreneurship | Leadership & Operations | 2.6 | 3.9 | 1.50  |\n|  Arts, Entertainment, & Design | Design & Digital Arts | 5.0 | 3.8 | 0.76  |\n|  Education | Teaching & Instruction | 4.9 | 3.6 | 0.73  |\n|  Financial Services | Financial Strategy & Investments | 3.8 | 3.9 | 1.03  |\n|  Agentic Query by Occupation Subcluster: The Top 10 Subclusters by AUR  |   |   |   |   |\n|  Cluster | Subcluster | User Share (%) | Agentic Query Share (%) | AUR  |\n|  Marketing & Sales | Business Development & Sales | 1.2 | 2.1 | 1.75  |\n|  Marketing & Sales | Digital Marketing & Social Media | 3.9 | 5.9 | 1.51  |\n|  Management & Entrepreneurship | Leadership & Operations | 2.6 | 3.9 | 1.50  |\n|  Management & Entrepreneurship | Business Information Management | 3.2 | 4.7 | 1.47  |\n|  Marketing & Sales | Brand Management & Strategy | 1.4 | 1.9 | 1.36  |\n|  Management & Entrepreneurship | Strategy & Consulting | 2.2 | 3.0 | 1.36  |\n|  Digital Technology | IT Support & Infrastructure | 4.0 | 5.3 | 1.32  |\n|  Marketing & Sales | Market Research, Analytics, & Ethics | 1.1 | 1.4 | 1.27  |\n|  Digital Technology | Software Development & Engineering | 13.0 | 15.4 | 1.18  |\n|  Supply Chain & Transportation | Planning & Logistics | 1.1 | 1.1 | 1.00  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 29,
          "markdown": "# A.2 Use Cases\n\n# A.2.1 Topics and Subtopics\n\n[tbl-9.md](tbl-9.md)\n\nNote: The table shows the distribution of topics and subtopics. The topic percentage  $(P(\\text{Topic}))$  is the topic's share among all agentic queries. Subtopic percentage  $(P(\\text{Subtopic} \\mid \\text{Topic}))$  is the percentage of a subtopic within a topic. Overall percentage  $(P(\\text{Subtopic}) = P(\\text{Topic}, \\text{Subtopic}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}))$  is the subtopic share among all agentic queries. Percentages may not sum to  $100\\%$  due to rounding.\n\nTable 10: Topic and Subtopic Distribution",
          "images": [],
          "tables": [
            {
              "id": "tbl-9.md",
              "content": "|  Topic | Topic (%) | Subtopic | Subtopic (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Productivity & Workflow | 36.2 | Document & Form Editing | 21.5 | 7.78  |\n|   |   |  Account Management | 20.5 | 7.43  |\n|   |   |  Email Management | 15.8 | 5.73  |\n|   |   |  Spreadsheet & Data Editing | 11.1 | 4.01  |\n|   |   |  Computer Programming | 10.3 | 3.73  |\n|   |   |  Investments & Banking | 6.2 | 2.25  |\n|   |   |  Multimedia Editing | 6.1 | 2.22  |\n|   |   |  Project Management | 5.1 | 1.85  |\n|   |   |  Calendar Management | 2.5 | 0.91  |\n|   |   |  Other | 0.8 | 0.30  |\n|  Learning & Research | 20.8 | Courses | 61.9 | 12.86  |\n|   |   |  Research | 37.9 | 7.88  |\n|   |   |  Other | 0.2 | 0.04  |\n|  Media & Entertainment | 15.8 | Social Media & Messaging | 42.4 | 6.69  |\n|   |   |  Movies, TV, & Videos | 20.1 | 3.17  |\n|   |   |  Online Games | 19.6 | 3.08  |\n|   |   |  Music & Podcasts | 10.7 | 1.68  |\n|   |   |  News | 3.8 | 0.59  |\n|   |   |  Sports | 2.7 | 0.42  |\n|   |   |  Other | 0.8 | 0.13  |\n|  Shopping & Commerce | 10.0 | Goods | 89.0 | 8.94  |\n|   |   |  Services | 10.3 | 1.03  |\n|   |   |  Other | 0.7 | 0.07  |\n|  Job & Career | 7.1 | Professional Networking | 50.1 | 3.56  |\n|   |   |  Job Search & Application | 49.5 | 3.52  |\n|   |   |  Other | 0.4 | 0.03  |\n|  Travel & Leisure | 6.7 | Flights & Transportation | 40.7 | 2.73  |\n|   |   |  Lodging | 27.3 | 1.83  |\n|   |   |  Trip Itineraries | 24.8 | 1.66  |\n|   |   |  Restaurants | 5.7 | 0.38  |\n|   |   |  Other | 1.5 | 0.10  |\n|  Other | 3.4 | Other | 100.0 | 3.42  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 30,
          "markdown": "![img-9.jpeg](img-9.jpeg)\nNote: The plot shows the transition matrix from the previous query to the following query, aggregated from the user level. Most query topics transition into themselves (the off-diagonal). Other than themselves, topics are most likely to transition into Productivity &amp; Workflow (the first column). Productivity &amp; Workflow, Learning &amp; Research, and Job &amp; Career are the most sticky with the highest self-transition probabilities. Whereas Travel &amp; Leisure is the least sticky, and Media &amp; Entertainment and Shopping &amp; Commerce are in between. The steady state probability distribution based on this transition matrix and the observed share are closely matched— $39\\%$  vs  $37\\%$  respectively for Productivity &amp; Workflow,  $24\\%$  vs  $22\\%$  for Learning &amp; Research,  $16\\%$  vs.  $16\\%$  for Media &amp; Entertainment,  $10\\%$  vs.  $10\\%$  for Shopping &amp; Commerce,  $7\\%$  vs  $7\\%$  for Job &amp; Career, and  $7\\%$  vs  $7\\%$  for Travel &amp; Leisure. Note that to be aligned with the transition matrix, the observed shares used here do not include the \"Other\" category in Table 10; the shares used here are based on the topic shares in that table divided by 0.96.\nFigure 7: Topic Transition Matrix: Previous vs. Next Agentic Query",
          "images": [
            {
              "id": "img-9.jpeg",
              "top_left_x": 263,
              "top_left_y": 528,
              "bottom_right_x": 1411,
              "bottom_right_y": 1524,
              "image_base64": null,
              "image_annotation": null
            }
          ],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 31,
          "markdown": "Figure 8: Topic Distribution by First vs. All Agentic Queries\n![img-10.jpeg](img-10.jpeg)\nNote: The plot shows the distribution of topics among users' first agentic queries versus all agentic queries. Over time, the query shares are shifting from Travel &amp; Leisure, and Media &amp; Entertainment to Productivity &amp; Workflow, Learning &amp; Research, and Job &amp; Career. Shopping &amp; Commerce share stays relatively stable.",
          "images": [
            {
              "id": "img-10.jpeg",
              "top_left_x": 333,
              "top_left_y": 721,
              "bottom_right_x": 1337,
              "bottom_right_y": 1460,
              "image_base64": null,
              "image_annotation": null
            }
          ],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 32,
          "markdown": "# A.2.2 Tasks\n\n[tbl-10.md](tbl-10.md)\n\nNote: The table shows all tasks under Productivity &amp; Workflow with a share of more than  $5\\%$  within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage  $(P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$  is the task share within the subtopic. The overall percentage is the task share among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\n\nTable 11: Task Distribution for Productivity &amp; Workflow",
          "images": [],
          "tables": [
            {
              "id": "tbl-10.md",
              "content": "|  Topic | Subtopic | Task | Task (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Productivity & Workflow (36.2) | Document & Form Editing (21.5) | Create/edit documents/forms | 84.6 | 6.58  |\n|   |   |  Summarize/analyze documents/forms | 24.1 | 1.87  |\n|   |   |  Search/filter documents/forms | 11.4 | 0.89  |\n|   |  Account Management (20.5) | Manage settings/profiles | 58.3 | 4.33  |\n|   |   |  Register/log in to accounts | 31.2 | 2.32  |\n|   |   |  Summarize/analyze account information | 24.0 | 1.79  |\n|   |   |  Manage files | 15.8 | 1.18  |\n|   |  Email Management (15.8) | Search/filter emails | 49.1 | 2.81  |\n|   |   |  Create/edit emails | 32.8 | 1.88  |\n|   |   |  Delete/unsubscribe emails | 30.6 | 1.75  |\n|   |   |  Summarize/analyze emails | 22.8 | 1.31  |\n|   |   |  Send emails | 9.6 | 0.55  |\n|   |  Spreadsheet & Data Editing (11.1) | Create/edit spreadsheets/data | 72.5 | 2.91  |\n|   |   |  Summarize/analyze spreadsheets/data | 38.7 | 1.55  |\n|   |   |  Search/filter spreadsheets/data | 27.5 | 1.10  |\n|   |  Computer Programming (10.3) | Create/edit code | 63.8 | 2.38  |\n|   |   |  Summarize/analyze code | 48.5 | 1.81  |\n|   |   |  Execute code | 20.3 | 0.76  |\n|   |  Investments & Banking (6.2) | Summarize/analyze investment information | 75.0 | 1.69  |\n|   |   |  Search/filter stocks | 28.8 | 0.65  |\n|   |   |  Summarize/analyze banking information | 11.7 | 0.26  |\n|   |   |  Buy/sell stocks | 7.8 | 0.18  |\n|   |  Multimedia Editing (6.1) | Create/edit multimedia | 81.0 | 1.80  |\n|   |   |  Summarize/analyze multimedia | 23.6 | 0.52  |\n|   |   |  Search/filter multimedia | 15.3 | 0.34  |\n|   |  Project Management (5.1) | Create/edit projects | 64.6 | 1.19  |\n|   |   |  Summarize/analyze project information | 48.0 | 0.89  |\n|   |  Calendar Management (2.5) | Create/edit events | 71.0 | 0.64  |\n|   |   |  Search/filter events | 24.6 | 0.22  |\n|  Summarize/analyze events |   | 22.0 | 0.20  |   |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 33,
          "markdown": "[tbl-11.md](tbl-11.md)\n\nNote: The table shows all tasks under Learning &amp; Research with a share of more than  $5\\%$  within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage  $(P(\\text{Task} | \\text{Topic}, \\text{Subtopic}))$  is the task share within the subtopic. The overall percentage is the task share among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} | \\text{Topic}) \\times P(\\text{Task} | \\text{Topic}, \\text{Subtopic}))$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\n\nTable 12: Task Distribution for Learning &amp; Research",
          "images": [],
          "tables": [
            {
              "id": "tbl-11.md",
              "content": "|  Topic | Subtopic | Task | Task (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Learning & Research (20.8) | Courses (61.9) | Assist exercises | 73.2 | 9.41  |\n|   |   |  Summarize/analyze course materials | 28.7 | 3.69  |\n|   |   |  Navigate courses | 25.6 | 3.29  |\n|   |  Research (37.9) | Summarize/analyze research information | 85.2 | 6.71  |\n|   |   |  Search/filter research information | 75.6 | 5.95  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 34,
          "markdown": "[tbl-12.md](tbl-12.md)\n\nNote: The table shows all tasks under Media &amp; Entertainment with a share of more than  $5\\%$  within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage  $(P(\\text{Task} | \\text{Topic}, \\text{Subtopic}))$  is the task share within the subtopic. The overall percentage is the task share among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} | \\text{Topic}) \\times P(\\text{Task} | \\text{Topic}, \\text{Subtopic}))$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\n\nTable 13: Task Distribution for Media &amp; Entertainment",
          "images": [],
          "tables": [
            {
              "id": "tbl-12.md",
              "content": "|  Topic | Subtopic | Task | Task (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Media & Entertainment (15.8) | Social Media & Messaging (42.4) | Search/filter social media posts/messages | 49.5 | 3.31  |\n|   |   |  Summarize/analyze social media posts/messages | 35.3 | 2.36  |\n|   |   |  Create social media posts/messages | 34.0 | 2.28  |\n|   |   |  Engage with social media posts/messages | 29.3 | 1.96  |\n|   |   |  Send social media/text messages | 20.7 | 1.39  |\n|   |  Movies, TV, & Videos (20.1) | Search/filter videos | 48.4 | 1.53  |\n|   |   |  Summarize/analyze videos | 43.8 | 1.39  |\n|   |   |  Play videos | 27.1 | 0.86  |\n|   |   |  Navigate within videos | 18.4 | 0.58  |\n|   |   |  Manage playlists | 6.2 | 0.20  |\n|   |  Online Games (19.6) | Play online games | 76.8 | 2.37  |\n|   |   |  Summarize/analyze online game information | 30.7 | 0.95  |\n|   |   |  Search/filter online games | 14.5 | 0.45  |\n|   |  Music & Podcasts (10.7) | Search/filter music/podcasts | 75.4 | 1.27  |\n|   |   |  Play music/podcasts | 61.2 | 1.03  |\n|   |   |  Manage playlists | 25.5 | 0.43  |\n|   |   |  Summarize/analyze music/podcasts | 9.7 | 0.16  |\n|   |  News (3.8) | Search/filter news | 70.7 | 0.42  |\n|   |   |  Summarize/analyze news | 56.6 | 0.34  |\n|   |  Sports (2.7) | Summarize/analyze match/player information | 77.0 | 0.32  |\n|   |   |  Search/filter match/player information | 67.7 | 0.28  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 35,
          "markdown": "[tbl-13.md](tbl-13.md)\n\nNote: The table shows all tasks under Shopping &amp; Commerce with a share of more than  $5\\%$  within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage  $(P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$  is the task share within the subtopic. The overall percentage is the task share among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\n\nTable 14: Task Distribution for Shopping &amp; Commerce",
          "images": [],
          "tables": [
            {
              "id": "tbl-13.md",
              "content": "|  Topic | Subtopic | Task | Task (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Shopping & Commerce (10.0) | Goods (89.0) | Search/filter products | 71.9 | 6.43  |\n|   |   |  Summarize/analyze product information | 57.9 | 5.18  |\n|   |   |  Add products to cart | 19.8 | 1.77  |\n|   |   |  Search discounts | 10.2 | 0.92  |\n|   |  Services (10.3) | Search/filter products | 54.5 | 0.56  |\n|   |   |  Summarize/analyze product information | 45.1 | 0.46  |\n|   |   |  Make product purchase | 20.2 | 0.21  |\n|   |   |  Search discounts | 12.5 | 0.13  |\n|   |   |  Add products to cart | 7.6 | 0.08  |\n|   |   |  Manage orders | 7.0 | 0.07  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 36,
          "markdown": "[tbl-14.md](tbl-14.md)\n\nNote: The table shows all tasks under Job &amp; Career with a share of more than  $5\\%$  within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage  $(P(\\text{Task} | \\text{Topic}, \\text{Subtopic}))$  is the task share within the subtopic. The overall percentage is the task share among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} | \\text{Topic}) \\times P(\\text{Task} | \\text{Topic}, \\text{Subtopic})$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\n\nTable 15: Task Distribution for Job &amp; Career",
          "images": [],
          "tables": [
            {
              "id": "tbl-14.md",
              "content": "|  Topic | Subtopic | Task | Task (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Job & Career (7.1) | Job Search & Application (50.1) | Complete applications | 65.7 | 2.31  |\n|   |   |  Search/filter jobs | 57.1 | 2.01  |\n|   |   |  Summarize/analyze job descriptions | 26.3 | 0.93  |\n|   |  Professional Networking (49.5) | Search/filter professional profiles | 53.8 | 1.92  |\n|   |   |  Summarize/analyze professional profiles | 39.9 | 1.42  |\n|   |   |  Send professional connection requests/messages | 31.4 | 1.12  |\n|   |   |  Engage with professional profiles/posts | 24.0 | 0.85  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 37,
          "markdown": "[tbl-15.md](tbl-15.md)\n\nNote: The table shows all tasks under Travel &amp; Leisure with a share of more than  $5\\%$  within the subtopic. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Task percentage  $(P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$  is the task share within the subtopic. The overall percentage is the task share among all agentic queries.  $P(\\text{Task Overall}) = P(\\text{Topic}, \\text{Subtopic}, \\text{Task}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Task} \\mid \\text{Topic}, \\text{Subtopic}))$ . Note that because task percentage measures the fraction of queries in which a task is present and a query might contain multiple tasks, the task percentages under each subtopic do not sum to 100.\n\nTable 16: Task Distribution for Travel &amp; Leisure",
          "images": [],
          "tables": [
            {
              "id": "tbl-15.md",
              "content": "|  Topic | Subtopic | Task | Task (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Travel & Leisure (6.7) | Flights & Transportation (40.7) | Search/filter flights & transportation | 93.4 | 2.55  |\n|   |   |  Summarize/analyze flights & transportation | 63.1 | 1.72  |\n|   |   |  Book flights & transportation | 9.5 | 0.26  |\n|   |  Lodging (27.3) | Search/filter lodging | 92.9 | 1.70  |\n|   |   |  Summarize/analyze lodging information | 67.5 | 1.23  |\n|   |   |  Book lodging | 5.5 | 0.10  |\n|   |  Trip Itineraries (24.8) | Plan trips | 87.4 | 1.45  |\n|   |   |  Summarize/analyze trips | 48.9 | 0.81  |\n|   |   |  Search/filter destinations | 48.8 | 0.81  |\n|   |  Restaurants (5.7) | Search/filter restaurants | 73.8 | 0.28  |\n|   |   |  Summarize/analyze restaurant information | 54.2 | 0.21  |\n|   |   |  Book restaurants | 25.0 | 0.09  |\n|  Manage bookings |   | 5.7 | 0.02  |   |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 38,
          "markdown": "[tbl-16.md](tbl-16.md)\n\nNote: The table shows the top 5 tasks under each occupation cluster. Task percentage  $(P(\\text{Task} | \\text{Cluster}))$  is the task share among all agentic queries within a cluster.\n\nTable 17: The Top 5 Tasks by Occupation Cluster",
          "images": [],
          "tables": [
            {
              "id": "tbl-16.md",
              "content": "|  Cluster | Task | Task (%)  |\n| --- | --- | --- |\n|  Digital Technology | Assist exercises | 9.1  |\n|   |  Search/filter products | 6.4  |\n|   |  Create/edit documents/forms | 6.2  |\n|   |  Summarize/analyze research information | 6.2  |\n|   |  Manage settings/profiles | 5.7  |\n|  Student | Assist exercises | 26.5  |\n|   |  Summarize/analyze course materials | 10.7  |\n|   |  Navigate courses | 7.8  |\n|   |  Create/edit documents/forms | 7.1  |\n|   |  Summarize/analyze research information | 5.4  |\n|  Management & Entrepreneurship | Summarize/analyze research information | 7.7  |\n|   |  Create/edit documents/forms | 7.5  |\n|   |  Search/filter research information | 6.8  |\n|   |  Search/filter products | 6.3  |\n|   |  Create/edit spreadsheets/data | 5.2  |\n|  Marketing & Sales | Create social media posts/messages | 8.1  |\n|   |  Search/filter social media posts/messages | 8.1  |\n|   |  Summarize/analyze product information | 8.1  |\n|   |  Summarize/analyze research information | 8.0  |\n|   |  Search/filter products | 7.6  |\n|  Financial Services | Summarize/analyze investment information | 11.9  |\n|   |  Summarize/analyze research information | 7.0  |\n|   |  Search/filter products | 6.7  |\n|   |  Search/filter research information | 6.1  |\n|   |  Summarize/analyze product information | 5.2  |\n|  Education | Assist exercises | 19.6  |\n|   |  Create/edit documents/forms | 9.8  |\n|   |  Summarize/analyze course materials | 8.6  |\n|   |  Summarize/analyze research information | 7.0  |\n|   |  Search/filter research information | 6.9  |\n|  Arts, Entertainment, & Design | Search/filter products | 7.8  |\n|   |  Create/edit documents/forms | 7.4  |\n|   |  Create/edit multimedia | 7.3  |\n|   |  Summarize/analyze product information | 6.1  |\n|   |  Summarize/analyze research information | 5.8  |\n|  Healthcare & Human Services | Summarize/analyze research information | 9.5  |\n|   |  Search/filter research information | 9.4  |\n|   |  Create/edit documents/forms | 7.9  |\n|   |  Search/filter products | 6.6  |\n|   |  Assist exercises | 5.5  |\n|  Advanced Manufacturing | Search/filter products | 20.9  |\n|   |  Summarize/analyze product information | 18.1  |\n|   |  Summarize/analyze research information | 7.8  |\n|   |  Search/filter research information | 7.5  |\n|   |  Assist exercises | 6.6  |\n|  Public Service & Safety | Search/filter research information | 15.7  |\n|   |  Summarize/analyze research information | 15.1  |\n|   |  Create/edit documents/forms | 10.2  |\n|   |  Search/filter products | 5.1  |\n|   |  Assist exercises | 4.3  |\n|  Hospitality, Events, & Tourism | Search/filter flights & transportation | 11.9  |\n|   |  Search/filter lodging | 9.6  |\n|   |  Search/filter products | 8.3  |\n|   |  Summarize/analyze flights & transportation information | 8.1  |\n|   |  Summarize/analyze lodging information | 7.6  |\n|  Supply Chain & Transportation | Search/filter products | 12.7  |\n|   |  Summarize/analyze product information | 10.6  |\n|   |  Create/edit documents/forms | 7.4  |\n|   |  Summarize/analyze research information | 7.2  |\n|   |  Search/filter research information | 6.4  |\n|  Construction | Search/filter products | 11.0  |\n|   |  Summarize/analyze product information | 9.1  |\n|   |  Summarize/analyze research information | 8.8  |\n|   |  Search/filter research information | 8.3  |\n|   |  Create/edit documents/forms | 5.6  |\n|  Energy & Natural Resources | Create/edit documents/forms | 10.5  |\n|   |  Summarize/analyze research information | 10.4  |\n|   |  Search/filter research information | 10.4  |\n|   |  Search/filter products | 7.7  |\n|   |  Summarize/analyze product information | 6.0  |\n|  Agriculture | Create/edit documents/forms | 10.3  |\n|   |  Search/filter products | 8.5  |\n|   |  Summarize/analyze research information | 8.4  |\n|   |  Search/filter research information | 8.4  |\n|   |  Summarize/analyze product information | 7.2  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 39,
          "markdown": "# A.2.3 Environments\n\n[tbl-17.md](tbl-17.md)\n\nNote: The table shows the top 5 environments under Productivity &amp; Workflow. The share of the topic among all agentic queries and the share of the subtopic within a topic are shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries.  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$  is the share of an environment when it is used under that subtopic and does not equal  $P(\\text{Environment})$ , which is the share under all subtopics.\n\nTable 18: The Top 5 Environments Distribution for Productivity &amp; Workflow",
          "images": [],
          "tables": [
            {
              "id": "tbl-17.md",
              "content": "|  Topic | Subtopic | Environment | Environment (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Productivity & Workflow (36.2) | Document & Form Editing (21.5) | docs.google.com | 66.6 | 5.18  |\n|   |   |  notion.so | 6.4 | 0.50  |\n|   |   |  canva.com | 2.5 | 0.19  |\n|   |   |  overleaf.com | 2.0 | 0.16  |\n|   |   |  perplexity.ai | 1.3 | 0.10  |\n|   |  Account Management (20.5) | perplexity.ai | 10.4 | 0.77  |\n|   |   |  docs.google.com | 7.6 | 0.56  |\n|   |   |  settings | 4.0 | 0.30  |\n|   |   |  github.com | 3.2 | 0.24  |\n|   |   |  linkedin.com | 3.1 | 0.23  |\n|   |  Email Management (15.8) | mail.google.com | 69.9 | 4.00  |\n|   |   |  outlook.office.com | 10.8 | 0.62  |\n|   |   |  outlook/live.com | 2.9 | 0.17  |\n|   |   |  mail.yahoo.com | 1.5 | 0.09  |\n|   |   |  mail.yandex.ru | 0.5 | 0.03  |\n|   |  Spreadsheet & Data Editing (11.1) | docs.google.com | 78.9 | 3.17  |\n|   |   |  notion.so | 4.4 | 0.18  |\n|   |   |  airtable.com | 2.3 | 0.09  |\n|   |   |  excel.cloud.microsoft | 1.4 | 0.06  |\n|   |   |  app.powerbi.com | 1.1 | 0.04  |\n|   |  Computer Programming (10.3) | github.com | 30.7 | 1.14  |\n|   |   |  colab.research.google.com | 5.3 | 0.20  |\n|   |   |  leetcode.com | 4.9 | 0.18  |\n|   |   |  aistudio.google.com | 4.2 | 0.16  |\n|   |   |  script.google.com | 3.1 | 0.12  |\n|   |  Investments & Banking (6.2) | tradingview.com | 47.3 | 1.06  |\n|   |   |  binance.com | 5.7 | 0.13  |\n|   |   |  kite.zerodha.com | 4.9 | 0.11  |\n|   |   |  groww.in | 4.6 | 0.10  |\n|   |   |  perplexity.ai | 4.4 | 0.10  |\n|   |  Multimedia Editing (6.1) | canva.com | 42.9 | 0.95  |\n|   |   |  figma.com | 8.6 | 0.19  |\n|   |   |  docs.google.com | 5.3 | 0.12  |\n|   |   |  youtube.com | 5.3 | 0.12  |\n|   |   |  aistudio.google.com | 3.5 | 0.08  |\n|   |  Project Management (5.1) | app.clickup.com | 9.6 | 0.18  |\n|   |   |  trello.com | 8.1 | 0.15  |\n|   |   |  notion.so | 7.3 | 0.13  |\n|   |   |  linear.app | 6.5 | 0.12  |\n|   |   |  adsmanager.facebook.com | 5.4 | 0.10  |\n|   |  Calendar Management (2.5) | calendar.google.com | 50.3 | 0.45  |\n|   |   |  outlook.office.com | 7.7 | 0.07  |\n|   |   |  meet.google.com | 3.7 | 0.03  |\n|   |   |  mail.google.com | 3.5 | 0.03  |\n|   |   |  teams.microsoft.com | 1.4 | 0.01  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 40,
          "markdown": "[tbl-18.md](tbl-18.md)\n\nNote: The table shows the top 5 environments under Learning &amp; Research. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries.  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$  is the share of an environment when it is used under that subtopic and does not equal  $P(\\text{Environment})$ , which is the share under all subtopics.\n\nTable 19: The Top 5 Environments Distribution for Learning &amp; Research",
          "images": [],
          "tables": [
            {
              "id": "tbl-18.md",
              "content": "|  Topic | Subtopic | Environment | Environment (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Learning & Research (20.8) | Courses (61.9) | coursera.org | 18.0 | 2.32  |\n|   |   |  netacad.com | 15.6 | 2.01  |\n|   |   |  canvas.com | 12.6 | 1.62  |\n|   |   |  learning.mheducation.com | 8.3 | 1.07  |\n|   |   |  docs.google.com | 6.4 | 0.82  |\n|   |  Research (37.9) | youtube.com | 17.8 | 1.40  |\n|   |   |  perplexity.ai | 6.1 | 0.48  |\n|   |   |  github.com | 5.8 | 0.46  |\n|   |   |  maps.google.com | 5.4 | 0.43  |\n|   |   |  docs.google.com | 3.9 | 0.31  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 41,
          "markdown": "[tbl-19.md](tbl-19.md)\n\nNote: The table shows the top 5 environments under Media &amp; Entertainment. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage  $(P(\\text{Environment} | \\text{Topic}, \\text{Subtopic}))$  is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries.  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} | \\text{Topic}) \\times P(\\text{Environment} | \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$  is the share of an environment when it is used under that subtopic and does not equal  $P(\\text{Environment})$ , which is the share under all subtopics.\n\nTable 20: The Top 5 Environments Distribution for Media &amp; Entertainment",
          "images": [],
          "tables": [
            {
              "id": "tbl-19.md",
              "content": "|  Topic | Subtopic | Environment | Environment (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Media & Entertainment (15.8) | Social Media & Messaging (42.4) | instagram.com | 21.3 | 1.43  |\n|   |   |  x.com | 18.0 | 1.21  |\n|   |   |  whatsapp.com | 13.6 | 0.91  |\n|   |   |  facebook.com | 10.1 | 0.68  |\n|   |   |  linkedin | 6.1 | 0.41  |\n|   |  Movies, TV, & Videos (20.1) | youtube.com | 89.9 | 2.85  |\n|   |   |  netflix.com | 4.1 | 0.13  |\n|   |   |  in.bookmyshow.com | 1.3 | 0.04  |\n|   |   |  twitch.tv | 0.7 | 0.02  |\n|   |   |  tiktok.com | 0.6 | 0.02  |\n|   |  Online Games (19.6) | chess.com | 32.5 | 1.01  |\n|   |   |  store.steampowered.com | 15.0 | 0.46  |\n|   |   |  nytimes.com | 14.2 | 0.44  |\n|   |   |  roblox.com | 6.8 | 0.21  |\n|   |   |  humanbenchmark.com | 5.4 | 0.17  |\n|   |  Music & Podcasts (10.7) | open.spotify.com | 46.1 | 0.78  |\n|   |   |  youtube.com | 39.9 | 0.67  |\n|   |   |  suno.com | 6.2 | 0.10  |\n|   |   |  soundcloud.com | 2.7 | 0.05  |\n|   |   |  music.apple.com | 2.4 | 0.04  |\n|   |  News (3.8) | youtube.com | 21.0 | 0.13  |\n|   |   |  trends.google.com | 13.6 | 0.08  |\n|   |   |  nytimes.com | 8.7 | 0.05  |\n|   |   |  perplexity.ai | 7.9 | 0.05  |\n|   |   |  x.com | 5.8 | 0.03  |\n|   |  Sports (2.7) | youtube.com | 28.3 | 0.12  |\n|   |   |  fantasy.espn.com | 20.1 | 0.09  |\n|   |   |  sleeper.com | 7.8 | 0.03  |\n|   |   |  sofascore.com | 3.3 | 0.01  |\n|   |   |  livescore.in | 1.8 | 0.01  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 42,
          "markdown": "[tbl-20.md](tbl-20.md)\n\nNote: The table shows the top 5 environments under Shopping &amp; Commerce. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries.  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$  is the share of an environment when it is used under that subtopic and does not equal  $P(\\text{Environment})$ , which is the share under all subtopics.\n\nTable 21: The Top 5 Environments Distribution for Shopping &amp; Commerce",
          "images": [],
          "tables": [
            {
              "id": "tbl-20.md",
              "content": "|  Topic | Subtopic | Environment | Environment (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Shopping & Commerce (10.0) | Goods (89.0) | amazon.com | 43.2 | 3.84  |\n|   |   |  flipkart.com | 6.2 | 0.55  |\n|   |   |  admin.shopify.com | 5.3 | 0.47  |\n|   |   |  alibaba.com | 3.7 | 0.33  |\n|   |   |  ozon.ru | 3.4 | 0.30  |\n|   |  Services (10.3) | perplexity.ai | 12.2 | 0.13  |\n|   |   |  maps.google.com | 8.7 | 0.09  |\n|   |   |  amazon.com | 5.1 | 0.05  |\n|   |   |  fiverr.com | 5.1 | 0.05  |\n|   |   |  avito.ru | 4.1 | 0.04  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 43,
          "markdown": "[tbl-21.md](tbl-21.md)\n\nNote: The table shows the top 5 environments under Job &amp; Career. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries.  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$  is the share of an environment when it is used under that subtopic and does not equal  $P(\\text{Environment})$ , which is the share under all subtopics.\n\nTable 22: The Top 5 Environments Distribution for Job &amp; Career",
          "images": [],
          "tables": [
            {
              "id": "tbl-21.md",
              "content": "|  Topic | Subtopic | Environment | Environment (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Job & Career (7.1) | Professional Networking (50.1) | linkedin.com | 92.5 | 3.29  |\n|   |   |  upwork.com | 1.3 | 0.05  |\n|   |   |  app.apollo.io | 0.8 | 0.03  |\n|   |   |  naukri.com | 0.6 | 0.02  |\n|   |   |  instagram.com | 0.5 | 0.02  |\n|   |  Job Search & Application (49.5) | linkedin.com | 60.2 | 2.12  |\n|   |   |  naukri.com | 6.3 | 0.22  |\n|   |   |  ziprecruiter.com | 2.7 | 0.09  |\n|   |   |  indeed.com | 2.5 | 0.09  |\n|   |   |  dice.com | 2.4 | 0.08  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 44,
          "markdown": "[tbl-22.md](tbl-22.md)\n\nNote: The table shows the top 5 environments under Travel &amp; Leisure. The share of topics and subtopics among all agentic queries is shown in parentheses. Environment percentage ( $P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ ) is the environment share within the subtopic. The overall percentage is the environment share among all agentic queries.  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment}) = P(\\text{Topic}) \\times P(\\text{Subtopic} \\mid \\text{Topic}) \\times P(\\text{Environment} \\mid \\text{Topic}, \\text{Subtopic})$ . Note that, unlike tasks, an environment is not unique to a subtopic, so  $P(\\text{Topic}, \\text{Subtopic}, \\text{Environment})$  is the share of an environment when it is used under that subtopic and does not equal  $P(\\text{Environment})$ , which is the share under all subtopics.\n\nTable 23: The Top 5 Environments Distribution for Travel &amp; Leisure",
          "images": [],
          "tables": [
            {
              "id": "tbl-22.md",
              "content": "|  Topic | Subtopic | Environment | Environment (%) | Overall (%)  |\n| --- | --- | --- | --- | --- |\n|  Travel & Leisure (6.7) | Flights & Transportation (40.7) | skyscanner.com | 35.6 | 0.97  |\n|   |   |  maps.google.com | 18.4 | 0.50  |\n|   |   |  makemytrip.com | 7.2 | 0.20  |\n|   |   |  irctc.co.in | 6.1 | 0.17  |\n|   |   |  expedia.com | 4.0 | 0.11  |\n|   |  Lodging (27.3) | booking.com | 54.9 | 1.00  |\n|   |   |  airbnb.com | 19.5 | 0.36  |\n|   |   |  expedia.com | 4.6 | 0.08  |\n|   |   |  maps.google.com | 4.0 | 0.07  |\n|   |   |  agoda.com | 3.5 | 0.06  |\n|   |  Trip Itineraries (24.8) | maps.google.com | 85.2 | 1.42  |\n|   |   |  docs.google.com | 4.2 | 0.07  |\n|   |   |  yandex.ru | 1.3 | 0.02  |\n|   |   |  skyscanner.com | 1.2 | 0.02  |\n|   |   |  booking.com | 0.8 | 0.01  |\n|   |  Restaurants (5.7) | maps.google.com | 54.7 | 0.21  |\n|   |   |  opentable.com | 6.5 | 0.02  |\n|   |   |  map.naver.com | 5.2 | 0.02  |\n|   |   |  swiggy.com | 4.6 | 0.02  |\n|   |   |  ubereats.com | 3.9 | 0.01  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 45,
          "markdown": "[tbl-23.md](tbl-23.md)\n\nNote: The table shows the sum of the top 5 environments' shares by topic and subtopic. A higher (lower) share indicates agentic queries are more (less) concentrated in a small number of environments. This metric can be interpreted as the agent usage market share of environments among agent adopters on Comet.\n\nTable 24: Sum of the Top 5 Environment Shares by Topic and Subtopic",
          "images": [],
          "tables": [
            {
              "id": "tbl-23.md",
              "content": "|  Topic | Subtopic | Sum of the Top 5 Environments (%)  |\n| --- | --- | --- |\n|  Productivity & Workflow | Spreadsheet & Data Editing | 88.1  |\n|   |  Email Management | 85.1  |\n|   |  Document & Form Editing | 78.8  |\n|   |  Investments & Banking | 66.9  |\n|   |  Calendar Management | 66.6  |\n|   |  Multimedia Editing | 65.6  |\n|   |  Computer Programming | 48.2  |\n|   |  Project Management | 36.9  |\n|   |  Account Management | 28.3  |\n|  Learning & Research | Courses | 60.9  |\n|   |  Research | 39.0  |\n|  Media & Entertainment | Music & Podcasts | 97.3  |\n|   |  Movies, TV, & Videos | 96.6  |\n|   |  Online Games | 73.9  |\n|   |  Social Media & Messaging | 69.1  |\n|   |  Sports | 61.3  |\n|   |  News | 57.0  |\n|  Shopping & Commerce | Goods | 61.8  |\n|   |  Services | 35.2  |\n|  Job & Career | Professional Networking | 95.7  |\n|   |  Job Search & Application | 74.1  |\n|  Travel & Leisure | Trip Itineraries | 92.7  |\n|   |  Lodging | 86.5  |\n|   |  Restaurants | 74.9  |\n|   |  Flights & Transportation | 71.3  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 46,
          "markdown": "[tbl-24.md](tbl-24.md)\n\nNote: The table shows the top 5 environments by occupation cluster. Environment percentage  $(P(\\text{Environment} | \\text{Cluster}))$  is the environment share among all agentic queries in that cluster. docs.google.com includes Google Docs, Sheets, Slides, and Forms. All email accounts are grouped into \"email services combined\".\n\nTable 25: The Top 5 Environments by Occupation Cluster",
          "images": [],
          "tables": [
            {
              "id": "tbl-24.md",
              "content": "|  Cluster | Environment | Environment (%)  |\n| --- | --- | --- |\n|  Digital Technology | linkedin.com | 6.5  |\n|   |  email services combined | 5.4  |\n|   |  docs.google.com | 4.0  |\n|   |  youtube.com | 3.3  |\n|   |  amazon.com | 2.4  |\n|  Student | docs.google.com | 7.8  |\n|   |  linkedin.com | 6.1  |\n|   |  email services combined | 4.3  |\n|   |  canvas.com | 3.4  |\n|   |  youtube.com | 3.0  |\n|  Management & Entrepreneurship | linkedin.com | 10.3  |\n|   |  email services combined | 8.8  |\n|   |  docs.google.com | 7.7  |\n|   |  youtube.com | 2.0  |\n|   |  amazon.com | 1.8  |\n|  Marketing & Sales | linkedin.com | 7.8  |\n|   |  docs.google.com | 6.8  |\n|   |  instagram.com | 6.5  |\n|   |  x.com | 5.2  |\n|   |  email services combined | 4.5  |\n|  Financial Services | email services combined | 6.6  |\n|   |  docs.google.com | 5.0  |\n|   |  linkedin.com | 4.3  |\n|   |  youtube.com | 3.6  |\n|   |  tradingview.com | 2.6  |\n|  Education | docs.google.com | 9.9  |\n|   |  email services combined | 6.5  |\n|   |  youtube.com | 4.4  |\n|   |  canvas.com | 2.4  |\n|   |  amazon.com | 2.1  |\n|  Arts, Entertainment, & Design | youtube.com | 7.0  |\n|   |  email services combined | 5.1  |\n|   |  docs.google.com | 4.9  |\n|   |  linkedin.com | 3.6  |\n|   |  instagram.com | 3.2  |\n|  Healthcare & Human Services | email services combined | 7.3  |\n|   |  docs.google.com | 5.8  |\n|   |  linkedin.com | 4.7  |\n|   |  youtube.com | 3.0  |\n|   |  amazon.com | 2.5  |\n|  Advanced Manufacturing | email services combined | 5.5  |\n|   |  linkedin.com | 4.6  |\n|   |  docs.google.com | 4.3  |\n|   |  youtube.com | 3.7  |\n|   |  amazon.com | 3.4  |\n|  Public Service & Safety | email services combined | 6.2  |\n|   |  docs.google.com | 4.9  |\n|   |  youtube.com | 4.1  |\n|   |  trends.google.com | 3.9  |\n|   |  linkedin.com | 2.8  |\n|  Hospitality, Events, & Tourism | email services combined | 6.4  |\n|   |  maps.google.com | 5.6  |\n|   |  docs.google.com | 5.4  |\n|   |  booking.com | 3.6  |\n|   |  skyscanner.com | 2.9  |\n|  Supply Chain & Transportation | email services combined | 8.0  |\n|   |  docs.google.com | 4.9  |\n|   |  linkedin.com | 3.7  |\n|   |  amazon.com | 3.0  |\n|   |  maps.google.com | 2.5  |\n|  Construction | email services combined | 8.2  |\n|   |  linkedin.com | 6.3  |\n|   |  docs.google.com | 4.3  |\n|   |  youtube.com | 3.1  |\n|   |  amazon.com | 2.8  |\n|  Energy & Natural Resources | email services combined | 7.4  |\n|   |  docs.google.com | 6.6  |\n|   |  linkedin.com | 3.8  |\n|   |  amazon.com | 3.4  |\n|   |  youtube.com | 2.9  |\n|  Agriculture | docs.google.com | 7.4  |\n|   |  email services combined | 6.9  |\n|   |  youtube.com | 3.6  |\n|   |  linkedin.com | 3.6  |\n|   |  amazon.com | 2.4  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 47,
          "markdown": "# A.2.4 Usage Context\n\n[tbl-25.md](tbl-25.md)\n\nNote: The table shows the distribution of the top 5 subtopics by usage context. Subtopic percentage  $(P(\\text{Subtopic} | \\text{Context}))$  is the subtopic share among all agentic queries in a given usage context.\n\nTable 26: The Top 5 Subtopic Distribution by Usage Context",
          "images": [],
          "tables": [
            {
              "id": "tbl-25.md",
              "content": "|  Context | Topic | Subtopic | Subtopic (%)  |\n| --- | --- | --- | --- |\n|  Personal | Shopping & Commerce | Goods | 15.6  |\n|   |  Media & Entertainment | Social Media & Messaging | 9.9  |\n|   |  Productivity & Workflow | Account Management | 8.0  |\n|   |  Productivity & Workflow | Email Management | 7.6  |\n|   |  Media & Entertainment | Online Games | 6.0  |\n|  Professional | Productivity & Workflow | Document & Form Editing | 13.3  |\n|   |  Job & Career | Professional Networking | 12.5  |\n|   |  Job & Career | Job Search & Application | 11.0  |\n|   |  Productivity & Workflow | Account Management | 10.2  |\n|   |  Learning & Research | Research | 8.9  |\n|  Educational | Learning & Research | Courses | 83.9  |\n|   |  Learning & Research | Research | 5.3  |\n|   |  Productivity & Workflow | Document & Form Editing | 5.0  |\n|   |  Productivity & Workflow | Account Management | 1.1  |\n|   |  Productivity & Workflow | Computer Programming | 0.9  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 48,
          "markdown": "[tbl-26.md](tbl-26.md)\n\nNote: The table shows the distribution of the top 5 tasks by usage context. Task percentage  $(P(\\text{Task} | \\text{Context}))$  is the task share among all agentic queries in a given usage context.\n\nTable 27: The Top 5 Task Distribution by Usage Context",
          "images": [],
          "tables": [
            {
              "id": "tbl-26.md",
              "content": "|  Context | Topic | Subtopic | Task | Task (%)  |\n| --- | --- | --- | --- | --- |\n|  Personal | Shopping & Commerce | Goods | Search/filter products | 8.6  |\n|   |  Shopping & Commerce | Goods | Summarize/analyze product information | 6.5  |\n|   |  Travel & Leisure | Flights & Transportation | Search/filter flights & transportation | 3.4  |\n|   |  Media & Entertainment | Social Media & Messaging | Search/filter social media posts/messages | 3.4  |\n|   |  Productivity & Workflow | Document & Form Editing | Create/edit documents/forms | 3.2  |\n|  Professional | Productivity & Workflow | Document & Form Editing | Create/edit documents/forms | 8.1  |\n|   |  Learning & Research | Research | Summarize/analyze research information | 5.9  |\n|   |  Job & Career | Job Search & Application | Complete applications | 5.4  |\n|   |  Productivity & Workflow | Account Management | Manage settings/profiles | 5.1  |\n|   |  Job & Career | Professional Networking | Search/filter professional profiles | 4.8  |\n|  Educational | Learning & Research | Courses | Assist exercises | 48.1  |\n|   |  Learning & Research | Courses | Summarize/analyze course materials | 18.8  |\n|   |  Learning & Research | Courses | Navigate courses | 16.0  |\n|   |  Productivity & Workflow | Document & Form Editing | Create/edit documents/forms | 3.6  |\n|   |  Learning & Research | Research | Summarize/analyze research information | 3.4  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 49,
          "markdown": "[tbl-27.md](tbl-27.md)\n\nNote: The table shows the distribution of the top 5 environments by usage context. Environment percentage  $(P(\\text{Environment} \\mid \\text{Context}))$  is the environment share among all agentic queries in a given usage context. docs.google.com includes Google Docs, Sheets, Slides, and Forms. All email domains are grouped into \"email services combined\".\n\nTable 28: The Top 5 Environment Distribution by Usage Context",
          "images": [],
          "tables": [
            {
              "id": "tbl-27.md",
              "content": "|  Context | Environment | Environment (%)  |\n| --- | --- | --- |\n|  Personal | email services combined | 14.5  |\n|   |  youtube.com | 10.8  |\n|   |  docs.google.com | 10.7  |\n|   |  amazon.com | 6.3  |\n|   |  maps.google.com | 3.8  |\n|  Professional | linkedin.com | 29.6  |\n|   |  docs.google.com | 11.4  |\n|   |  email services combined | 9.6  |\n|   |  github.com | 3.8  |\n|   |  admin.shopify.com | 2.8  |\n|  Educational | docs.google.com | 14.8  |\n|   |  coursera.org | 14.6  |\n|   |  netacad.com | 12.7  |\n|   |  canvas.com | 10.2  |\n|   |  learning.mheducation.com | 6.8  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 50,
          "markdown": "# B Agent Demo\n\n# B.1 Sample Agentic Queries\n\n# Useful Prompts for Agentic actions\n\n[tbl-28.md](tbl-28.md)\n\nFigure 9: Sample Agentic Queries from Perplexity at Work",
          "images": [],
          "tables": [
            {
              "id": "tbl-28.md",
              "content": "|  \"Find the latest published journal articles that focus on [insert topic]. Next, open each one in a new tab. Then create a comparison table analyzing research methodologies and results.\"  |\n| --- |\n|  \"Find all unanswered emails from the last 3 days that require a response and draft brief replies. Ignore calendar invites.\"  |\n|  \"Group my tabs by topic and close any that aren't relevant to my current project\"  |\n|  \"Apply for the open job listings opened in this window with my resume.\"  |\n|  \"Find and pull up the Youtube video at the section where Jensen Huang talks about Perplexity at GTC.\"  |\n|  \"Look through these customer case studies and identify any use cases relevant to how our company would use this vendor.\"  |\n|  \"Go through Amazon and see any supplies I haven't ordered in awhile and have it ship to the office address.\"  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 51,
          "markdown": "[tbl-29.md](tbl-29.md)\n\nNote: The table shows how the sample agentic queries map to our taxonomy.\n\nTable 29: Sample Agentic Queries Mapped to the Taxonomy",
          "images": [],
          "tables": [
            {
              "id": "tbl-29.md",
              "content": "|  Sample Query | Topic | Subtopic | Task  |\n| --- | --- | --- | --- |\n|  Find the latest published journal articles... | Learning & Research | Research | Search/filter research information, Summarize/analyze research information  |\n|  Find all unanswered emails... | Productivity & Workflow | Email Management | Search/filter emails, Create/edit emails  |\n|  Group my tabs by topic... | Productivity & Workflow | Account Management | Manage settings/profiles  |\n|  Apply for the open job listings... | Job & Career | Job Search & Application | Complete application  |\n|  Find and pull up the YouTube video... | Media & Entertainment | Movies, TV, & Videos | Search/filter videos, Navigate within videos  |\n|  Look through these customer case studies... | Learning & Research | Research | Search/filter research information, Summarize/analyze research information  |\n|  Go through Amazon... | Shopping & Commerce | Goods | Search/filter products, Make product purchase  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 52,
          "markdown": "# B.2 Agent Behavior for a Real Task\n\nThe prompt asks the agent to find a round-trip flight between Boston and San Diego to attend the 2025 NeurIPS conference. The user prefers late-night direct flights and a lower price. The Figures below show some key steps in how the agent completes the task.[32]\n\n35 steps completed  $\\nvdash$\nPreparing to assist you\n- I'll help you search for flights between Boston and San Diego for the NeurIPS conference. Let me start by creating a tab and searching for information about the conference dates, then look for flights that match your preferences.\n\n$\\mathbb{O}$  Creating to-do list\n\nSearching for NeurIPS conference dates\nSearch for direct flights from Boston to San Diego\nFilter for late night departures and cheaper prices\n\nSearching\n\n$\\mathbb{Q}$  NeurIPS 2025 conference dates location\n\nReviewing sources·10\n\n2025 Dates and Deadlines\n\n2025 Conference\n\n[D] Neurips 2025 being hosted at 3 locations.: r/MachineLearning\n\nNeurIPS 2025 Expo Schedule Overview\n\nNeurIPS 2025: The 39th Annual Conference on Neural Information ...\n\nNeurIPS 2025 - Mexico City Satellite Conference\n\nConferences Future Meetings - NeurIPS 2025\n\nneurips\n\n- Great! I found that NeurIPS 2025 is from December 2-7, 2025 in San Diego. Now let me create a tab and search for flights.\n\nNote: The agent first creates a to-do list that breaks the task into three steps. Because the flight dates are not specified, the agent first searches for the 2025 NeurIPS conference dates and confirms that they are found.\n\nFigure 10: Agent Behavior 1",
          "images": [],
          "tables": [],
          "hyperlinks": [
            "https://www.perplexity.ai/search/search-for-the-best-flights-be-TNxDicWmSiW9gmcpa2pHNg#0"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 53,
          "markdown": "Updating to-do list\n\nSearch for NeurIPS conference dates\nSearching for direct flights\nFilter for late night departures and cheaper prices\n\n![img-11.jpeg](img-11.jpeg)\nCreating tab\n\n![img-12.jpeg](img-12.jpeg)\n\nPerfect! Google Flights is loaded with Boston already in the origin field. Now I need to enter San Diego as the destination and set the dates around the conference (December 2-7, 2025). Let me fill in the destination and dates.\n\n![img-13.jpeg](img-13.jpeg)\nClicking\n\n![img-14.jpeg](img-14.jpeg)\nNote: The agent then updates the to-do list and proceeds to the next item by searching flights. It operates on the website by entering destinations and dates.\nFigure 11: Agent Behavior 2",
          "images": [
            {
              "id": "img-11.jpeg",
              "top_left_x": 244,
              "top_left_y": 774,
              "bottom_right_x": 518,
              "bottom_right_y": 961,
              "image_base64": null,
              "image_annotation": null
            },
            {
              "id": "img-12.jpeg",
              "top_left_x": 244,
              "top_left_y": 963,
              "bottom_right_x": 518,
              "bottom_right_y": 1150,
              "image_base64": null,
              "image_annotation": null
            },
            {
              "id": "img-13.jpeg",
              "top_left_x": 244,
              "top_left_y": 1344,
              "bottom_right_x": 518,
              "bottom_right_y": 1529,
              "image_base64": null,
              "image_annotation": null
            },
            {
              "id": "img-14.jpeg",
              "top_left_x": 244,
              "top_left_y": 1533,
              "bottom_right_x": 518,
              "bottom_right_y": 1718,
              "image_base64": null,
              "image_annotation": null
            }
          ],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 54,
          "markdown": "![img-15.jpeg](img-15.jpeg)\nFigure 12: Agent Behavior 3",
          "images": [
            {
              "id": "img-15.jpeg",
              "top_left_x": 251,
              "top_left_y": 536,
              "bottom_right_x": 1443,
              "bottom_right_y": 1680,
              "image_base64": null,
              "image_annotation": null
            }
          ],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 55,
          "markdown": "Good! Now it's \"Sorted by price\". The flights are now in price order:\n\nJetBlue 3:50 PM - 7:21 PM (Nonstop, 6h 31m) - $1,134 (cheapest)\n\nAlaska/American 4:26 PM - 8:06 PM (Nonstop, 6h 40m) - $1,502\n\nDelta 5:25 PM - 8:56 PM (Nonstop, 6h 31m) - $1,857\n\nNow let me check if there might be red-eye flights by changing the departure date to November 30th (Sunday night) which would arrive December 1st. Let me click on the departure date to change it.\n\nClicking\n\n![img-16.jpeg](img-16.jpeg)\nFigure 13: Agent Behavior 4\n\n![img-17.jpeg](img-17.jpeg)\n\nNote: The agent applies a price filter and observes options. Because options are limited, it expands the travel dates to look for red-eye flights.",
          "images": [
            {
              "id": "img-16.jpeg",
              "top_left_x": 258,
              "top_left_y": 1056,
              "bottom_right_x": 547,
              "bottom_right_y": 1249,
              "image_base64": null,
              "image_annotation": null
            },
            {
              "id": "img-17.jpeg",
              "top_left_x": 258,
              "top_left_y": 1254,
              "bottom_right_x": 547,
              "bottom_right_y": 1447,
              "image_base64": null,
              "image_annotation": null
            }
          ],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 56,
          "markdown": "Excellent! Now I can see flights departing November 30 (Sunday). This is much better! I can see there are more nonstop options and the prices are cheaper. The flights shown are:\n\nJetBlue 7:00 AM - 10:39 AM (Nonstop, 6h 39m) - $1,173\n\nJetBlue 10:02 AM - 1:34 PM (Nonstop, 6h 32m) - $1,173\n\nJetBlue 3:50 PM - 7:21 PM (Nonstop, 6h 31m) - $1,173\n\nAlaska/American 4:26 PM - 8:06 PM (Nonstop, 6h 40m) - $1,702\n\nDelta 5:25 PM - 8:56 PM (Nonstop, 6h 31m) - $1,897\n\nThese are all Sunday flights. Now let me scroll down to see if there are any late night/red-eye flights departing Sunday night (which would arrive Monday).\n\n![img-18.jpeg](img-18.jpeg)\n$\\odot$  Scrolling\n\n![img-19.jpeg](img-19.jpeg)\nFigure 14: Agent Behavior 5\n\nNote: The agent expands the dates and confirms that red-eye flights departing a day earlier are much cheaper.",
          "images": [
            {
              "id": "img-18.jpeg",
              "top_left_x": 251,
              "top_left_y": 1104,
              "bottom_right_x": 525,
              "bottom_right_y": 1287,
              "image_base64": null,
              "image_annotation": null
            },
            {
              "id": "img-19.jpeg",
              "top_left_x": 251,
              "top_left_y": 1291,
              "bottom_right_x": 525,
              "bottom_right_y": 1474,
              "image_base64": null,
              "image_annotation": null
            }
          ],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 57,
          "markdown": "Perfect! I selected the JetBlue 7:00 AM flight and now I can see the return flight options. The page shows:\n\nOutbound: BOS-SAN (selected: JetBlue 7:00 AM - 10:39 AM on Nov 30)\n\nReturning flights: Shows two options:\n\nJetBlue 8:31 PM - 5:02 AM+1 (Red-eye, arrives next day) - $1,173\n\nJetBlue 11:38 AM - 8:14 PM - $1,313\n\nGreat! There's actually a red-eye return flight option. Now let me go back to see all the outbound flight options to compile a comprehensive summary. Let me click on \"BOS-SAN\" to go back.\n\nClicking\n\n![img-20.jpeg](img-20.jpeg)\nFigure 15: Agent Behavior 6\n\n![img-21.jpeg](img-21.jpeg)\n\n![img-22.jpeg](img-22.jpeg)\n\n![img-23.jpeg](img-23.jpeg)\n\nNote: The agent clicks on an outbound flight with the lowest price and proceeds to the inbound flight.",
          "images": [
            {
              "id": "img-20.jpeg",
              "top_left_x": 246,
              "top_left_y": 888,
              "bottom_right_x": 525,
              "bottom_right_y": 1075,
              "image_base64": null,
              "image_annotation": null
            },
            {
              "id": "img-21.jpeg",
              "top_left_x": 246,
              "top_left_y": 1078,
              "bottom_right_x": 525,
              "bottom_right_y": 1262,
              "image_base64": null,
              "image_annotation": null
            },
            {
              "id": "img-22.jpeg",
              "top_left_x": 246,
              "top_left_y": 1265,
              "bottom_right_x": 525,
              "bottom_right_y": 1449,
              "image_base64": null,
              "image_annotation": null
            },
            {
              "id": "img-23.jpeg",
              "top_left_x": 246,
              "top_left_y": 1452,
              "bottom_right_x": 525,
              "bottom_right_y": 1639,
              "image_base64": null,
              "image_annotation": null
            }
          ],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 58,
          "markdown": "# Updating to-do list\n\nSearch for NeurIPS conference dates\nSearch for direct flights from Boston to San Diego\nFilter for late night departures and cheaper prices\n\nPerfect! I've completed the search for the best flights for the NeurIPS conference. Let me provide a comprehensive summary.\nFinished\n\nI've searched for the best flights between Boston and San Diego for the NeurIPS conference (December 2-7, 2025). Here's what I found:\n\n# Conference Details\n\n- NeurIPS 2025: December 2-7, 2025 at the San Diego Convention Center neurips\n\n# Direct Flight Options (sorted by price)\n\nUnfortunately, there are no true late-night/red-eye nonstop flights from Boston to San Diego. However, I found these nonstop options:\n\nDeparting Sunday, November 30 (arriving day before conference):\n\n1. JetBlue 7:00 AM - 10:39 AM - $1,173 (6h 39m) √ Best Price\n2. JetBlue 10:02 AM - 1:34 PM - $1,173 (6h 32m) √ Best Price\n3. JetBlue 3:50 PM - 7:21 PM - $1,173 (6h 31m) √ Best Price, Latest budget option\n4. Alaska/American 4:26 PM - 8:06 PM - $1,702 (6h 40m)\n5. Delta 5:25 PM - 8:56 PM - $1,897 (6h 31m) - Latest departure\n\nDeparting Monday, December 1 (conference start date):\n\n1. JetBlue 3:50 PM - 7:21 PM - $1,134 (6h 31m) √ Cheapest\n2. Alaska/American 4:26 PM - 8:06 PM - $1,502 (6h 40m)\n3. Delta 5:25 PM - 8:56 PM - $1,857 (6h 31m)\n\n# Recommendation\n\nFor your preference of late departures and cheaper prices, I recommend:\n\nOption 1 (Best Value): JetBlue departing Sunday, Nov 30 at 3:50 PM for $1,173 - This gives you:\n\n- Evening departure (closest to \"late night\" available)\n- Cheapest nonstop option\n- Arrival day before conference starts for buffer time\n\nOption 2 (Conference Day): JetBlue departing Monday, Dec 1 at 3:50 PM for $1,134 - Slightly cheaper but arrives evening of conference start\n\nNote: The latest nonstop departure is Delta at 5:25 PM, but it costs $1,897 (significantly more expensive).\n\nNote: The agent completes the task by presenting the recommendations to the user.\n\nFigure 16: Agent Behavior 7",
          "images": [],
          "tables": [],
          "hyperlinks": [],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        },
        {
          "index": 59,
          "markdown": "# C Early Adopter Survey\n\nTo better understand who the early users of Comet are, we invited a subset of users to complete a survey in November 2025. A typical respondent is a male aged 35 or older who works full-time in the technology industry, is either a current Perplexity user or has a strong interest in AI-powered browsing, and uses Comet roughly equally across professional and personal contexts. As is often the case with new technology products, we expect user composition to change significantly over time as Comet diffuses into the population.\n\n# D Validation of Agent Use Cases Classifier\n\nWe randomly select 1,000 agentic queries for manual labeling.33 These queries are sampled from a larger set previously classified as containing no harmful content. To preserve representativeness, we retain queries that may include personal information, while redacting names, email addresses, physical addresses, and phone numbers. Each query in the sample is independently labeled by two or three annotators using our agentic taxonomy. Out of the 1,000 queries, 370 show disagreement among annotators on what the primary topic and subtopic are. Most disagreements stemmed from variations in labeling quality across annotators. For each query that shows disagreement, our team manually reviews it and labels it against our taxonomy. The final golden dataset includes the 630 queries on which all annotators agreed, along with the 370 queries we labeled. We validate the classifier against the golden dataset and across multiple runs, and the agreement rates are listed in Table 30.\n\n[tbl-30.md](tbl-30.md)\n\nNote: The table shows the agreement rate between the classifier label and the golden dataset and across runs. The tasks are specific to subtopics, so when the classifier disagrees with the golden dataset or across runs on topics or subtopics, the tasks will by definition have zero agreement rates. Therefore, the task agreement rate is conditional on topic- and subtopic-level agreement. The across-runs agreement rate is the average pairwise agreement rate across three runs.\n\nTable 30: Agent Use Case Classification Validation",
          "images": [],
          "tables": [
            {
              "id": "tbl-30.md",
              "content": "|  Variable | Golden Dataset (%) | Across Runs (%)  |\n| --- | --- | --- |\n|  Topic | 89.4 | 97.2  |\n|  Subtopic | 83.2 | 94.6  |\n|  Task | 81.3 | 88.2  |\n|  Usage Context | 82.9 | 96.3  |",
              "format": "markdown"
            }
          ],
          "hyperlinks": [
            "https://wildchat.allen.ai/"
          ],
          "header": null,
          "footer": null,
          "dimensions": {
            "dpi": 200,
            "height": 2200,
            "width": 1700
          }
        }
      ],
      "model": "mistral-ocr-latest",
      "document_annotation": null,
      "usage_info": {
        "pages_processed": 60,
        "doc_size_bytes": 2715976
      }
    }
  }
}